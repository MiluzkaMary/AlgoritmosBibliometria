@article{ROOS2020112975,
title = {Online conferences – Towards a new (virtual) reality},
journal = {Computational and Theoretical Chemistry},
volume = {1189},
pages = {112975},
year = {2020},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2020.112975},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X20302759},
author = {Goedele Roos and Julianna Oláh and Rebecca Ingle and Rika Kobayashi and Milica Feldt},
keywords = {Virtual conference, Virtual Winter School on Computational Chemistry, Hybrid online/in-person conference},
abstract = {The recent article: Nature 579, 327–328 (2020), ending with the phrase: “You can’t just suddenly make a conference be online.”, has motivated us to write about the practicalities and philosophy of running online events, drawing on our extensive experience running an annual online computational chemistry conference. Our goals for this online conference series have always been: (1) Availability; (2) Community building and (3) Supporting young scientists. In this article, we highlight the motivations behind our initiative, how this has influenced the organisation of our online meeting, and discuss the benefits as well as the drawbacks of virtual meetings. Virtual conferences may not fully replace in-person meetings, but they are rapidly becoming an accepted alternative format. We discuss the hybrid online/in-person conference format as a future possibility that may offer an opportunity to reduce the environmental impact and accessibility barriers associate with in-person meetings without comprising networking and community-building opportunities.}
}
@article{MANLEY201427,
title = {A framework for simulating large-scale complex urban traffic dynamics through hybrid agent-based modelling},
journal = {Computers, Environment and Urban Systems},
volume = {44},
pages = {27-36},
year = {2014},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2013.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971513001129},
author = {Ed Manley and Tao Cheng and Alan Penn and Andy Emmonds},
keywords = {Agent-based simulation, Urban complexity, Human cognition, Collective phenomena, Traffic flow, Hybrid simulation},
abstract = {Urban road traffic dynamics are the product of the behaviours and interactions of thousands, often millions of individuals. Traditionally, models of these phenomena have incorporated simplistic representations of individual behaviour, ensuring the maximisation of simulation scale under given computational constraints. Yet, by simplifying representations of behaviour, the overall predictive capability of the model inevitably reduces. In this work a hybrid agent-based modelling framework is introduced that aims to balance the demands of behavioural realism and computational capacity, integrating a descriptive representation of driver behaviour with a simplified, collective model of traffic flow. The hybridisation of these approaches within an agent-based modelling framework yields a representation of urban traffic flow that is driven by individual behaviour, yet, in reducing the computational intensity of simulated physical interaction, enables the scalable expansion to large numbers of agents. A real-world proof-of-concept case study is presented, demonstrating the application of this approach, and showing the gains in computational efficiency made in utilising this approach against traditional agent-based approaches. The paper concludes in addressing how this model might be extended, and exploring the role hybrid agent-based modelling approaches may hold in the simulation of other complex urban phenomena.}
}
@article{NORTHOFF2025106139,
title = {Bridging the gap of brain and experience – Converging Neurophenomenology with Spatiotemporal Neuroscience},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {173},
pages = {106139},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106139},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425001393},
author = {Georg Northoff and Bianca Ventura},
keywords = {Neurophenomenology, Temporo-spatial dynamics, Self, Meditation, Depression},
abstract = {Neuroscience faces the challenge of connecting brain and mind, with the mind manifesting in first-person experience while the brain’s neural activity can only be investigated in third-person perspective. To connect neural and mental states, Neurophenomenology provides a methodological toolkit for systematically linking first-person subjective experience with third-person objective observations of the brain’s neural activity. However, beyond providing a systematic methodological strategy (‘disciplined circularity’), it leaves open how neural activity and subjective experience are related among themselves, independent of our methodological strategy. The recently introduced Spatiotemporal Neuroscience suggests that neural activity and subjective experience share a commonly underlying feature as their “common currency”, notably analogous spatiotemporal dynamics. Can Spatiotemporal Neuroscience inform Neurophenomenology to allow for a deeper and more substantiative connection of first-person experience and third-person neural activity? The goal of our paper is to show how Spatiotemporal Neuroscience and Neurophenomenology can be converged and integrated with each other to gain better understanding of the brain-mind connection. We describe their convergence on theoretical grounds which, subsequently, is illustrated by empirical examples like self, meditation, and depression. In conclusion, we propose that the integration of Neurophenomenology and Spatiotemporal Neuroscience can provide complementary insights, enrich both fields, allows for deeper understanding of brain-mind connection, and opens the door for developing novel methodological approaches in their empirical investigation.}
}
@article{XU2021104922,
title = {Brain decoding in multiple languages: Can cross-language brain decoding work?},
journal = {Brain and Language},
volume = {215},
pages = {104922},
year = {2021},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2021.104922},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X2100016X},
author = {Min Xu and Duo Li and Ping Li},
keywords = {Cross-language brain decoding, Neural representation, Multivariate pattern analysis, Computational modeling, Multilingualism},
abstract = {The approach of cross-language brain decoding is to use models of brain decoding from one language to decode stimuli of another language. It has the potential to provide new insights into how our brain represents multiple languages. While it is possible to decode semantic information across different languages from neuroimaging data, the approach’s overall success remains to be tested and depends on a number of factors such as cross-language similarity, age of acquisition/proficiency levels, and depth of language processing. We expect to see continued progress in this domain, from a traditional focus on words and concrete concepts toward the use of naturalistic experimental tasks involving higher-level language processing (e.g., discourse processing). The approach can also be applied to understand how cross-modal, cross-cultural, and other nonlinguistic factors may influence neural representations of different languages. This article provides an overview of cross-language brain decoding with suggestions for future research directions.}
}
@article{HAO201630,
title = {Reflection enhances creativity: Beneficial effects of idea evaluation on idea generation},
journal = {Brain and Cognition},
volume = {103},
pages = {30-37},
year = {2016},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278262616300057},
author = {Ning Hao and Yixuan Ku and Meigui Liu and Yi Hu and Mark Bodner and Roland H. Grabner and Andreas Fink},
keywords = {Idea evaluation, Idea generation, Creativity, Alpha, EEG},
abstract = {The present study aimed to explore the neural correlates underlying the effects of idea evaluation on idea generation in creative thinking. Participants were required to generate original uses of conventional objects (alternative uses task) during EEG recording. A reflection task (mentally evaluating the generated ideas) or a distraction task (object characteristics task) was inserted into the course of idea generation. Behavioral results revealed that participants generated ideas with higher originality after evaluating the generated ideas than after performing the distraction task. The EEG results revealed that idea evaluation was accompanied with upper alpha (10–13Hz) synchronization, most prominent at frontal cortical sites. Moreover, upper alpha activity in frontal cortices during idea generation was enhanced after idea evaluation. These findings indicate that idea evaluation may elicit a state of heightened internal attention or top-down activity that facilitates efficient retrieval and integration of internal memory representations.}
}
@article{KUGURAKOVA2015112,
title = {Anthropomorphic Artificial Social Agent with Simulated Emotions and its Implementation},
journal = {Procedia Computer Science},
volume = {71},
pages = {112-118},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.217},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036789},
author = {Vlada Kugurakova and Maxim Talanov and Nadir Manakhov and Denis Ivanov},
keywords = {intelligent agents, visualization, emotional artificial intelligence, neuromodulators, visual speech synthesis, expressive and controllable speech synthesis},
abstract = {In this paper we describe an emotional human-machine interface as an anthropomorphic social agent able to exhibit simulated emotions and react to emotional stimuli. We propose a neurobiologically inspired agent implementation that is based on mechanics of chemical and physiological processes within human brain. Implementation of model features simulation of neuromodulators such as dopamine, serotonin, and noradrenaline. Demonstration of emotions is achieved via combining aforementioned neuromodulators in different proportions. The Lovheim cube of emotions is used for this purpose. Topic of “uncanny valley” phenomenon and its effect on human-machine interactions is also mentioned. In conclusion of this paper we have proposed realistic computation model allowing us to visualize agents mimics in sync with his speech, and have made a working prototype of aforementioned model.}
}
@article{POGGIO1981258,
title = {Marr's computational approach to vision},
journal = {Trends in Neurosciences},
volume = {4},
pages = {258-262},
year = {1981},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(81)90081-3},
url = {https://www.sciencedirect.com/science/article/pii/0166223681900813},
author = {T. Poggio},
abstract = {In the last 7 years a new computational approach has led to promising advances in our understanding of visual perception. The foundations of the approach, its overall framework and its first solid results are largely due to the work of a single man, David Marr at MIT. Now, after his death in Boston on 17 November, 1980, research in vision will never be the same.}
}
@incollection{DORST200723,
title = {2 - Spanning oriented subspaces},
editor = {Leo Dorst and Daniel Fontijne and Stephen Mann},
booktitle = {Geometric Algebra for Computer Science},
publisher = {Morgan Kaufmann},
address = {Burlington},
pages = {23-64},
year = {2007},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-369465-2},
doi = {https://doi.org/10.1016/B978-012369465-2/50005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123694652500050},
author = {Leo Dorst and Daniel Fontijne and Stephen Mann},
abstract = {Publisher Summary
This chapter shows that a vector space is much more than merely a space of vectors, and that it is straightforward and useful to extend it computationally. The crucial idea here is to make the subspaces of vector space explicit elements of computation. To build the algebra of subspaces, the familiar lines and planes are revisited through the origin. This chapter investigates their geometrical properties carefully and formalizes those by the aid of a new algebraic outer product, which algebraically builds subspaces from vectors. The structure it produces is considered for the Grassmann space of subspaces of a vector space Rn, and defines many terms to describe its features. Throughout this chapter, it considers a real n-dimensional vector space Rn, but has no need for a metric; additionally, it only treats its homogeneous subspaces (i.e., subspaces containing the origin). The chapter starts with an n-dimensional vector space. However, the definition of a vector space in linear algebra is more general than what is needed in this book, being defined over arbitrary fields of scalars. To develop thinking about subspaces, the homogeneous subspaces of a 3-D space are considered.}
}
@article{LI2022101701,
title = {A framework and method for Human-Robot cooperative safe control based on digital twin},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101701},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101701},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001604},
author = {Hao Li and Wenfeng Ma and Haoqi Wang and Gen Liu and Xiaoyu Wen and Yuyan Zhang and Miying Yang and Guofu Luo and Guizhong Xie and Chunya Sun},
keywords = {Human-robot collaboration, Digital twin, Safety control, Machine vision, Convolutional neural network},
abstract = {Human-robot collaboration (HRC) combines the robot’s mechanical properties and predictability with human experience, logical thinking, and strain capabilities to alleviate production efficiency. However, ensuring the safety of the HRC process in-real time has become an urgent issue. Digital twin extends functions of virtual models in the design phase of the physical counterpart in the production phase through virtual-real interactive feedback, data fusion analysis, advanced computational features, etc. This paper proposes an HRC safety control framework and corresponding method based on the digital twin. In the design phase, virtual simulation and virtual reality technology are integrated to construct virtual twins of various HRC scenarios for testing and analyzing potential safety hazards. In the production phase, the safety distance between humans and robots of the HRC scene is monitored and calculated by an iterative algorithm according to machine vision and a convolutional neural network. Finally, the virtual twin is driven based on real-scene data, real-time online visual monitoring, and optimization of the HRC’s overall process. A case study using ABB-IRB1600 is presented to verify the feasibility of the proposed approach.}
}
@article{OFOSUAMPONG2024100127,
title = {Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100127},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000136},
author = {Kingsley Ofosu-Ampong},
keywords = {Artificial intelligence, Classification, Literature review, Technological issues, Research agenda},
abstract = {This article presents an analysis of artificial intelligence (AI) in information systems and innovation-related journals to determine the current issues and stock of knowledge in AI literature, research methodology, frameworks, level of analysis and conceptual approaches. By doing this, the article aims to identify research gaps that can guide future investigations. A total of 85 peer-reviewed articles from 2020 to 2023 were used in the analysis. The findings show that extant literature is skewed towards the prevalence of technological issues and highlights the relatively lower focus on other themes, such as contextual knowledge co-creation issues, conceptualisation, and application domains. While there have been increasing technological issues with artificial intelligence, the three identified areas of security concern are data security, model security and network security. Furthermore, the review found that contemporary AI, which continually drives the boundaries of computational capabilities to tackle increasingly intricate decision-making challenges, distinguishes itself from earlier iterations in two primary aspects that significantly affect organisational learning in dealing with AI's potential: autonomy and learnability. This study contributes to AI research by providing insights into current issues, research methodology, level of analysis and conceptual approaches, and AI framework to help identify research gaps for future investigations.}
}
@article{MAFTEI2022107032,
title = {Using fake news as means of cyber-bullying: The link with compulsive internet use and online moral disengagement},
journal = {Computers in Human Behavior},
volume = {127},
pages = {107032},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107032},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221003551},
author = {Alexandra Maftei and Andrei-Corneliu Holman and Ioan-Alex Merlici},
keywords = {Fake news, Online moral disengagement, Cyberbullying, Compulsive internet use},
abstract = {Online moral disengagement and cyberbullying can enhance fake news spreading. We explored the links between these variables and compulsive Internet use in a sample of 509 teenagers and adults aged 11 to 67. We investigated the effect of compulsive Internet use on cyberbullying through fake news creation and/or distribution, both direct and via moral disengagement, and the related differences between adults and teenagers. The indirect effect of compulsive Internet use on cyberbullying through moral disengagement was significant in adolescents, but not in adults. As assumed, teenagers scored significantly higher than adults on all the primary variables. Contrary to our expectations, no significant gender differences emerged, regardless of participants' age, in terms of compulsive Internet use, moral disengagement, nor cyberbullying. The results emphasize the importance of relevant online education programs designed to engage both teenagers and adults in critical thinking that might help in the fake news detection process, especially during the COVID-19 pandemic.}
}
@article{MONTEIRO2023100076,
title = {Environmental assessment in concrete pole industries},
journal = {CEMENT},
volume = {13},
pages = {100076},
year = {2023},
issn = {2666-5492},
doi = {https://doi.org/10.1016/j.cement.2023.100076},
url = {https://www.sciencedirect.com/science/article/pii/S2666549223000221},
author = {Nathalie Barbosa Reis Monteiro and José Machado {Moita Neto} and Elaine Aparecida {da Silva}},
keywords = {Concrete poles, Life cycle, Environmental impact},
abstract = {Purpose
Companies that manufacture poles generate several negative environmental impacts, whose extent needs to be assessed to find ways to mitigate them.
Methods
In this research, Life Cycle Assessment (LCA) was used as a methodology to measure the potential environmental impacts throughout the poles' life cycle. Primary data (amount of cement, gravel, sand, steel rebars, energy, water) were collected from industries located in Teresina, Piauí, Brazil, and information from the Ecoinvent 3.7.1 database (transport, solid waste, liquid effluents, particulate matter) was used.
Results and discussion
The literature addresses pole production from a different perspective, making this study relevant to disseminate the life cycle thinking in concrete pole production. However, the literature points to a correlation trend for ecotoxicity and human toxicity indicators, as well as the results found in this research. Waste disposal stands out as an important source of impact for these industries, confirming the necessity of efficient management of these materials at the end of their lifespan and during the production process. The scenario analysis showed that is possible to reduce the potential impacts of these industries.
Conclusion
The reuse of waste within the industry itself is feasible (using a shredder for this purpose) and can contribute to decreasing the extraction of natural deposits in various production processes related to the poles' life cycle and reducing their accumulation in the environment. The use of inputs from closer suppliers is a strategy that contributes to mitigating the potential impact of gaseous emissions, reducing the impact that generates global warming and climate change. In addition, other papers show viable alternatives in different scenarios, based on complex laboratory studies. Nevertheless, his approach shows how impacts can be mitigated with the adoption of simple actions such as the reuse of effluents and residues from these industries. It is possible to redefine the production process through a scenario close to the ideal, bringing environmental sustainability to the sector.}
}
@article{RODRIGUEZ2024,
title = {Leveraging Generative AI Tools to Support the Development of Digital Solutions in Health Care Research: Case Study},
journal = {JMIR Human Factors},
volume = {11},
year = {2024},
issn = {2292-9495},
doi = {https://doi.org/10.2196/52885},
url = {https://www.sciencedirect.com/science/article/pii/S2292949524000245},
author = {Danissa V Rodriguez and Katharine Lawrence and Javier Gonzalez and Beatrix Brandfield-Harvey and Lynn Xu and Sumaiya Tasneem and Defne L Levine and Devin Mann},
keywords = {digital health, GenAI, generative, artificial intelligence, ChatGPT, software engineering, mHealth, mobile health, app, apps, application, applications, diabetes, diabetic, diabetes prevention, digital prescription, software, engagement, behaviour change, behavior change, developer, developers, LLM, LLMs, language model, language models, NLP, natural language processing},
abstract = {Background
Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting.
Objective
This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program.
Methods
We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency.
Results
Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies.
Conclusions
ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation.
Trial Registration
ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500}
}
@article{POURFOULADI2025107722,
title = {PoliBrick plugin as a parametric tool for digital stereotomy modelling},
journal = {Computers & Structures},
volume = {311},
pages = {107722},
year = {2025},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2025.107722},
url = {https://www.sciencedirect.com/science/article/pii/S004579492500080X},
author = {Mohammad Pourfouladi and Natalia Pingaro and Marco Valente},
keywords = {PoliBrick Plugin, Software Development, Masonry Construction, Brick Pattern, Stereotomy, Single and Double Curvature Vaults},
abstract = {This paper presents the development of a new plugin that is both simple and user-friendly for the digital modelling of multiple brick patterns in 3D on any surface, from simple flat walls to complex single and double curvature geometries. The plugin, named PoliBrick, is specifically conceived to assist in modelling different types of brickwork shells with intricate patterns, such as masonry arches and vaults. It excels in streamlining parametric modelling across a broad spectrum of free-form curved surfaces, standing out from existing tools. Developed for Rhino software within the Grasshopper environment, PoliBrick features an intuitive interface and comprises only six essential components. Its parametric method makes it competitive with any procedure documented in the literature, as it can accurately replicate brick assemblies on all types of free-form shells. PoliBrick can reproduce, with immediate feedback, any brick arrangement, including patterns like basket weave, stretcher bond, herringbone bond, and many others. Such a functionality addresses a significant gap in current software tools, which cannot often handle curved geometries with complex brick layouts. Moreover, the new plugin can be integrated into a variety of software tools to enable pre-analysis capabilities for the structural evaluation of single and double curvature vaulted structures, using preferred methods like finite element or distinct element approaches. It also supports robotic fabrication processes by considering paths and construction order, enhancing its practical utility in modern construction techniques. PoliBrick is benchmarked on some case studies to demonstrate the validity of the developed procedure and the robustness of the proposed algorithm, which is expected to be effective in markedly reducing the computational effort in pre-structural analysis modelling phases and allows designers to take into account the non-negligible role of stereotomy in curved structures.}
}
@incollection{SEDIG2005239,
title = {17 A descriptive framework for designing interaction for visual abstractions},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {239-254},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80045-5},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800455},
author = {K. Sedig and J. Morey},
abstract = {This chapter propses a descriptive framework for categorisation and characterisation of the different forms of interaction with visual abstractions (VAs). Abstract visual representations play an important role in assisting human reasoning, thinking, and understanding processes. There are different forms of designing interaction with these representations. The goal of this chapter is to provide a descriptive framework to guide the designers and evaluators of cognitive tools to determine the appropriate forms of interaction that can facilitate the understanding of abstract concepts, patterns, structures and processes. The framework is described and substantiated using a number of VAs that represent and communicate mathematical ideas.}
}
@article{PESSOA2019158,
title = {Neural dynamics of emotion and cognition: From trajectories to underlying neural geometry},
journal = {Neural Networks},
volume = {120},
pages = {158-166},
year = {2019},
note = {special Issue in Honor of the 80th Birthday of Stephen Grossberg},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019302242},
author = {Luiz Pessoa},
keywords = {Emotion, Cognition, Dynamics, Trajectories, Manifold},
abstract = {How can we study, characterize, and understand the neural underpinnings of cognitive-emotional behaviors as inherently dynamic processes? In the past 50 years, Stephen Grossberg has developed a research program that embraces the themes of dynamics, decentralized computation, emergence, selection and competition, and autonomy. The present paper discusses how these principles can be heeded by experimental scientists to advance the understanding of the brain basis of behavior. It is suggested that a profitable way forward is to focus on investigating the dynamic multivariate structure of brain data. Accordingly, central research problems involve characterizing “neural trajectories” and the associated geometry of the underlying “neural space.” Finally, it is argued that, at a time when the development of neurotechniques has reached a fever pitch, neuroscience needs to redirect its focus and invest comparable energy in the conceptual and theoretical dimensions of its research endeavor. Otherwise we run the risk of being able to measure “every atom” in the brain in a theoretical vacuum.}
}
@article{NAGHDY2025102445,
title = {Collaboration with GenAI in Engineering Research Design},
journal = {Data & Knowledge Engineering},
pages = {102445},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102445},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000400},
author = {Fazel Naghdy},
keywords = {literature review, hypothesis, research design, GenAI, research gaps},
abstract = {Over the past five years, the fast development and use of generative artificial intelligence (GenAI) and large language models (LLMs) has ushered in a new era of study, teaching, and learning in many domains. The role that GenAIs can play in engineering research is addressed. The related previous works report on the potential of GenAIs in the literature review process. However, such potential is not demonstrated by case studies and practical examples. The previous works also do not address how GenAIs can assist with all the steps traditionally taken to design research. This study examines the effectiveness of collaboration with GenAIs at various stages of research design. It explores whether collaboration with GenAIs can result in more focused and comprehensive outcomes. A generalised approach for collaboration with AI tools in research design is proposed. A case study to develop a research design on the concept of “shared machine-human driving” is deployed to show the validity of the articulated concepts. The case study demonstrates both the pros and cons of collaboration with GenAIs. The results generated at each stage are rigorously validated and thoroughly examined to ensure they remain free from inaccuracies or hallucinations and align with the original research objectives. When necessary, the results are manually adjusted and refined to uphold their integrity and accuracy. The findings produced by the various GenAI models utilized in this study highlight the key attributes of generative artificial intelligence, namely speed, efficiency, and scope. However, they also underscore the critical importance of researcher oversight, as unexamined inferences and interpretations can render the results irrelevant or meaningless.}
}
@article{SUCHANTKE2020439,
title = {Space sustainability in Martian orbits — First insights in a technical and regulatory analysis},
journal = {Journal of Space Safety Engineering},
volume = {7},
number = {3},
pages = {439-446},
year = {2020},
note = {Space Debris: The State of Art},
issn = {2468-8967},
doi = {https://doi.org/10.1016/j.jsse.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468896720300677},
author = {Isabell Suchantke and Francesca Letizia and Vitali Braun and Holger Krag},
abstract = {Hazards from the outer space environment either natural (space weather and asteroids) or artificial (space debris and the growing number of satellites launched to orbit) pose a rising risk to space flight activities. The awareness for space sustainability and space safety has seen a continuous increase in recent years and does not stop at the Earth's sphere of influence. The first spacefaring nations start thinking about sustainability in cislunar space and the Martian environment. This work deals with the issue of space debris in Martian orbits in the light of planetary protection. A Mars Sustainability Framework has been developed. This includes a study on the orbital and regulatory environment of Mars, long-term propagation of orbits of artificial objects and the two natural moons, and the analysis of objects evolution and first approaches for collision probability computation. With this work, the issue of space debris beyond Earth orbit is analysed at an early stage.}
}
@article{FAN2020248,
title = {From Brain Science to Artificial Intelligence},
journal = {Engineering},
volume = {6},
number = {3},
pages = {248-252},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920300035},
author = {Jingtao Fan and Lu Fang and Jiamin Wu and Yuchen Guo and Qionghai Dai},
keywords = {Artificial intelligence, Brain science},
abstract = {Reviewing the history of the development of artificial intelligence (AI) clearly reveals that brain science has resulted in breakthroughs in AI, such as deep learning. At present, although the developmental trend in AI and its applications has surpassed expectations, an insurmountable gap remains between AI and human intelligence. It is urgent to establish a bridge between brain science and AI research, including a link from brain science to AI, and a connection from knowing the brain to simulating the brain. The first steps toward this goal are to explore the secrets of brain science by studying new brain-imaging technology; to establish a dynamic connection diagram of the brain; and to integrate neuroscience experiments with theory, models, and statistics. Based on these steps, a new generation of AI theory and methods can be studied, and a subversive model and working mode from machine perception and learning to machine thinking and decision-making can be established. This article discusses the opportunities and challenges of adapting brain science to AI.}
}
@article{PRINSLOO2021101515,
title = {Sustainability assessment framework and methodology with trans-disciplinary numerical simulation model for analytical floatovoltaic energy system planning assessments},
journal = {Sustainable Energy Technologies and Assessments},
volume = {47},
pages = {101515},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101515},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821005269},
author = {F.C. Prinsloo and Peter Schmitz and Andrea Lombard},
keywords = {Floatovoltaic system synthesis, WELF-nexus environmental profiling, Sustainability profiling, Floating solar simulation model, FPV sustainability assessment},
abstract = {Floatovoltaics is rapidly emerging as a novel type of sustainable energy technology, in which solar photovoltaic installations are sited directly on open-water spaces. As an agro-renewable energy-generation technology, it makes dual use of water to generate revenue from under-utilised irrigation water surfaces while also offering mutually beneficial layers of land-saving, environmental conservation and water-preservation benefits. Standardised metrics for ground-mounted photovoltaic projects, however, do not properly account for the technology’s extended range of resource-use-efficiencies and impact-effect-positives. Such knowledge gaps hinder evidence-based scientific assessments in regulatory project permissions mandated by law. Technology planning and impact assessment practices can benefit from a computer-aided technique to characterise floatovoltaic performance profiles. This paper introduces a conceptual empirical modelling framework, a holistic system dynamics-thinking methodology and a computer synthesis model to empirically predict the performance and sustainability profiles of prospective floatovoltaic installations. By inherently exploring the techno-economic and techno-environmental externalities of floatovoltaic enterprises, it translates performance profiles into sustainability indicators, articulated as WELF-nexus parameters. The paper details the integrated analytical framework, mathematical modelling formulation and digital computer synthesis model towards quantitative floatovoltaic energy system planning and sustainability assessments. The study’s main finding is that an integrated techno-enviro-economic floatovoltaic assessment methodology can be successfully modelled as a context-sensitive synthesis technique in a system dynamics modelling environment. The proposed technique can find utility in solving real-world problems with assessments in efficiency, feasibility and sustainability for agricultural floatovoltaics.}
}
@article{DING2024120338,
title = {Next generation of computer vision for plant disease monitoring in precision agriculture: A contemporary survey, taxonomy, experiments, and future direction},
journal = {Information Sciences},
volume = {665},
pages = {120338},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120338},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524002512},
author = {Weiping Ding and Mohamed Abdel-Basset and Ibrahim Alrashdi and Hossam Hawash},
keywords = {Computer vision, Deep learning, Convolutional neural networks (CNNs), Vision transformers, Vision MLPs, Plant recognition, Precision agriculture},
abstract = {Efficient and rational monitoring of plant health is an essential prerequisite for ensuring optimal crop production and resource management in the field of agriculture. Computer vision techniques have revolutionized visual disease monitoring with their exceptional visual recognition performance. However, despite the outstanding results, the widespread acceptance of these methods in agriculture practice is still in its early stages. This study presents a comprehensive survey of the next generation of computer vision models applied to plant disease monitoring in precision agriculture. Our study begins by tracing the evolution of agricultural computer vision research over the past decade, encompassing legacy methods such as convolutional neural networks (CNNs), progressing to newer techniques like vision transformers (ViTs), and culminating in cutting-edge vision multi-layer perceptrons (MLPs). Next, our study embraces both qualitative and quantitative approaches, supporting a profound review of literature and classifying methodologies and experimental approaches. A significant contribution lies in our comprehensive taxonomy, offering a fine-grained categorization of current computer vision models. This taxonomy meticulously highlights the potentials and limitations of these models while explaining their roles in improving plant disease management. Moreover, extensive experimental comparisons are conducted on PlantVillage dataset to evaluate the performance of state-of-the-art computer-vision models for plant recognition data. The obtained results are then utilized to draw insightful conclusions about the behavior of these models and provide guidance for selecting the most suitable one for specific tasks at hand. Additionally, we discuss open research avenues and future directions of computer-vision models in plant disease management including challenges related to the data scarcity, the computational efficiency, need for explainability, and multi-modal analysis.}
}
@article{KUMAR202415,
title = {Hybrid approach of type-2 fuzzy inference system and PSO in asthma disease},
journal = {Clinical eHealth},
volume = {7},
pages = {15-26},
year = {2024},
issn = {2588-9141},
doi = {https://doi.org/10.1016/j.ceh.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2588914124000017},
author = {Tarun Kumar and Anirudh {Kumar Bhargava} and M.K. Sharma and Nitesh Dhiman and Neha Nain},
keywords = {Asthma, Type-2 fuzzy set, Type-2 fuzzy optimized system, Particle swarm optimization, Medical diagnostic},
abstract = {This research work presents a hybrid approach combining a type-2 fuzzy inference system with particle swarm optimization (PSO) to develop a type-2 fuzzy optimized inference system, specifically tailored for asthma patient data. Addressing the inherent uncertainty in medical diagnostics, this model enhances traditional type-1 fuzzy logic by incorporating ambiguity into linguistic variables and utilizing type-2 fuzzy if-then rules. The system is trained to minimize diagnostic error in asthma disease identification. Applied to a dataset comprising eight medical entities from asthma patients, the model demonstrates substantial accuracy improvements. Numerical computations validate the system, showing a decrease in error rate from 1.445 to 0.03, indicating a significant enhancement in diagnostic precision. These results underscore the potential of our model in medical diagnostic problems, providing a novel and effective tool for tackling the complexities of asthma diagnosis.}
}
@article{SHAHIM2021102345,
title = {Security of the digital transformation},
journal = {Computers & Security},
volume = {108},
pages = {102345},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102345},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001693},
author = {Abbas Shahim},
keywords = {Digital transformation, Digital security, Information security, Digital disruption, IT auditing},
abstract = {In the early days of computation the focus was mainly on designing, developing, maintaining, and administering infrastructures and information systems housed in data centers. To this extend, security was traditionally organized around the basic technical components (e.g. data center facilities). The point was that an associated security activity was mostly separated from a business context and in general executed by the technical staff. Security was not fully understood by other audiences because the computer terminologies were frequently used. When security elements (e.g. logical access protocols used for identification, authentication, authorization) became part of the financial statement audit, its context became clearer, and it was conducted for external auditors. However, the presented outcome of the work was not completely interpretable for these practitioners as again, it was mainly reported in Information Technology (IT) jargon, and was not linked with the financial statement either. With the emergence the Sarbanes–Oxley Act (SOX) and the fundamental role of IT in relation hereto, the context of security suddenly changed to a great extent. The audience extended as compliance, including security, became the dominating item on the agenda of many C-levels (e.g. CFOs).}
}
@incollection{BENTHEM1989331,
title = {Semantic Parallels in Natural Language and Computation},
editor = {H.-D. Ebbinghaus and J. Fernandez-Prida and M. Garrido and D. Lascar and M. Rodriquez Artalejo},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {129},
pages = {331-375},
year = {1989},
booktitle = {Logic Colloquium'87},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(08)70133-2},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X08701332},
author = {Johan van Benthem},
abstract = {Publisher Summary
This chapter describes two major themes: (1) techniques for local strengthening of logical inference via minimization of models and (2) the more general dynamics of progressive handling of information in interpretation and argument. The chapter provides a coherent pattern behind some recent developments in these areas and discusses their value as affecting logic in general. The chapter also provides a mathematical analysis of the minimization operator on classes of models while also investigating several special systems in which minimal models play a central role. The chapter develops an analogy with earlier work in the philosophy of science on so-called “Ramsey eliminability” of theoretical terms in scientific theories. A technical connection is found between the general inferential properties of circumscription and more traditional conditional logic. It considers possible reductions of circumscriptive inference to standard first-order logic, establishing a high complexity for the question just when this is possible. The chapter reviews a number of results on dynamical semantics and several reductions of proposed dynamic systems to standard first-order logic. The latter system provides a promising tool for investigating dynamic modes of handling propositions.}
}
@article{DUFVA201917,
title = {Grasping the future of the digital society},
journal = {Futures},
volume = {107},
pages = {17-28},
year = {2019},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302252},
author = {Tomi Dufva and Mikko Dufva},
keywords = {Digitalisation, Digital society, Experiential foresight, Craft education, Art education, Artistic research, Embodied learning, Critical theory},
abstract = {Society is increasingly digitalised and connected, with computers and algorithms mediating much of people’s daily activity in one way or another. The degree of digitalisation and its consequences are challenging to understand because most people lack first-hand experience of what digitalisation actually feels like. Digitalisation is abstract and difficult to grasp, which leads to a detached sense of the digital surroundings. In this paper, we argue that in order to grasp the nature and future of a digitalised society, an embodied understanding of digitalisation is needed. Such an understanding should utilise ways of knowing other than rational thinking, challenge existing narratives and move from preparing for the future to exploring novelty. We focus on the importance of a broader understanding of digitalisation within the field of education and discuss how a more diverse view is essential to empower people to take part in a digitalised society. We use the concept of ‘digi-grasping’ to analyse awareness and involvement in the digital world. By digi-grasping we mean active sense-making and existing in a world that consists of both a digital and a physical world. We argue that through ‘grasping’ the digital world it is possible to create an ethical and aesthetic attachment to society. Digi-grasping can empower people to understand and question the choices and motivations behind current digital structures and create new structures. It is thus an important approach to shaping the futures of digital society. We illustrate the concept with examples representing different modes of being and doing at the interface of the digital and physical.}
}
@article{ALHARRASI201958,
title = {Evidence for the involvement of a GABAergic mechanism in the effectiveness of natural and synthetically modified incensole derivatives in neuropharmacological disorders: A computational and pharmacological approach},
journal = {Phytochemistry},
volume = {163},
pages = {58-74},
year = {2019},
issn = {0031-9422},
doi = {https://doi.org/10.1016/j.phytochem.2019.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0031942218308239},
author = {Ahmed Al-Harrasi and Ajmal Khan and Najeeb Ur Rehman and Sulaiman Al-Shidhani and Nasiara Karim and Imran Khan and Sobia Ahsan Halim and Ahmed Al-Rawahi and Javid Hussain and Rene Csuk},
keywords = {Incensole, Incensone, Incensfuran, Antidepressant, Anxiolytic, Anticonvulsant, Homology modelling, Molecular docking, ADMET prediction},
abstract = {In the course of our continuing exploration for novel bioactive lead compounds (s) from the species Boswellia, we have recently reported incensole derivatives isolated from Boswellia papyrifera Hochst. Given the known antidepressant-like effects of incensole and incensole acetate, we herein present that the low dose intraperitoneal administration of incensole derivatives, namely, incensfuran and incensone, showed significant antidepressant-like effects in the forced swim test (FST) and tail suspension test (TST). Furthermore, these compounds were evaluated for their anxiolytic potential in the elevated plus maze (EPM) and light dark box (LDB) tests and anticonvulsant effects in pentylenetetrazole (PTZ)-induced seizure tests. In the EPM test, administration of these compounds led to dose-dependent increases in open arm entries and in the time spent in EPM open arms. Similar results were obtained in the LDB test, wherein compounds these caused significant increases in the number of transitions between lit and dark compartments and the time spent in the lit compartment. The anxiolytic-like effects in the EPM were not reversed by pretreatment with flumazenil, whereas PTZ and bicuculline (BIC) completely abolished the anxiolytic effects, showing the involvement of the non-benzodiazepine binding sites of GABAA receptors. All four compounds induced significantly elevated brain GABA levels, indicating the involvement of a GABAergic mechanism. Additionally, molecular docking was conducted to elucidate the mode of action for the anxiolytic and anticonvulsant effects of these derivatives. Moreover, these compounds also possess drug-like properties and excellent ADMET profiles.}
}
@article{FEIZABADI2024103461,
title = {When and under what conditions ambidextrous supply chains prove effective? Insights from simulation and empirical studies},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {183},
pages = {103461},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103461},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524000516},
author = {Javad {Feiz Abadi} and David M. Gligor and Somayeh {Alibakhshi Motlagh} and Raj Srivastava},
keywords = {Supply Chain Archetype, Ambidexterity, NK modeling, Paradoxes},
abstract = {Our research delves into the impact of ambidextrous supply chain activity configurations on performance, particularly in the dynamic and complex contexts of today's business landscape. Drawing from the rich literature on paradox theory, we aim to unravel the efficacy of ambidextrous supply chain setup in mitigating the tensions inherent in managing dynamism, complexities, munificence, and, as well as understanding the contextual factors that modulate this efficacy. To accomplish this, we construct a computational model that captures the resource allocation and search behavior of the ambidextrous supply chain archetype within the ever-shifting terrain of performance. Our findings reveal that ambidextrous supply chain configurations excel at reconciling paradoxical tensions stemming from high complexity, limited resource abundance, and turbulent market conditions. Empirical data substantiate these findings.}
}
@incollection{MOITRA198793,
title = {Parallel Algorithms for Some Computational Problems},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {26},
pages = {93-153},
year = {1987},
booktitle = {Advances in Computers},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60006-6},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808600066},
author = {Abha Moitra and S. {Sitharama Iyengar}},
abstract = {Publisher Summary
The chapter presents a survey of parallel algorithms for finding the connected and biconnected components of a graph. The chapter classifies the various parallel algorithms for finding the connected components of undirected graphs according to two major criteria: the basic technique employed and the format of the input. The basic techniques used in these algorithms are breadth-first search, transitive closure, and vertex collapse. The most common form of input is adjacency matrix. The chapter presents several parallel minimum spanning tree algorithms for different types of parallel computational models. A minimum spanning tree of a weighted, connected, and undirected graph is defined as a set of edges of the graph that connects all vertices and whose total edge weight is minimum. The chapter discusses various other parallel graph algorithms for shortest path, maximum matching, planarity testing, and maximal independent set. It describes parallel algorithms for various nongraph-theoretic problems like arithmetic expression and polynomial evaluation, string matching, tree balancing, and alpha-beta search.}
}
@article{LIU2023100050,
title = {Literature review of digital twin technologies for civil infrastructure},
journal = {Journal of Infrastructure Intelligence and Resilience},
volume = {2},
number = {3},
pages = {100050},
year = {2023},
issn = {2772-9915},
doi = {https://doi.org/10.1016/j.iintel.2023.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2772991523000257},
author = {Cheng Liu and Peining Zhang and Xuebing Xu},
keywords = {Digital Twin, Civil Infrastructure, Bridges, High-speed Railway},
abstract = {Currently, there are numerous drawbacks associated with infrastructure health monitoring and management, such as inefficiency, subpar real-time functionality, demanding data requirements, and high cost. Digital twin (DT), a hybrid of a computational simulation and an actual physical system, has been proposed to overcome these challenges and become increasingly popular for modeling civil infrastructure systems. This literature review summarized different methods to build digital twins in civil infrastructure. In addition, this review also introduced the current progress of digital twins in different infrastructure sectors, including smart cities and urban spaces, transport systems, and energy systems, along with detailed examples of their various applications. Finally, the current challenges in digital twin technologies for civil infrastructure are also highlighted.}
}
@article{CHAIARWUT2025101338,
title = {Enhancing executive mathematics problem-solving through a constructivist digital learning platform: Design, development and evaluation},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101338},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101338},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000658},
author = {Supaluk Chaiarwut and Sanit Srikoon and Apirat Siritaratiwat and Parama Kwangmuang},
keywords = {Learning innovation, Digital platform, Mathematics problem solving},
abstract = {Recent international assessments have highlighted a global decline in mathematics performance, particularly among students in Thailand. This study aims to (1) design and evaluate a constructivist learning innovation model on a digital platform that promotes executive mathematics problem-solving and (2) develop and assess a prototype based on the designed model. A mixed-method research design was employed across two phases. Phase 1 involved designing and evaluating the learning model through document analysis and expert validation (n = 9). Phase 2 focused on developing and testing a prototype with experts (n = 15) and students (n = 30). Data collection utilized the Index of Item-Objective Congruence (IOC), System Usability Scale (SUS), and User Engagement Scale (UES). The model showed strong alignment with theoretical principles (IOC = 0.84). The prototype showed excellent usability (SUS = 91.0/100) and high engagement (UES = 4.26/5.00). Expert evaluations indicated high quality in content (M = 4.47, SD = 0.48), media (M = 4.40, SD = 0.50), and innovation design (M = 4.59, SD = 0.64). The findings validate the model's efficacy in promoting executive mathematics problem-solving skills through a constructivist digital platform approach.}
}
@article{SANGA2025104241,
title = {Stories, simulations and narratives: Collaboratively exploring food security and agricultural innovation in sub-Saharan Africa},
journal = {Agricultural Systems},
volume = {224},
pages = {104241},
year = {2025},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2024.104241},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X24003913},
author = {Udita Sanga and Maja Schlüter},
keywords = {Food security, Narratives, Storytelling, Sub-Saharan Africa, Agent-based models},
abstract = {CONTEXT
Food insecurity remains a global challenge, with differing narratives shaping interventions in sub-Saharan Africa. The “crisis narrative,” favored by aid agencies, links insecurity to production issues, advocating agricultural innovations. Meanwhile, the “chronic poverty narrative,” reflected in African policy, ties insecurity to farmer poverty, emphasizing livelihood and economic solutions. Narrative subjectivity can lead to uncritical privileging of certain understandings and solutions, necessitating a critical exploration of contexts, causes, and solutions to food insecurity in the region. Our research addresses the need to understand and illustrate the complex problem of food insecurity in the region.
OBJECTIVE
This study employs a mixed-method approach, combining collaborative storytelling, model exploration, and scenario analysis, to investigate food security, agricultural innovation, and climate adaptation in Mali, West Africa.
METHODS
We developed a three-stage methodology represented as a story arc: beginning (exposition and problem statement), development (action), and completion (solution), providing a cohesive narrative framework. The arc unfolds with the story exposition introducing characters, plot, and problem statement. The story development includes participant-led model simulations and modeler-led scenario analysis. The story completion integrates insights from model simulations and scenario analysis to develop the collective understanding of the narratives surrounding food (in)security.
RESULTS AND CONCLUSIONS
This study generates several insights that highlight the inherent complexities within agricultural innovation systems that emerge from the non-linear dynamic interaction of actors operating across scales that contribute to food insecurity. We redirect the focus of narratives of causes (and subsequent solutions) of food insecurity from solely climate-driven production losses and poverty to the complex interplay of climate, agroecology, innovation networks, risk perception, innovation beliefs, desires, and knowledge transmission. A shared narrative emerges, characterizing food security as a complex adaptive system influenced by factors such as climate-induced production variability, agroecological heterogeneity, network structures and climate risk perception. The study underscores the methodological value of collaborative storytelling and model simulation to enable a structured and reflective exploration of these complex systems. By transforming participants into co-creators of knowledge, this methodology fosters systems thinking, turning abstract systemic relationships into tangible, actionable insights.
SIGNIFICANCE
Our study demonstrates the need to critically reevaluate the role of narratives in shaping agricultural innovation systems and their capacity to transform food systems toward enhanced sustainability and food security. Our participatory and systems-driven approach offers a pathway to more adaptive and effective interventions in the face of complex, dynamic challenges.}
}
@article{SHIEH1993421,
title = {Massively parallel computational methods for finite element analysis of transient structural responses},
journal = {Computing Systems in Engineering},
volume = {4},
number = {4},
pages = {421-433},
year = {1993},
note = {Parallel Computational Methods for Large-Scale Structural Analysis and Design},
issn = {0956-0521},
doi = {https://doi.org/10.1016/0956-0521(93)90011-K},
url = {https://www.sciencedirect.com/science/article/pii/095605219390011K},
author = {R.C. Shieh},
abstract = {With the emphasis on the finitely damped system (e.g. control structure interaction) case, two fully implicit and two semi-implicit sets of finite element method-based numerical algorithms are formulated for transient response analysis of space frame and truss structures in a massively parallel processing (MPP) environment. All algorithm sets use an implicit force calculation/vector equation of motion assembly procedure. The semi-implicit algorithms are based on the explicit central difference (CD) and the fourth-order Runge-Kutta (RK4) schemes, respectively, in conjunction with the use of mass lumping techniques so that solution of the recurrence equations for unknown displacements is reduced to a trivial diagonal matrix inversion operation. The fully implicit algorithm sets are based on the Newmark Beta (NB) and CD schemes, respectively, in conjunction with use of the (iterative) preconditioned conjugate gradient (PCG) method for solving the linear algebraic recurrence equations. The semi-implicit algorithm sets are fully implemented and assessed on an MPP CM-2 computer. A preliminary assessment of the fully implicit sets of algorithms is made on a Sun Workstation. These numerical study results show that the newly formulated MPP algorithms are, to a varying degree, superefficient (or potentially superefficient) on the CM-2 compared with, and even highly competitive against, the conventional sequential algorithms on an advanced serial computer.}
}
@article{JIN202520,
title = {Methods and reliability study of moral education assessment in universities: A machine learning-based approach},
journal = {Alexandria Engineering Journal},
volume = {125},
pages = {20-28},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.03.095},
url = {https://www.sciencedirect.com/science/article/pii/S111001682500403X},
author = {Ting Jin},
keywords = {Reliability study, Moral education, Machine learning, Policy analysis, Statistical analysis},
abstract = {The research aims to assess the effectiveness of machine learning (ML) techniques in evaluating moral education programs at university institutions. The objective is to employ data-driven methodologies to enhance ethical assessment frameworks through improved objectivity, scalability, and consistency. This analysis utilizes Principal Component Analysis (PCA) alongside the k-Nearest Neighbor (k-NN) method, Support Vector Regression (SVR), and Artificial Neural Networks (ANN) to study student performance indices, enabling the prediction of ethical reasoning capabilities for standardized evaluation. The study demonstrates how machine learning efficiently assesses student moral education performance by leveraging PCA to identify patterns and using ML models to make accurate predictions. Findings reveal a strong correlation between subject proficiency in mathematics, reading, and writing and moral reasoning abilities, highlighting the role of academic competencies in ethical decision-making. Additionally, gender-based analysis indicates that female students tend to achieve better results in moral skills assessments than their male counterparts. Among the models tested, SVR exhibits the highest predictive accuracy, whereas k-NN returns the widest prediction errors. The study recommends the deployment of AI-based moral assessment systems in universities to ensure consistent and objective evaluation processes for policy development.}
}
@article{RIZZOLATTI1997562,
title = {Parietal cortex: from sight to action},
journal = {Current Opinion in Neurobiology},
volume = {7},
number = {4},
pages = {562-567},
year = {1997},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(97)80037-2},
url = {https://www.sciencedirect.com/science/article/pii/S0959438897800372},
author = {Giacomo Rizzolatti and Leonardo Fogassi and Vittorio Gallese},
abstract = {Recent findings have altered radically our thinking about the functional role of the parietal cortex. According to this view, the parietal lobe consists of a multiplicity of areas with specific connections to the frontal lobe. These areas, together with the frontal areas to which they are connected, mediate distinct sensorimotor transformations related to the control of hand, arm, eye or head movements. Space perception is not unitary, but derives from the joint activity of the fronto-parietal circuits that control actions requiring space computation.}
}
@article{ZHANG20162579,
title = {Efficient vehicles path planning algorithm based on taxi GPS big data},
journal = {Optik},
volume = {127},
number = {5},
pages = {2579-2585},
year = {2016},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2015.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0030402615019075},
author = {Jindong Zhang and Weibin Meng and QiangQiang Liu and Haofeng Jiang and Yujie Feng and Gang Wang},
keywords = {Taxi GPS trajectory, Big data, Driving stratagem, Map matching, Optimal path},
abstract = {The driving thinking of taxi drivers is always hidden in a large amount of taxis GPS data. An efficient driving stratagem derived from taxi drivers is provided for private car drivers. The five million pieces of taxis GPS data in Nanjing, China are analyzed: firstly, the data preprocessing is conducted for the reduction measuring error of GPS data with the expurgation of the static point, the drifting point, and the relatively independent point; then, the road intersections through the regional extreme points are found to restore map with the following three algorithms: the path selection algorithm based on probability, the improved Prim path selection algorithm, and the improved Prim path selection algorithm based on probability; at last, the SPFA (Shortest Path Faster Algorithm) is applied to the measurement of the road map gained from the previous three algorithms for optimal path planning with 40 pairs of starting points and termination points, and making a comparison of the road length among three methods. Through the experimental comparison, the third method namely the improved Prim path selection algorithm based on probability which proved to be more optimal than others two methods produces an efficient driving route more accurately.}
}
@article{RUSSELL2018114,
title = {Leveraging complexity for ecosystemic innovation},
journal = {Technological Forecasting and Social Change},
volume = {136},
pages = {114-131},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517316475},
author = {Martha G. Russell and Nataliya V. Smorodinskaya},
keywords = {Business network, Collaboration, Complexity, Innovation ecosystem, Innovation cluster, Global economy, Non-linearity},
abstract = {This paper looks at innovation ecosystems through the lens of complexity science, considering them as open non-linear entities that are characterized by changing multi-faceted motivations of networked actors, high receptivity to feedback, and persistent structural transformations. In the context of the growing organizational complexity of economies, driven by their adaptation to high uncertainty, and the central role of collaboration, we differentiate the innovation capacity of various types of business networks by the complexity of their internal interactions, thus identifying the place of innovation ecosystems in the world of business networks, as well as the place of innovation clusters among other innovation ecosystems. We observe how innovation ecosystems have been viewed in four different research streams: management literature; the inter-firm and business network stream of economic and sociological literature; the innovation policy and competitiveness agenda in economic literature; and the dichotomy of localized and economy-wide innovation ecosystems in policy studies (in economic literature, evolutionary geography, and regional research). We then describe generic properties of innovation ecosystems in terms of complexity science, viewing them as complex adaptive systems, paying special attention to the complexity of innovation clusters. We compare complexity thinking of modern economies, deriving from their emerging ecosystem design, with traditional thinking conceived for industrial era, drawing insights for a better transition to innovation-led growth. We conclude with a summary of key findings, practical and policy implications and recommendations for further study.}
}
@article{BOGGS19831,
title = {The integration of structure determination by computation, electron diffraction and microwave spectroscopy},
journal = {Journal of Molecular Structure},
volume = {97},
pages = {1-16},
year = {1983},
note = {Determination of Molecular Structure by Microwave Spectroscopy and Electron Diffraction},
issn = {0022-2860},
doi = {https://doi.org/10.1016/0022-2860(83)90171-0},
url = {https://www.sciencedirect.com/science/article/pii/0022286083901710},
author = {James E. Boggs},
abstract = {The history of the interaction between experimental structure determinations by microwave spectroscopy and by gas phase electron diffraction is briefly reviewed in terms of three eras: (1) competition and antagonism, (2) comparison and correction, and (3) integration of analysis. A similar progression is noted for the relation between experimental and theoretical methods for studying molecular structure, with the present time straddling ages (2) and (3). Examples are given from a variety of studies involving various degrees of methodological interaction. The true integration of experimental and computational structural studies is still in its infancy with the primary illustrations involving the evaluation of theoretical structural offset values from experimental evidence, the transfer of theoretically determined parameters into the fitting of experimental data, and the current development of methods for utilizing vibrational information obtained from the combined analysis of computed theoretical and experimental infrared data in the further analysis of experimental diffraction and microwave information.}
}
@article{LAL2023100791,
title = {IOT-based cyber security identification model through machine learning technique},
journal = {Measurement: Sensors},
volume = {27},
pages = {100791},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100791},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423001277},
author = {Bechoo Lal and S. Ravichandran and R. Kavin and N. {Anil Kumar} and Dibyahash Bordoloi and R. {Ganesh Kumar}},
keywords = {Cyber security, Machine learning algorithms, Security, Repositories, Meta-classifier methods, Internet of things},
abstract = {Manual vulnerability evaluation tools produce erroneous data and lead to difficult analytical thinking. Such security concerns are exacerbated by the variety, imperfection, and redundancies of modern security repositories. These problems were common traits of producers and public vulnerability disclosures, which make it more difficult to identify security flaws through direct analysis through the Internet of Things (IoT). Recent breakthroughs in Machine Learning (ML) methods promise new solutions to each of these infamous diversification and asymmetric information problems throughout the constantly increasing vulnerability reporting databases. Due to their varied methodologies, those procedures themselves display varying levels of performance. The authors provide a method for cognitive cybersecurity that enhances human cognitive capacity in two ways. To create trustworthy data sets, initially reconcile competing vulnerability reports and then pre-process advanced embedded indicators. This proposed methodology's full potential has yet to be fulfilled, both in terms of its execution and its significance for security evaluation in application software. The study shows that the recommended mental security methodology works better when addressing the above inadequacies and the constraints of variation among cybersecurity alert mechanisms. Intriguing trade-offs are presented by the experimental analysis of our program, in particular the ensemble method that detects tendencies of computational security defects on data sources.}
}
@article{FITZPATRICK2020101942,
title = {The relation between academic abilities and performance in realistic word problems},
journal = {Learning and Individual Differences},
volume = {83-84},
pages = {101942},
year = {2020},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2020.101942},
url = {https://www.sciencedirect.com/science/article/pii/S1041608020301229},
author = {Cheryll L. Fitzpatrick and Darcy Hallett and Kyle R. Morrissey and Nadine R. Yıldız and Rutanya Wynes and Felix Ayesu},
keywords = {Word problems, Academic abilities, Educational psychology, Math cognition},
abstract = {The research on realistic word problems investigates how children (and even adults) largely fail to incorporate real-world knowledge into mathematical word problems. Because of this, most research in this area focuses on improving realistic thinking. However, very little research has explored what other abilities might predict which children actually do take real-world information into account, and what this might imply about the nature of realistic responding. We tested whether general academic abilities, such as verbal skill, reading comprehension, and math calculation skill, previously shown to be related to standard word problem performance, are related to realistic responses, and whether realistic responding is related to standard word problem solving. In our sample of sixth-grade students, only reading comprehension was independently predictive of solving realistic word problems. Performance on realistic word problems, however, was independently predictive of solving standard word problems. As such, realistic word problems may reflect problem solving ability independent of general academic ability, and therefore may be an ability worth fostering.}
}
@incollection{MENAMADATHIL202463,
title = {Chapter 4 - Machine learning approach for vaccine development-fundamentals},
editor = {Jayashankar Das and Sushma Dave and Siomar de Castro Soares and Sandeep Tiwari},
booktitle = {Reverse Vaccinology},
publisher = {Academic Press},
pages = {63-85},
year = {2024},
isbn = {978-0-443-13395-4},
doi = {https://doi.org/10.1016/B978-0-443-13395-4.00025-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443133954000253},
author = {Dhanalakshmi Menamadathil and Kajari Das and Sushma Dave and Jayashankar Das},
keywords = {Artificial intelligence, machine learning, support vector machine, logistic regression, extreme gradient boosting, convolutional neural network, recurrent neural networks, reverse vaccinology},
abstract = {Artificial intelligence (AI)–assisted vaccine creation has emerged as a significant development among the cutting-edge technologies that will help society in the 21st century. AI and machine learning technologies have brought answers to issues that have arisen as a result of the advent of recurring and emerging infectious diseases and the rise in antibiotic resistance. The rapid discovery of effective vaccines has been crucial in preparation for outbreaks, including epidemics and pandemics. The urgent requirement for precise vaccine creation in a short duration has led the way for researchers to investigate diverse vaccine-development technologies such as computational biology, structure-based antigen design, protein engineering, gene synthesis, and novel manufacturing platforms, With the advent of whole-genome sequencing and big data analytic platforms aided by AI, omics-based vaccine design has emerged, which is also known as reverse vaccinology (RV). RV accomplishes comprehensive immunogenicity profiling employing proteome and structural data. With the advancement of AI and deep learning algorithms, a range of modeling tools for accurate and precise prediction of immune-recognition patterns have been created, which may be utilized to generate novel vaccine candidates. Given that vaccinations are available for a few infectious illnesses, there is an urgent need for the quick development of vaccines for numerous lethal and developing infections, which can give prominence to RV. Within the course of this chapter, a thorough view of AI -employed algorithms and their role in RV is offered, with a particular emphasis on immunoinformatic and AI methods utilized in it.}
}
@article{SHARMA2024100944,
title = {Towards intelligent industrial systems: A comprehensive survey of sensor fusion techniques in IIoT},
journal = {Measurement: Sensors},
volume = {32},
pages = {100944},
year = {2024},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100944},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423002805},
author = {Deepak sharma and Anuj kumar and Nitin Tyagi and Sunil S. Chavan and Syam Machinathu Parambil Gangadharan},
keywords = {Sensor fusion, Machine learning, Fault tolerance, Fault prediction, Neural network},
abstract = {Industrial Internet of Things (IIoT) is systems aim to facilitate human monitoring and the direction of efficient production of goods in industrial settings by linking a wide variety of intelligent devices such as sensors, actuators, and controllers. This is achieved by utilizing Internet of Things (IoT) to diagnose a problem with a specific IIoT part is to employ a basic diagnostic technique that's based on models and data. Physical models, signal patterns, and machine-learning strategies must be adequately built to account for system challenges. Another factor that could lead to an exponential rise in complexity is the ever-increasing interconnections between different electronic hardware. The knowledge-based defect diagnosis methods boost interoperability in the operation. Users don't need to be experts in the field to benefit from the system's high-level thinking and response to their queries. So, in advanced IIoT systems, a knowledge-based fault diagnostic approach is favored over traditional model-based and data-driven diagnosis methods. The goal of this study is to evaluate recent improvements in the design of knowledge-based defect detection in the context of IIoT systems, deductive and inductive reasoning, and many other forms of logical reasoning. IIoT-based systems have revolutionized industrial settings by connecting intelligent devices such as sensors, actuators, and controllers to enable efficient production and human monitoring. In this survey paper, we explore machine learning-based sensor fusion techniques within the realm of Industrial Internet of Things (IIoT), addressing critical challenges in fault detection and diagnosis.}
}
@article{OLMEDO2015115,
title = {Quantitative characterization of chaordic tourist destination},
journal = {Tourism Management},
volume = {47},
pages = {115-126},
year = {2015},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2014.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0261517714001812},
author = {Elena Olmedo and Ruth Mateos},
keywords = {Complexity, Chaos, Chaordic system, Tourism Arrivals},
abstract = {This paper highlights the new horizons opening with the applications of concepts from the application of the complexity science to tourism data, which are traditionally treated from an intradisciplinar point of view. From this new point of view, tourism is considered as a complex adaptive system. Complexity theory is rooted in the hard sciences, and social sciences have adopted it in recent times. Going a step further, we introduce the concept of chaordic system in tourism. This new thinking has appeared in the social sciences as a response to the current need to cope with contradictions and inconsistencies, adapting evolution without losing essence. We propose considering tourism as a chaordic system and analyzing the resulting managerial consequences. We propose the use of a set of measures to quantify a system as chaordic. Finally, we empirically analyze tourist arrivals to Majorca (Spain) to verify the existence of a chaordic system.}
}
@article{GRIFFEN20208695,
title = {Chemists: AI Is Here; Unite To Get the Benefits},
journal = {Journal of Medicinal Chemistry},
volume = {63},
number = {16},
pages = {8695-8704},
year = {2020},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.0c00163},
url = {https://www.sciencedirect.com/science/article/pii/S1520480420001672},
author = {Edward J. Griffen and Alexander G. Dossetter and Andrew G. Leach},
abstract = {The latest developments in artificial intelligence (AI) have arrived into an existing state of creative tension between computational and medicinal chemists. At their most productive, medicinal and computational chemists have made significant progress in delivering new therapeutic agents into the clinic. However, the relationship between these communities has the prospect of being weakened by application of oversimplistic AI methods that, if they fail to deliver, will reinforce unproductive prejudices. We review what can be learned from our history of integrating QSAR and structure-based methods into drug discovery. Now with synthesis and testing available as contract services, the environment for computational innovation has changed and we consider the impact this may have on the relationships in our disciplines. We discuss the current state of interdisciplinary communication and suggest approaches to bring the subdisciplines together in order to improve computational medicinal chemistry and, most importantly, deliver better medicines to the clinic faster.
}
}
@article{GINEITYTE1999205,
title = {On the future of the Hückel model},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {491},
number = {1},
pages = {205-209},
year = {1999},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(99)00116-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128099001165},
author = {V. Gineityte},
keywords = {Basis orbitals, Hückel model, Hamiltonian matrix},
abstract = {In an attempt to foresee the prospects of the qualitative trend in quantum chemistry, the place of the Hückel model is analyzed in the broad context of quantum mechanical and chemical perspectives on the molecular world. Quantum mechanics and chemistry are considered as complementary approaches to molecular structure and properties that are irreducible one to another. Arguments are given for the hypothesis that the Hückel model makes a separate level of investigation of molecules situated in between quantum mechanics and chemistry. In this context, the need is emphasized for development of new concepts immanent in the very Hückel model. These concepts are anticipated to play the role of terms for qualitative orbital thinking, the persistent need for which was emphasized recently (R. Hoffmann, J. Mol. Struct. (Theochem), 424 (1998) 1).}
}
@article{ZONG2024120192,
title = {Parameter estimation of multivariable Wiener nonlinear systems by the improved particle swarm optimization and coupling identification},
journal = {Information Sciences},
volume = {661},
pages = {120192},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120192},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524001051},
author = {Tiancheng Zong and Junhong Li and Guoping Lu},
keywords = {System identification, Multivariable Wiener system, Particle swarm optimization, Coupling identification, Auxiliary model},
abstract = {This paper investigates the parameter estimation of multivariable Wiener nonlinear systems. To solve the inconsistency problem of the parameter vector and the parameter matrix, the coupling identification concept is applied. Combined with particle swarm optimization (PSO) and an auxiliary model, the partially coupled improved particle swarm optimization (PC-IPSO) method is proposed. In this algorithm, the adaptive feedback inertia weight is improved to accelerate the convergence speed, and the retirement update mechanism is introduced to improve the optimization ability of the basic PSO algorithm. To verify the performance of PC-IPSO, we also derive a multivariable improved PSO (M-IPSO) method for comparison. The computational complexity analysis shows that the PC-IPSO algorithm requires less computational resources than the M-IPSO algorithm. Then, the convergence of the improved PSO method is analyzed. The simulation results indicate that the PC-IPSO method has a faster convergence speed and higher identification accuracy than the M-IPSO and several existing state-of-the-art methods for multivariable Wiener system identification.}
}
@article{LOWRIE20112244,
title = {Gender differences in students’ mathematics game playing},
journal = {Computers & Education},
volume = {57},
number = {4},
pages = {2244-2248},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511001394},
author = {Tom Lowrie and Robyn Jorgensen},
keywords = {Gender studies, Elementary education, Pedagogical issues, Numeracy practices},
abstract = {The investigation monitored the digital game-playing behaviours of 428 primary-aged students (aged 10–12 years). Chi-square analysis revealed that boys tend to spend more time playing digital games than girls while boys and girls play quite different game genres. Subsequent analysis revealed statistically significant gender differences in terms of the types of mathematics-rich games students prefer to play. Girls preferred to play games that required problem solving, quantitative computations and the interpretation of graphs. Boys preferred games that required visual/spatial engagement. Given the fact that boys outperform girls on spatial tasks and mathematics assessment items that contain graphics, this study has implications for the development of students' mathematics sense making.}
}
@article{NAKAMURA20091639,
title = {A shift of mind – Introducing a concept creation model},
journal = {Information Sciences},
volume = {179},
number = {11},
pages = {1639-1646},
year = {2009},
note = {Including Special Issue on Chance Discovery},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508004933},
author = {Jun Nakamura and Yukio Ohsawa},
keywords = {Creativity, Concept, Ambiguity and constraint},
abstract = {The ability to construct concepts is indispensable to both individual and evolutionary development. Our model involves the use of ambiguous stimuli to facilitate decision-making by promoting analogical reasoning. Toward this end, we have developed Web-based exercises in word categorization for the purpose of engaging participants in analogical reasoning that contributes to the integration of words and leads to the construction of new concepts. 12 graduate students and 20 junior high school students were presented with ambiguous information for the purpose of comparison between the senior and the junior students. We hypothesized that the senior students tend to behave with more insight rather than junior students with less activation of thought process. Our results suggested that the presentation of the ambiguous stimuli were associated with unique thought processes, which are consistent with approaches to word categorization that reflect either the experience of insight or the operation of a trial and error strategy, depending on the junior or the senior students. We showed that the senior students tend to be more like insight into categorization design, while the junior as rather try and error behavior, in consideration of needed time and actions in analogical thinking.}
}
@article{BARRON1992245,
title = {A bibliography on computational molecular biology and genetics},
journal = {Mathematical and Computer Modelling},
volume = {16},
number = {6},
pages = {245-319},
year = {1992},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(92)90166-I},
url = {https://www.sciencedirect.com/science/article/pii/089571779290166I},
author = {Sarah Barron and Matthew Witten and Gongxian Liu},
abstract = {The field of computational molecular biology and genetics is expanding at an enormous rate. Journals such as CABIOS and Nucleic Acids Research routinely publish articles on computational and mathematical aspects of biology. The purpose of this paper is to provide a bibliographic review of the literature in this area related to DNA mapping and sequence analysis. We have focused on computer and mathematical aspects of molecular biology and genetics (interpreted in a broad sense). Authors are solicited for their additions/corrections to this bibliography. Contact us at the above address.}
}
@article{LEIVANT198651,
title = {Typing and computational properties of lambda expressions},
journal = {Theoretical Computer Science},
volume = {44},
pages = {51-68},
year = {1986},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(86)90109-X},
url = {https://www.sciencedirect.com/science/article/pii/030439758690109X},
author = {Daniel Leivant},
abstract = {We use a perception of second-order typing in the λ-Calculus, as conveying semantic properties of expressions in models over λ-expressions, to exhibit natural and uniform proofs of theorems of Girard (1971/1972) and of Coppo, Dezani and Veneri (1981) about the relations between typing properties and computational properties of λ-expressions (solvability, normalizability, strong normalizability), and of some generalizations of these theorems.}
}
@article{BOEING2021102013,
title = {Spatial information and the legibility of urban form: Big data in urban morphology},
journal = {International Journal of Information Management},
volume = {56},
pages = {102013},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302154},
author = {Geoff Boeing},
keywords = {OpenStreetMap, Urban design, Urban form, Urban morphology, Urban planning, Visualization},
abstract = {Urban planning and morphology have relied on analytical cartography and visual communication tools for centuries to illustrate spatial patterns, conceptualize proposed designs, compare alternatives, and engage the public. Classic urban form visualizations – from Giambattista Nolli’s ichnographic maps of Rome to Allan Jacobs’s figure-ground diagrams of city streets – have compressed physical urban complexity into easily comprehensible information artifacts. Today we can enhance these traditional workflows through the Smart Cities paradigm of understanding cities via user-generated content and harvested data in an information management context. New spatial technology platforms and big data offer new lenses to understand, evaluate, monitor, and manage urban form and evolution. This paper builds on the theoretical framework of visual cultures in urban planning and morphology to introduce and situate computational data science processes for exploring urban fabric patterns and spatial order. It demonstrates these workflows with OSMnx and data from OpenStreetMap, a collaborative spatial information system and mapping platform, to examine street network patterns, orientations, and configurations in different study sites around the world, considering what these reveal about the urban fabric. The age of ubiquitous urban data and computational toolkits opens up a new era of worldwide urban form analysis from integrated quantitative and qualitative perspectives.}
}
@incollection{VHORA2024709,
title = {Investigating Fluid Flow Dynamics in Triply Periodic Minimal Surfaces (TPMS) Structures Using CFD Simulation},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {709-714},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50119-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443288241501198},
author = {Kasimhussen Vhora and Tanya Neeraj and Dominique Thévenin and Gábor Janiga and Kai Sundmacher},
keywords = {Computational Fluid Dynamic, TPMS Structure, Pressure Drop, LBM},
abstract = {Efficient absorption processes require optimized packed bed column structures, which affect gas-liquid contact, flow distribution, and pressure drop. An optimal setup ensures efficient mass transfer with high surface area while keeping down the pressure drop, which leads to energy savings and better absorption. TPMS structures such as the Gyroid, Schwarz-P, and Schwarz-D were investigated in this study, with a focus on balancing porosity and surface area to achieve reduced pressure drops and optimal phase contact. Single-phase flow simulations were conducted using the commercial software STAR- CCM+, compared to the lattice Boltzmann method (LBM) to provide an alternative perspective on fluid dynamics. Validation, analysis of the results and identification of possible improvements were achieved through these comparisons. According to the results, the Schwarz-D structure with 70% porosity and 2 mm unit cell leads to the best performance, exhibiting a pressure drop of 655 Pa m-1 and a specific surface area of 1776 m2 m-3 when analysed with STAR-CCM+. The predicted pressure drop was successfully confirmed using LBM simulations, adding robustness to the findings.}
}
@article{LI2025125605,
title = {Traffic scenario frozen callback and adaptive neuro-fuzzy inference system based energy management strategy for connected fuel cell buses},
journal = {Applied Energy},
volume = {387},
pages = {125605},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.125605},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925003356},
author = {Menglin Li and Haoran Liu and Mei Yan and Boyu Guo and Jingda Wu and Guokai Jiang and Xupeng Fu},
keywords = {Connected fuel cell bus, Energy management strategy, Traffic scenario frozen callback, Adaptive neuro-fuzzy inference system},
abstract = {Exploring the full potential of energy savings for new energy vehicles in a future connected transportation system is a challenging task. To address how connected buses can leverage surrounding traffic information to improve their energy efficiency, an intelligent fuel cell bus energy management method based on traffic scenario frozen callback is proposed， which enables high real-time performance in online energy management. To tackle the issue of inconsistent data dimensions caused by random fluctuations in the number of vehicles in a fixed traffic flow, a traffic flow representation based on grid grayscale images is designed. Building upon this representation, a speed trajectory prediction model based on traffic scenario frozen callback is developed. Subsequently, offline historical global optimal data are used to construct a training dataset that links speed trajectories to optimal control sequences. An end-to-end energy management framework based on the adaptive neuro-fuzzy inference system (ANFIS) is presented and validated in scenarios that before entering bus station and after exiting bus station. Simulation results demonstrate that, the proposed energy management strategy (EMS) approaches the overall energy consumption of dynamic programming (DP), reaching 97.76 % and 98.82 % in the two kinds of scenarios of its performance, outperforms the other two comparative EMSs. In terms of timeliness, the computational time spent by the proposed EMS is only 0.2076 times and 0.1952 times that of traditional model predictive control (MPC)-based EMS in the separate scenario.}
}
@article{FURNARI2023103763,
title = {Streaming egocentric action anticipation: An evaluation scheme and approach},
journal = {Computer Vision and Image Understanding},
volume = {234},
pages = {103763},
year = {2023},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2023.103763},
url = {https://www.sciencedirect.com/science/article/pii/S1077314223001431},
author = {Antonino Furnari and Giovanni Maria Farinella},
keywords = {Action anticipation, Egocentric vision, Streaming perception},
abstract = {Egocentric action anticipation aims to predict the future actions the camera wearer will perform from the observation of the past. While predictions about the future should be available before the predicted events take place, most approaches do not pay attention to the computational time required to make such predictions. As a result, current evaluation schemes assume that predictions are available right after the input video is observed, i.e., presuming a negligible runtime, which may lead to overly optimistic evaluations. We propose a streaming egocentric action evaluation scheme which assumes that predictions are performed online and made available only after the model has processed the current input segment, which depends on its runtime. To evaluate all models considering the same prediction horizon, we hence propose that slower models should base their predictions on temporal segments sampled ahead of time. Based on the observation that model runtime can affect performance in the considered streaming evaluation scenario, we further propose a lightweight action anticipation model based on feed-forward 3D CNNs which is optimized using knowledge distillation techniques with a novel past-to-future distillation loss. Experiments on the three popular datasets EPIC-KITCHENS-55, EPIC-KITCHENS-100 and EGTEA Gaze+ show that (i) the proposed evaluation scheme induces a different ranking on state-of-the-art methods as compared to classic evaluations, (ii) lightweight approaches tend to outmatch more computationally expensive ones, and (iii) the proposed model based on feed-forward 3D CNNs and knowledge distillation outperforms current art in the streaming egocentric action anticipation scenario.}
}
@article{ANDROUTSOPOULOS2023141,
title = {Punctuating the other: Graphic cues, voice, and positioning in digital discourse},
journal = {Language & Communication},
volume = {88},
pages = {141-152},
year = {2023},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2022.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530922000957},
author = {Jannis Androutsopoulos},
keywords = {Voice, Positioning, Graphic cues, <!!1!>, Reddit, Punctuation},
abstract = {This article investigates the nested relationship between graphic cues, voice, and positioning in digital discourse. The focus is on the ‘indignation mark’, or <!!1!>, an allographic sign used in German-language discussion boards on Reddit. The study's theoretical backdrop brings research on graphic practices in digitally-mediated communication into dialogue with sociolinguistic approaches to the enactment of group relations in discourse, in particular double-voicing, stylization, and positioning, thereby aiming to foster theory-building on both sides. Data is extracted from a large German-language forum (‘subreddit’) on Reddit and subjected to computational, sequential, and microlinguistic analysis. The findings show how participants in public online discussions use punctuation signs and other graphic cues to animate voices, i.e. ways of speaking that index recognizable social positions and ideologies; how these stylized voices provide a resource for positioning; and how participants display recognition of and alignment to this feature's indexical meaning. The findings also suggest that the ‘indignation mark’ is part of a wider ecology of graphic cues, which evolve constantly to enable multi-voicedness in public digital discourse. Overall, this paper aims to advance our understanding about how graphic elements of digital discourse are indexically and ideologically connected with positioning activities in online communities of practice.}
}
@article{HALL198939,
title = {Computational approaches to analogical reasoning: A comparative analysis},
journal = {Artificial Intelligence},
volume = {39},
number = {1},
pages = {39-120},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90003-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900039},
author = {Rogers P. Hall},
abstract = {Analogical reasoning has a long history in artificial intelligence research, primarily because of its promise for the acquisition and effective use of knowledge. Defined as a representational mapping from a known “source” domain into a novel “target” domain, analogy provides a basic mechanism for effectively connecting a reasoner's past and present experience. Using a four-component process model of analogical reasoning, this paper reviews sixteen computational studies of analogy. These studies are organized chronologically within broadly defined task domains of automated deduction, problem solving and planning, natural language comprehension, and machine learning. Drawing on these detailed reviews, a comparative analysis of diverse contributions to basic analogy processes identifies recurrent problems for studies of analogy and common approaches to their solution. The paper concludes by arguing that computational studies of analogy are in a state of adolescence: looking to more mature research areas in artificial intelligence for robust accounts of basic reasoning processes and drawing upon a long tradition of research in other disciplines.}
}
@article{YANG201616,
title = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
journal = {Global Environmental Change},
volume = {37},
pages = {16-30},
year = {2016},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016300036},
author = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
keywords = {The Yarlung Tsangpo River, The Jamuna River, Water resources systems analysis, Transboundary water management, Ex post scenario analysis},
abstract = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower projects, upstream water diversions and possible climate changes introduce concerns among riparian countries about future water supply for energy and food production in the basin. This study presents a new hydro-economic water system model of the basin coupled with ex post scenario analysis under the “nexus thinking” concept to identify and illustrate where development paths are in conflict. Results indicate that the ability of future development to remain free of conflict hinges mostly on the amount of precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future temperature and the unknown amount of upstream water diversion combine to strongly influence future water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries unable to secure enough water to produce their desired energy and food. Future climate projected by General Circulation Models suggest a warmer and wetter climate condition in the region, which is associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The methodology presented here is expected to be generally useful for diagnosing the conditions that may cause water resources development goals to not be achieved due to either changes in climate or water use among competing users.}
}
@article{ALQARALLEH20223913,
title = {Automated Handwriting Recognition and Speech Synthesizer for Indigenous Language Processing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {2},
pages = {3913-3927},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.026531},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822014461},
author = {Bassam A. Y. Alqaralleh and Fahad Aldhaban and Feras Mohammed A-Matarneh and Esam A. AlQaralleh},
keywords = {Computational linguistics, handwriting character recognition, natural language processing, indigenous language},
abstract = {In recent years, researchers in handwriting recognition analysis relating to indigenous languages have gained significant internet among research communities. The recent developments of artificial intelligence (AI), natural language processing (NLP), and computational linguistics (CL) find useful in the analysis of regional low resource languages. Automatic lexical task participation might be elaborated to various applications in the NLP. It is apparent from the availability of effective machine recognition models and open access handwritten databases. Arabic language is a commonly spoken Semitic language, and it is written with the cursive Arabic alphabet from right to left. Arabic handwritten Character Recognition (HCR) is a crucial process in optical character recognition. In this view, this paper presents effective Computational linguistics with Deep Learning based Handwriting Recognition and Speech Synthesizer (CLDL-THRSS) for Indigenous Language. The presented CLDL-THRSS model involves two stages of operations namely automated handwriting recognition and speech recognition. Firstly, the automated handwriting recognition procedure involves preprocessing, segmentation, feature extraction, and classification. Also, the Capsule Network (CapsNet) based feature extractor is employed for the recognition of handwritten Arabic characters. For optimal hyperparameter tuning, the cuckoo search (CS) optimization technique was included to tune the parameters of the CapsNet method. Besides, deep neural network with hidden Markov model (DNN-HMM) model is employed for the automatic speech synthesizer. To validate the effective performance of the proposed CLDL-THRSS model, a detailed experimental validation process takes place and investigates the outcomes interms of different measures. The experimental outcomes denoted that the CLDL-THRSS technique has demonstrated the compared methods.}
}
@article{MASHAL201366,
title = {Enhanced left frontal involvement during novel metaphor comprehension in schizophrenia: Evidence from functional neuroimaging},
journal = {Brain and Language},
volume = {124},
number = {1},
pages = {66-74},
year = {2013},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2012.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X12002155},
author = {N. Mashal and T. Vishne and N. Laor and D. Titone},
keywords = {Schizophrenia, Novel metaphors, Lateralization, Language, fMRI},
abstract = {The neural basis involved in novel metaphor comprehension in schizophrenia is relatively unknown. Fourteen people with schizophrenia and fourteen controls were scanned while they silently read novel metaphors, conventional metaphors, literal expressions, and meaningless word-pairs. People with schizophrenia showed reduced comprehension of both novel and conventional metaphors. Furthermore, while controls showed enhanced brain activation in right inferior frontal gyrus (IFG) for novel metaphors versus meaningless word-pairs, people with schizophrenia showed an over-activation of left IFG and middle frontal gyrus (MFG). Direct comparison between the groups revealed greater activation in left precuneus for both novel metaphors and literal expressions vs. baseline for individuals with schizophrenia. Direct comparison for novel metaphors vs. literal expressions also revealed increased activation for individuals with schizophrenia in left MFG. These results suggest that the inefficient processing of novel metaphors in schizophrenia involves compensatory recruitment of additional brain regions that include the left MFG and left precuneus.}
}
@article{LEUKHIN2018300,
title = {Bio-plausible simulation of three monoamine systems to replicate emotional phenomena in a machine},
journal = {Procedia Computer Science},
volume = {145},
pages = {300-305},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323639},
author = {Alexey Leukhin and Max Talanov and Jordi Vallverdú and Fail Gafarov},
keywords = {affective computing, affective computation, spiking neural networks, bio-inspired cognitive architecture},
abstract = {In this paper we present the validation of the three-dimensional model of emotions by Hugo Lövheim the “cube of emotion” via neurosimulation in the NEST. We also present the extension of original “cube of emotion” with the bridge to computational processes parameters. The neurosimulation is done via re-implementation of dopamine (DA), serotonin (5-HT) and noradrenaline (NA) subsystems of a rat brain to replicate 8 basic psycho-emotional states according to the “cube of emotion”. Results of neu-rosimulations indicate the incremental influence of DA and NA over computational resources of a psycho-emotional state while 5-HT decreases the computational resources used to calculate a psycho-emotional state. This way we indicate the feasibility of the bio-plausible re-implementation of psycho-emotional states in a computational system. This approach could be useful extension of decision making and load balancing components of modern artificial agents as well as intelligent robotic systems.}
}
@article{HU2023100795,
title = {A cardiologist-like computer-aided interpretation framework to improve arrhythmia diagnosis from imbalanced training datasets},
journal = {Patterns},
volume = {4},
number = {9},
pages = {100795},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100795},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923001502},
author = {Lianting Hu and Shuai Huang and Huazhang Liu and Yunmei Du and Junfei Zhao and Xiaoting Peng and Dantong Li and Xuanhui Chen and Huan Yang and Lingcong Kong and Jiajie Tang and Xin Li and Heng Liang and Huiying Liang},
keywords = {arrhythmia, inter-class bullying, waveform clustering, heartbeat splicing, Bayesian approach},
abstract = {Summary
Arrhythmias can pose a significant threat to cardiac health, potentially leading to serious consequences such as stroke, heart failure, cardiac arrest, shock, and sudden death. In computer-aided electrocardiogram interpretation systems, the inclusion of certain classes of arrhythmias, which we term “aggressive” or “bullying,” can lead to the underdiagnosis of other “vulnerable” classes. To address this issue, a method for arrhythmia diagnosis is proposed in this study. This method combines morphological-characteristic-based waveform clustering with Bayesian theory, drawing inspiration from the diagnostic reasoning of experienced cardiologists. The proposed method achieved optimal performance in macro-recall and macro-precision through hyperparameter optimization, including spliced heartbeats and clusters. In addition, with increasing bullying by aggressive arrhythmias, our model obtained the highest average recall and the lowest average drop in recall on the nine vulnerable arrhythmias. Furthermore, the maximum cluster characteristics were found to be consistent with established arrhythmia diagnostic criteria, lending interpretability to the proposed method.}
}
@article{PISTIKOPOULOS2021107252,
title = {Process systems engineering – The generation next?},
journal = {Computers & Chemical Engineering},
volume = {147},
pages = {107252},
year = {2021},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2021.107252},
url = {https://www.sciencedirect.com/science/article/pii/S0098135421000302},
author = {E N Pistikopoulos and Ana Barbosa-Povoa and Jay H Lee and Ruth Misener and Alexander Mitsos and G V Reklaitis and V Venkatasubramanian and Fengqi You and Rafiqul Gani},
keywords = {Process systems engineering, Synthesis-design, Optimization, Control, Modelling, Supply chain},
abstract = {Process Systems Engineering (PSE) is the scientific discipline of integrating scales and components describing the behavior of a physicochemical system, via mathematical modelling, data analytics, design, optimization and control. PSE provides the ‘glue’ within scientific chemical engineering, and offers a scientific basis and computational tools towards addressing contemporary and future challenges such as in energy, environment, the ‘industry of tomorrow’ and sustainability. This perspective article offers a guide towards the next generation of PSE developments by looking at its history, core competencies, current status and ongoing trends.}
}
@article{COLOMBO2016291,
title = {Analysing the connectivity and communication of suicidal users on twitter},
journal = {Computer Communications},
volume = {73},
pages = {291-300},
year = {2016},
note = {Online Social Networks},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2015.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S014036641500256X},
author = {Gualtiero B. Colombo and Pete Burnap and Andrei Hodorog and Jonathan Scourfield},
keywords = {Social media, Social network analysis, Twitter, Computational social science, Suicide},
abstract = {In this paper we aim to understand the connectivity and communication characteristics of Twitter users who post content subsequently classified by human annotators as containing possible suicidal intent or thinking, commonly referred to as suicidal ideation. We achieve this understanding by analysing the characteristics of their social networks. Starting from a set of human annotated Tweets we retrieved the authors’ followers and friends lists, and identified users who retweeted the suicidal content. We subsequently built the social network graphs. Our results show a high degree of reciprocal connectivity between the authors of suicidal content when compared to other studies of Twitter users, suggesting a tightly-coupled virtual community. In addition, an analysis of the retweet graph has identified bridge nodes and hub nodes connecting users posting suicidal ideation with users who were not, thus suggesting a potential for information cascade and risk of a possible contagion effect. This is particularly emphasised by considering the combined graph merging friendship and retweeting links.}
}
@incollection{VANDERFORD2017105,
title = {Chapter 10 - Transferable Skills: How to Describe What You Really Know},
editor = {Teresa M. Evans and Natalie Lundsteen and Nathan L. Vanderford},
booktitle = {ReSearch},
publisher = {Academic Press},
pages = {105-118},
year = {2017},
isbn = {978-0-12-804297-7},
doi = {https://doi.org/10.1016/B978-0-12-804297-7.00010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042977000100},
author = {Nathan L. Vanderford},
keywords = {Alternative careers, Biomedical science, Career path, Communicating skills, Graduate student, Job market, Life science, Nontraditional career, PhD, Postdoc, Self-assessment, Transferable skills},
abstract = {Think beyond your label—years of academic life have pushed you to fine-tune a statement regarding your research interests that is short and to the point. It often starts with “I am a doctoral student in…” To hone your transferable skills, or the skills that are valued in research as well as other career areas, you have to break away from thinking about yourself in those terms. Prove that you can do the job even when you do not have direct job experience—you will do this by learning to think broadly and comprehensively about your transferable skills. Know how to identify your transferable skills. For everything that you have achieved in your life, there is an accompanying set of skills that will add value to you as a job applicant. Know how to describe them. Know how to portray your transferable skills in industry terms. There are phrases that resonate with key industries and organizations in their search for new recruits. Identify the correct terms to be understood in your chosen career field.}
}
@article{LIANG2022119384,
title = {Dynamic Causal Modelling of Hierarchical Planning},
journal = {NeuroImage},
volume = {258},
pages = {119384},
year = {2022},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2022.119384},
url = {https://www.sciencedirect.com/science/article/pii/S1053811922005031},
author = {Qunjun Liang and Jinhui Li and Senning Zheng and Jiajun Liao and Ruiwang Huang},
keywords = {Dynamic Causal Modelling (DCM), Parametric Empirical Bayes (PEB), fMRI, neural architecture, individual difference},
abstract = {Hierarchical planning (HP) is a strategy that optimizes the planning by storing the steps towards the goal (lower-level planning) into subgoals (higher-level planning). In the framework of model-based reinforcement learning, HP requires the computation through the transition value between higher-level hierarchies. Previous study identified the dmPFC, PMC and SPL were involved in the computation process of HP respectively. However, it is still unclear about how these regions interaction with each other to support the computation in HP, which could deepen our understanding about the implementation of plan algorithm in hierarchical environment. To address this question, we conducted an fMRI experiment using a virtual subway navigation task. We identified the activity of the dmPFC, premotor cortex (PMC) and superior parietal lobe (SPL) with general linear model (GLM) in HP. Then, Dynamic Causal Modelling (DCM) was performed to quantify the influence of the higher- and lower-planning on the connectivity between the brain areas identified by the GLM. The strongest modulation effect of the higher-level planning was found on the dmPFC→right PMC connection. Furthermore, using Parametric Empirical Bayes (PEB), we found the modulation of higher-level planning on the dmPFC→right PMC and right PMC→SPL connections could explain the individual difference of the response time. We conclude that the dmPFC-related connectivity takes the response to the higher-level planning, while the PMC acts as the bridge between the higher-level planning to behavior outcome.}
}
@article{KEE1984198,
title = {Computational modeling of flame structure},
journal = {Physica D: Nonlinear Phenomena},
volume = {12},
number = {1},
pages = {198-211},
year = {1984},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(84)90524-4},
url = {https://www.sciencedirect.com/science/article/pii/0167278984905244},
author = {Robert J. Kee and James A. Miller},
abstract = {In this paper we discuss the need to model the detailed structure of a flame. That is, we argue the value of tracing the elementary reaction steps that are responsible for the creation of pollutant species and the release of heat. Accomplishing this task requires the computational solution of equations describing the conservation of mass, momentum, energy, and chemical species. In the course of our development we compare the computational approach with that of large activation energy asymptotic analysis. In the second half of the paper we concentrate on the computational consequences of flame modeling. Typically the governing equations are large and stiff systems of partial differential equations. Computational solution requires strongly stable implicit numerical algorithms, and we discuss these methods. We also discuss the adaptive meshing strategies that are required to resolve accurately the structure of thin flames in relatively large domains.}
}
@article{HICKENDORFF2020101311,
title = {Fourth graders’ adaptive strategy use in solving multidigit subtraction problems},
journal = {Learning and Instruction},
volume = {67},
pages = {101311},
year = {2020},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2020.101311},
url = {https://www.sciencedirect.com/science/article/pii/S0959475219307327},
author = {Marian Hickendorff},
keywords = {Mathematics education, Multidigit subtraction, Strategy flexibility, Strategy adaptivity, Choice/no-choice method},
abstract = {Using the choice/no-choice methodology we investigated Dutch fourth graders’ (N = 124) adaptive use of the indirect addition strategy to solve subtraction problems. Children solved multidigit subtraction problems in one choice condition, in which they were free to choose between direct subtraction and indirect addition, and in two no-choice conditions, in which they had to use either direct subtraction or indirect addition. Furthermore, children were randomly assigned to mental computation, written computation, or free choice between mental and written computation. One third of the children adaptively switched their strategy according to the number characteristics of the problems, whereas the remaining children consistently used the same strategy. The likelihood to adaptively switch strategies decreased when written computation was allowed or required, compared to mandatory mental computation. On average, children were adaptive to their own speed differences but not to the accuracy differences between the strategies.}
}
@article{BECK2017110,
title = {Can bootstrapping explain concept learning?},
journal = {Cognition},
volume = {158},
pages = {110-121},
year = {2017},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2016.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0010027716302578},
author = {Jacob Beck},
keywords = {Bootstrapping, Concept learning, Susan Carey, Concepts, Computational constraints},
abstract = {Susan Carey’s account of Quinean bootstrapping has been heavily criticized. While it purports to explain how important new concepts are learned, many commentators complain that it is unclear just what bootstrapping is supposed to be or how it is supposed to work. Others allege that bootstrapping falls prey to the circularity challenge: it cannot explain how new concepts are learned without presupposing that learners already have those very concepts. Drawing on discussions of concept learning from the philosophical literature, this article develops a detailed interpretation of bootstrapping that can answer the circularity challenge. The key to this interpretation is the recognition of computational constraints, both internal and external to the mind, which can endow empty symbols with new conceptual roles and thus new contents.}
}
@article{ENE20141110,
title = {Open Loop Reverse Supply Chain Network Design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {109},
pages = {1110-1115},
year = {2014},
note = {2nd World Conference on Business, Economics and Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.12.596},
url = {https://www.sciencedirect.com/science/article/pii/S187704281305235X},
author = {Seval Ene and Nursel Öztürk},
keywords = {Supply chain management, open loop system, product recovery, network design, mathematical programming},
abstract = {Reverse supply chain management is a significant issue for sustainable economy, product recovery and green thinking. The purpose of this study is to contribute product recovery management by designing open loop reverse supply chain network. The main difference between open loop and closed loop reverse supply chain is in returning of used products. In a closed loop reverse supply chain, used products are generally returned to original producers. But in an open loop reverse supply chain, used products are not returned to original producers, outsider firms recover them. This paper presents a mathematical model for multi stage and multi period reverse supply chain network, which maximizes total profit of the network. The proposed model determines facility locations and material flows between stages in each period. Numerical experiments showed the applicability and efficiency of the model.}
}
@article{WANG2021102528,
title = {Automatic diagnosis of ECG disease based on intelligent simulation modeling},
journal = {Biomedical Signal Processing and Control},
volume = {67},
pages = {102528},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102528},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421001257},
author = {Xu Wang and Runchuan Li and Shuhong Wang and Shengya Shen and Wenzhi Zhang and Bing Zhou and Zongmin Wang},
keywords = {Intelligent simulation modeling, Rule, ECG diseases, Diagnosis},
abstract = {In order to better assist doctors in diagnosing cardiovascular diseases, a set of end-to-end automatic diagnosis algorithms for ECG diseases based on intelligent simulation modeling are proposed. Firstly, wavelet transform and threshold method are used to denoise the ECG signal and locate the waveform in this paper. Secondly, waveform features are extracted. Finally, the rule method is used to convert the doctors’ thinking of diagnosing the disease into a description of the ECG characteristics of the disease to diagnose the ECG disease, and the algorithm is verified on the public database CCDD and the private data all-in-one machine data. The results show that this method is not inferior to the deep learning method. Now 11 types of diseases and 10 types of rhythm can be diagnosed.}
}
@article{PARIKH2024138,
title = {A comprehensive study on epigenetic biomarkers in early detection and prognosis of Alzheimer's disease},
journal = {Biomedical Analysis},
volume = {1},
number = {2},
pages = {138-153},
year = {2024},
issn = {2950-435X},
doi = {https://doi.org/10.1016/j.bioana.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2950435X24000167},
author = {Dhruv Parikh and Manan Shah},
keywords = {Alzheimer’s Disease, Biomarkers, Detection, Epigenetics},
abstract = {Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by beta-amyloid plaques and tau tangles, disrupting brain cell communication, causing atrophy, and leading to cognitive decline. It poses a substantial global health challenge, necessitating urgent research. Molecular biomarkers, reflecting AD progression, have been identified in diverse bodily tissues. Notably, emerging epigenetic biomarkers introduce a novel dimension to AD pathophysiology. However, their precise role in early AD detection and prognosis remains unclear. This review classifies various epigenetic biomarkers, emphasizing their potential in early detection and prognosis. Various epigenetic biomarkers like DNA methylation, non-coding RNAs, histone modification, OMICS, and many more get significantly altered during AD; these biomarkers being distinctly expressed in normal conditions to AD offer a huge therapeutic benefit to stop the progression or worsening it. We explore the therapeutic implications and propose integration with existing diagnostic methods to intervene in AD progression, mitigating exacerbation. Addressing challenges, we envision the future scope of these biomarkers, emphasizing their synergy with computational approaches for enhanced AD detection. This review contributes to the field by proposing a multifaceted approach that combines epigenetic markers with computational analysis to improve early detection and facilitate timely therapeutic interventions. Furthermore, we discuss the economic implications of these biomarkers, proposing that their early application could significantly reduce the financial burden of AD by delaying the progression and severity of the disease.}
}
@article{BAILLIE1989209,
title = {A comparison of the CM with the DAP for lattice gauge theory},
journal = {Parallel Computing},
volume = {12},
number = {2},
pages = {209-220},
year = {1989},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(89)90054-9},
url = {https://www.sciencedirect.com/science/article/pii/0167819189900549},
author = {Clive F Baillie and G {Stuart Pawley}},
keywords = {Connection Machine, Distributed Array Processor, SIMD, massively parallel, lattice gauge theory, QED, QCD, performance measurement, performance analysis},
abstract = {Lattice gauge theory is one of the most challenging large-scale scientific computations; a state of the art calculation requires at least 1014 floating-point operations, necessitating the use of advanced architecture massively parallel computers such as the Connection Machine (CM) made by Thinking Machines Corporation (TMC), and the Distributed Array Processor (DAP) made in the past by International Computers Limited (ICL) and currently by active Memory Technology (AMT). The most important gauge theory to be solved is that descrining the sub-nuclear world of high energy physics: Quantum Chromodynamics (QCD). The simples example of a gauge theory is Quantum Electro-dynamics (QED), the theory which describes the interaction of electrons and photons. Simulation of QCD requires computer software very similar to that for the simpler QED problem. Thus, as a first step towards computer simulation of QCD, we have developed code for QED on the CM, and compared this with similar code for the DAP. Experience with the DAP allows us to predict performances for QCD code on the CM, showing the latter to be a very serious proposition for such large-scale scientific computations.}
}
@article{OSTLUND1985109,
title = {WATERLOPP V2/64: A highly parallel machine for numerical computation},
journal = {Computer Physics Communications},
volume = {37},
number = {1},
pages = {109-117},
year = {1985},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(85)90142-0},
url = {https://www.sciencedirect.com/science/article/pii/0010465585901420},
author = {Neil S. Ostlund},
abstract = {Current technological trends suggest that the high performance scientific machines of the future are very likely to consist of a large number (greater than 1024) of processors connected and communicating with each other in some as yet undetermined manner. Such an assembly of processors should behave as a single machine in obtaining numerical solutions to scientific problems. However, the appropriate way of organizing both the hardware and software of such an assembly of processors is an unsolved and active area of research. It is particularly important to minimize the organizational overhead of interprocessor comunication, global synchronization, and contention for shared resources if the performance of a large number (n) of processors is to be anything like the desirable n times the performance of a single processor. In many situations, adding a processor actually decreases the performance of the overall system since the extra organizational overhead is larger than the extra processing power added. The systolic loop architecture is a new multiple processor architecture which attemps at a solution to the problem of how to organize a large number of asynchronous processors into an effective computational system while minimizing the organizational overhead. This paper gives a brief overview of the basic systolic loop architecture, systolic loop algorithms for numerical computation, and a 64-processor implementation of the architecture, WATERLOOP V2/64, that is being used as a testbed for exploring the hardware, software, and algorithmic aspects of the architecture.}
}
@article{CRISTOFARO2020344,
title = {“I feel and think, therefore I am”: An Affect-Cognitive Theory of management decisions},
journal = {European Management Journal},
volume = {38},
number = {2},
pages = {344-355},
year = {2020},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263237319301094},
author = {Matteo Cristofaro},
keywords = {Sensemaking, Decision making, Socially situated cognition, Affect, Cognition, Rationality, Behavioral strategy},
abstract = {I propose an Affect-Cognitive Theory to comprehensively understand how decisions occur in organizations. To this aim, I first review the assumptions of sensemaking and decision-making streams of research, especially the influence of bounded rationality, affective states and their relationships with cognition; then, I integrate them on the common basis of socially situated cognition. This new theory emphasizes the role of affective states in determining/being determined by cognition and its errors, pointing out decision makers’ affect as the result of multi-level adaptations to the physical and social environment. Management decisions are path dependent but not immutable; they, indeed, bank on the predominant feeling resulting from the modifying interactions and regulations of decision makers with their physical and social environment. Here, decision makers are proposed as “emotional cognizers” overcoming the thinking-feeling dichotomy that has often featured in the study of management decisions. This theory is beneficial for behavioral strategy, offering the needed assumptions to intertwine human cognition, emotions, and social behavior.}
}
@article{RANA201761,
title = {Dynamic effects in the didehydro‐Diels‐Alder (DDDA) reaction of enyne‐ketoenes: 50% stepwise bond formation in spite of concerted transition state††This article is published as part of a special issue to celebrate the 80th birthday of Professor Waldemar Adam},
journal = {Journal of Physical Organic Chemistry},
volume = {30},
number = {9},
pages = {61-67},
year = {2017},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.3732},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022014072},
author = {Anup Rana and Indrajit Paul and Michael Schmittel},
abstract = {The C2─C6/Diels‐Alder cyclization of enyne‐ketoene 1 was studied by experiments, theoretical calculations, and dynamic trajectory computations. The failure to trap possible intermediate(s), indicates a concerted reaction mechanism. A detailed search for stationary points revealed a concerted mechanism and surprisingly a diradical intermediate with no direct connection to the enyne‐ketoene 1. To probe the accessibility of this intermediate quasiclassical trajectories were initiated from the concerted transition state structure. Notably, 36% of the trajectories reach the product zone directly and 5% arrive at the product via the intermediate diradical. Additionally, 31% of the trajectories go to the intermediate zone and stay there within the simulation time limit.}
}
@article{CHRISTAKOU2014302,
title = {Present simple and continuous: Emergence of self-regulation and contextual sophistication in adolescent decision-making},
journal = {Neuropsychologia},
volume = {65},
pages = {302-312},
year = {2014},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0028393214003133},
author = {Anastasia Christakou},
keywords = {Decision-making, Adolescence, Self-regulation, Corticostriatal circuits},
abstract = {Sophisticated, intentional decision-making is a hallmark of mature, self-aware behaviour. Although neural, psychological, interpersonal, and socioeconomic elements that contribute to such adaptive, foresighted behaviour mature and/or change throughout the life-span, here we concentrate on relevant maturational processes that take place during adolescence, a period of disproportionate developmental opportunity and risk. A brief, eclectic overview is presented of recent evidence, new challenges, and current thinking on the fundamental mechanisms that mature throughout adolescence to support adaptive, self-controlled decision-making. This is followed by a proposal for the putative contribution of frontostriatal mechanisms to the moment-to-moment assembly of evaluative heuristics that mediate increased decision-making sophistication, promoting the maturation of self-regulated behaviour through adolescence and young adulthood.}
}
@article{KRELLENSTEIN1987155,
title = {A reply to ”parallel computation and the mind-body problem”},
journal = {Cognitive Science},
volume = {11},
number = {2},
pages = {155-157},
year = {1987},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(87)80003-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021387800034},
author = {Marc Krellenstein}
}
@article{SKLAD2014710,
title = {The Development of the Heuristics and Biases Scale (HBS)},
journal = {Procedia - Social and Behavioral Sciences},
volume = {112},
pages = {710-718},
year = {2014},
note = {International Conference on Education & Educational Psychology 2013 (ICEEPSY 2013)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.01.1221},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814012385},
author = {Marcin Sklad and Rene Diekstra},
keywords = {Cognitive Heuristics Biases Education Psychometric Scale},
abstract = {Problem Statement
There is no comprehensive tool capturing general vulnerability to biases caused by the use of heuristics. Existing tools focus only on one specific bias or on personality traits.
Research Questions
Can general vulnerability to heuristic thinking be assessed and what are the sub-dimensions of this construct? Can undergraduate students be successfully involved in the research process?
Purpose of the Study
To demonstrate the results of an educational experiment in which undergraduate students are involved in the first stage of development of the Heuristics and Biases Scale (HBS).
Research Methods
After getting acquainted with the underlying theory, students chose one specific bias or heuristic, investigated related results of the experiments and paradigms. At the later stage, under supervision, students developed items intended to capture the chosen bias. Finally, positively evaluated items were combined together and piloted. The psychometrical properties of the items and course outcomes were assessed.
Findings
Developed items formed scales with satisfactory reliability. Course received positive student evaluations, and the assessment indicated that the majority of students achieved intended learning outcomes.
Conclusions
The study indicates that it is possible to develop a psychometrically sound assessment to measure vulnerability to a range of common cognitive biases. Moreover, it is also possible to successfully involve undergraduate students in the development of a psychometrical tool.
Acknowledgments
Authors would like to thank the Students of University College Roosevelt contributing to this work as their Independent Research Projects or as a part of Social Psychology or Statistics Course.}
}
@article{ACAR2016861,
title = {Soundscapes of Digital Morphogenesis in Architecture which Created from Musical Algorithm},
journal = {Procedia - Social and Behavioral Sciences},
volume = {216},
pages = {861-873},
year = {2016},
note = {Urban Planning and Architectural Design for Sustainable Development (UPADSD)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.12.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815062631},
author = {Didem Acar},
keywords = {Transcoding, Acoustic, Computational Design, Transdisciplinary framework, Architectural design},
abstract = {Music and architecture have made use of mathematical proportions throughout the history for the purpose of creating acoustic and visual forms. The reason for this is the aesthetic pursuit of both disciplines since centuries. Mathematics is one of the most important factors that influence aesthetic results. While forming their abstract aesthetic compositions the musicians use the musical notes that have definite frequency values. Each of these frequency values are defined by one integer. Every classical music artist uses the fractal sequencing of these frequencies. On the other hand we encounter hundreds of silent formats which are produced using mathematical ideas. In this context if we think of the interdisciplinary interaction between music and architecture no form is ever silent. In this study, the intersection of two disciplines will be examined in the perspective of architecture; a stumper and interrogative start for pursuit of architectural forms of the present day with the transformation of auditory forms to visual forms will be made; and a basis will be provided to be able to discuss the innovations that the spaces, structures and auditory experiences which can be formed by obtaining musical codes bring.}
}
@incollection{CHIARENZA202317,
title = {Chapter 2 - The psychophysiology of “covert” goal-directed behavior},
editor = {Tal Dotan Ben-Soussan and Joseph Glicksohn and Narayanan Srinivasan},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {280},
pages = {17-42},
year = {2023},
booktitle = {Neurophysiology of Silence Part B: Theory and Review},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000067},
author = {Giuseppe Augusto Chiarenza},
keywords = {Covert behavior, Movement related potentials, Bereitschaftspotential, Skilled performance positivity, Development, Dyslexia, Education},
abstract = {Covert behavior is defined as behavior that is not directly visible and is thus comparable to a type of behavioral silence that requires modern psychophysiological techniques to reveal. Goal-directed behavior is teleologically purposive. Fundamentally, there are two approaches to accounting for purposeful behavior. One is the cybernetic approach, which views behavior as homeostatic and largely reflexive. The other one views behavior as a cognitive process that involves an interaction between neural events representing the previous experience, the present state of the individual, and the occurrence of particular features in the environment. This review, based on published data, presents a non-invasive psychophysiological method for investigating the electrical brain activity associated with those “silent” behaviors such as intention, evaluation of results, and memorization. Movement-related potentials (MRPs) are ideal for studying these processes. The MRPs are recorded during the execution of the skilled performance task (SPT). This task requires the execution of fast ballistic movements with the thumbs of both hands, learning a precise and short time interval between the two thumb presses, and scoring the highest number of target performances. The subject receives real-time feedback about the results of his performance. The MRPs associated with this task and present during covert behavior are the Bereitschaftspotential (BP) present before the onset of movement and the Skilled Performance Positivity (SPP) after movement, which coincides with the subject's awareness of the success or failure of his performance. These potentials show a maturational trend, reaching the adult form around the age of 10 when formal and abstract thinking progress. SPT and MRPs are particularly suitable to study neurodevelopmental disorders. Children with developmental dyslexia show abnormal MRPs, both in latency and amplitude, in different brain areas.}
}
@article{AYERS201861,
title = {A first step toward a practice-based theory of pedagogical content knowledge in secondary economics},
journal = {The Journal of Social Studies Research},
volume = {42},
number = {1},
pages = {61-79},
year = {2018},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X17300177},
author = {Cheryl A. Ayers},
keywords = {Secondary economic education, Pedagogical content knowledge, Horizon content knowledge, Specialized content knowledge, Knowledge of content and teaching, Knowledge of content and students},
abstract = {The purpose of this qualitative case study was to gain an in-depth understanding of how three award-winning secondary economics teachers demonstrated their pedagogical content knowledge (PCK), specifically horizon content knowledge, specialized content knowledge, knowledge of content and teaching, and knowledge of content and students. The teachers consistently connected economic content to other grades, subjects, and economic concepts and skills. Economic content was also regularly used to prepare students for citizenship, including casting more informed votes and understanding current events. However, authentic discussions, including ones about controversial issues, were mostly lacking. An emphasis was placed on developing students’ economic reasoning skills, including real-world applications of the economic way of thinking and decision-making models. Additionally, active learning instructional practices were frequently incorporated, and economic content was almost always related to students’ interests and experiences. A detailed description of a first step toward a practice-based theory of PCK in secondary economics concludes the article.}
}
@article{WANG2023120829,
title = {DBCT-Net:A dual branch hybrid CNN-transformer network for remote sensing image fusion},
journal = {Expert Systems with Applications},
volume = {233},
pages = {120829},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120829},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423013313},
author = {Quanli Wang and Xin Jin and Qian Jiang and Liwen Wu and Yunchun Zhang and Wei Zhou},
keywords = {Image fusion, Convolutional neural network, Pansharpening, Transformer},
abstract = {Remote sensing image fusion aims at fusing high spatial resolution single-band panchromatic (PAN) image with spectrally informative multispectral (MS) image to generate panchromatic sharpened image with high resolution and color information, it is also called pansharpening. Most of the proposed single convolutional neural network (CNN) or transformer-based pansharpening methods own several problems, such as inability to acquire long-range features or difficult to train, resulting the loss of spatial details and colors. In addition, the computational complexity of transformer cannot be ignored. In this work, we propose a dual-branch hybrid CNN-Transformer network (DBCT-Net) that utilizes the local specificity of CNN and models the global dependencies by transformer. First, a multi-branch dense connected block (MDCB-4) network is designed to obtain spectral and textural information in MS and PAN images, respectively. Next, an encoder–decoder transformer based on the self-attention and co-attention modules is able to inject the missing local and global information, which can further enhance the results. It is worth noting that an inverted multi-head transposed attention (IMTA) is applied here to build attention maps from feature dimensions, which greatly reduces the computation time. Finally, an image reconstruction module is employed to effectively fuse the acquired texture and spectral features. Furthermore, to generate visually better pansharpened images, we propose a combined loss function that includes a focal frequency loss. Extensive experiments on WorldView II (WV2), GF-2,and QuickBird (QB) datasets show that DBCT-Net can perform better in spatial preservation and spectral feature recovery.}
}
@article{BALAKRISHNAN2025109810,
title = {Alzheimer's Disease detection and classification using optimized neural network},
journal = {Computers in Biology and Medicine},
volume = {187},
pages = {109810},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.109810},
url = {https://www.sciencedirect.com/science/article/pii/S001048252500160X},
author = {Nair Bini Balakrishnan and Anitha S. Pillai and Jisha {Jose Panackal} and P.S. Sreeja},
keywords = {Recurrent neural network, Moth flame optimization, Deep reinforcement learning, Alzheimer's detection},
abstract = {Alzheimer's disease (AD) is a degenerative neurological condition characterized by a progressive decline in cognitive abilities, resulting in memory impairment and limitations in performing daily tasks. Timely and precise identification of AD holds paramount importance for prompt intervention and enhanced patient prognosis. In this research, a novel approach to AD mechanism was developed by combining Deep Reinforcement Learning (DRL) with a Moth Flame Optimized Recurrent Neural Network (MFORNN). Initially, the brain MRI samples are gathered and preprocessed to discard the noise features and to improve their quality. Consequently, the MFO algorithm captures and selects the most informative and highly correlative features from the preprocessed images, making it easier for Recurrent Neural Networks (RNNs) to learn the temporal dependencies and patterns differentiating normal and AD-affected images. The DRL component fine-tunes the parameters of RNN through its reward-based mechanism, ensuring that the classifier produces accurate outcomes and reduces computational complexity. The Python tool was utilized to implement the outlined framework, with the outcomes showcased that the designed algorithm attained an accuracy of 99.31 %, precision of 99.24 %, recall of 99.43 %, and f-measure of 99.35 %. Ultimately, a comparative analysis was performed against established classifier models, affirming the superior performance of the proposed technique over conventional algorithms.}
}
@article{WIERZBICKI2007610,
title = {Modelling as a way of organising knowledge},
journal = {European Journal of Operational Research},
volume = {176},
number = {1},
pages = {610-635},
year = {2007},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2005.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0377221705007010},
author = {Andrzej P. Wierzbicki},
keywords = {OR in research and development, Knowledge-based systems, Mathematical modelling, Knowledge management, Hard and soft systems approaches, Tacit knowledge and intuition, Epistemology},
abstract = {The paper is motivated by the need of to address a new the old topic of operational research and hard (but also soft) systems science: what is the role of mathematical modelling, how does it relate to knowledge, to creativity, to human concerns? Such a need arises because of the great change observed today, of informational revolution, of transition towards knowledge-based economy, towards networked organization of our social and economic life. During last 50years operational research, mathematical modelling and computerised techniques of model analysis and optimisation contributed essentially to the change of perception of contemporary world, characteristic for the current informational revolution indicating the change of civilisation eras. These contributions have been noted during these years inside operational research, but analysed mostly from so-called soft systems thinking perspective. Main contributions to the actual formation of the new era, however, came from the hard systems research, in particular, as we shall show, from mathematical modelling in applications to the development of technological systems. The new civilisation era of information and knowledge-based economy started around 1980. It is a long duration historical era, characterised by a new way of understanding the world. This understanding is systemic and chaotic; in particular, it assumes the emergence of qualitatively new properties of complex systems on higher layers of complexity, which cannot be reduced to the properties of system components. On this background, it is necessary to reflect a new on the theory of knowledge. The paper presents a discussion of the concept of knowledge from several perspectives, such as the perspective of operational research, of systems science, of mathematical modelling, of knowledge-based economy, of knowledge engineering and knowledge management, of interactive model-based decision support. The human-centred development of informational technology necessitates a re-appraisal of soft systems approaches; their values and limitations are discussed. Additionally, a rational theory of intuition is recalled to show its relation with the concept of tacit knowledge, of knowledge creation and with harmonious approaches to knowledge characterising Far East philosophy as well as Japanese approaches to knowledge management and creation. Epistemological conclusions from the rational theory of intuition are discussed, including a new concept of micro-theories of knowledge creation and the concept of Creative Space.}
}
@article{SHEKHAR2024820,
title = {Topological data analysis enhanced prediction of hydrogen storage in metal–organic frameworks (MOFs)††Electronic supplementary information (ESI) available: Figure showing the effect of training set size. See DOI: https://doi.org/10.1039/d3ma00591g},
journal = {Materials Advances},
volume = {5},
number = {2},
pages = {820-830},
year = {2024},
issn = {2633-5409},
doi = {https://doi.org/10.1039/d3ma00591g},
url = {https://www.sciencedirect.com/science/article/pii/S2633540924000550},
author = {Shivanshu Shekhar and Chandra Chowdhury},
abstract = {Metal–organic frameworks (MOFs) have the capacity to serve as gas capturing, sensing, and storing systems. It is usual practice to select the MOF from a vast database with the best adsorption property in order to do an adsorption calculation. The costs of computing thermodynamic values are sometimes a limiting factor in high-throughput computational research, inhibiting the development of MOFs for separations and storage applications. In recent years, machine learning has emerged as a promising substitute for traditional methods like experiments and simulations when trying to foretell material properties. The most difficult part of this process is choosing characteristics that produce interpretable representations of materials that may be used for a variety of prediction tasks. We investigate a feature-based representation of materials using tools from topological data analysis. In order to describe the geometry of MOFs with greater accuracy, we use persistent homology. We show our method by forecasting the hydrogen storage capacity of MOFs during a temperature and pressure swing from 100 bar/77 K to 5 bar/160 K, using the synthetically compiled CoRE MOF-2019 database of 4029 MOFs. Our topological descriptor is used in conjunction with more conventional structural features, and their usefulness to prediction tasks is explored. In addition to demonstrating significant progress over the baseline, our findings draw attention to the fact that topological features capture information that is supplementary to the structural features.}
}
@article{COIERA2007S98,
title = {Putting the technical back into socio-technical systems research},
journal = {International Journal of Medical Informatics},
volume = {76},
pages = {S98-S103},
year = {2007},
note = {Information Technology in Health Care: Sociotechnical Approaches},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2006.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S1386505606001481},
author = {Enrico Coiera},
keywords = {Human–computer interaction, Information system design, Information system evaluation, Socio-technical systems},
abstract = {Socio-technical systems (STS) analysis has provided us with a powerful framework with which to analyse the reasons behind the poor acceptability, uptake and performance of many information or communication technology systems (ICT). However, for the contribution of STS thinking to be more than simply a means of critiquing current practices and ICT systems, it needs to also contribute to the process of developing new and more effective ICT systems. Specifically, we need to develop a formal design language for translating our insights about the socio-technical nature of work, into design specifications that result in better interventions in the work place. We need to get ‘technical’ about what we mean and about what we want from a design, and we need to work alongside technologists to shape technology, as well as the processes, organisations and cultures within which they will be embedded. Indeed the process of design itself can be seen as a socio-technical one, and understanding the decision to design itself may allow us one day to stop designing for people, and create STS that sustainably design themselves.}
}
@article{CORBETT2020e03250,
title = {Connectivism and leadership: harnessing a learning theory for the digital age to redefine leadership in the twenty-first century},
journal = {Heliyon},
volume = {6},
number = {1},
pages = {e03250},
year = {2020},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2020.e03250},
url = {https://www.sciencedirect.com/science/article/pii/S2405844020300955},
author = {Frederique Corbett and Elio Spinello},
keywords = {Connectivism, Learning, Education, Learning theory, Leadership, Computer science, Human-centered computing, Information systems, Network (computer science)},
abstract = {This manuscript provides a literature review of connectivism. It presents evidence and thinking in which connectivism, a new learning theory which has typically been used for online learning, is applied to leadership, with a provocative discussion on the yet unexplored opportunities to use connectivism to redefine leadership in the twenty-first century. The paper aims to bridge the gap between the contributions of digital learning in education and the field of leadership theory and development. It seeks to apply the critical tenets of connectivism in education and learning to leadership theory and to stimulate a debate on new forms of leadership.}
}
@article{NI2025168,
title = {Hybrid solar-energy harvest model for durable photocatalytic hydrogen production},
journal = {International Journal of Hydrogen Energy},
volume = {116},
pages = {168-177},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.03.119},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925012145},
author = {Nan Ni and Yifan Hao and Yinglao Liu and Haibo Li and Jin Feng and Wei Liu and Wenxu Zheng},
keywords = {Photocatalyst, Water splitting, Hydrogen generation, Photon absorption, Semiconductors},
abstract = {Hybrid solar-energy harvest model for next-generation photocatalysts is customized for central metallic manipulation to achieve superior hydrogen generation with outstanding stability and long-lasting reduction reactions. Current single catalysts fail to satisfy demands of photoelectric conversion owing to irreversible photo-corrosion and charge-carrier trapping, leading to inner transmission wanes. Here we present a hybrid solar-energy harvest model with a organic-inorganic hybrid mesoscopic system, CoT(tz)PP/CdS, ranging from ordered to disordered frameworks with sufficient reactive sites and controllable active surface, which erase the energy barriers driven by existing water decomposition. This design enables simultaneous knocked out and coupling interactions of fermions and bosons at surface of binary semiconductors without invisible multi-path fading of generation efficiency. Experimentally, multi-dimension characterizations reveal the intrinsic fine genes of such novel catalyst are innate ideas, preventing unmeaning matters of energy loss and its hydrogen evolution rate reaches up to 66.44 mmol g−1 h−1. Molecular loop domain from CoT(tz)PP limits collapse of molecules in energy transfer, mitigating recombination of electron-hole pairs and enhancing morphological integrity. Overall, these results suggest that CoT(tz)PP/CdS assists hydrogen evolution in predicated review of solar energy utilization trials, reducing internal obstacles and loss on hydrogen outcomes and offering a more valid certificate in sustainable initiative of green energy.}
}
@article{BOHSALI2025105535,
title = {Neural connectivity underlying core language functions},
journal = {Brain and Language},
volume = {262},
pages = {105535},
year = {2025},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2025.105535},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X25000045},
author = {Anastasia A. Bohsali and Joseph M. Gullett and David B. FitzGerald and Thomas Mareci and Bruce Crosson and Keith White and Stephen E. Nadeau},
keywords = {Broca’s region, Tractography, Language, Aphasia, Grammar, Supramarginal gyrus, Angular gyrus, Temporal lobe},
abstract = {Introduction
Although many white matter tracts underlying language functions have been identified, even in aggregate they do not provide a sufficiently detailed and expansive picture to enable us to fully understand the computational processes that might underly language production and comprehension. We employed diffusion tensor tractography (DTT) with a tensor distribution model to more extensively explore the white matter tracts supporting core language functions. Our study was guided by hypotheses stemming largely from the aphasia literature.
Methods
We employed high angular resolution diffusion imaging (HARDI) with a dual region of interest tractography approach. Our diffusion tensor distribution model uses a mixture of Wishart distributions to estimate the water molecule displacement probability functions on a voxel-by-voxel basis and to model crossing/branching fibers using a multicompartmental approach.
Results
We replicated the results of previously published studies of tracts underlying language function. Our study also yielded a number of novel findings: 1) extensive connectivity between Broca’s region and the entirety of the middle and superior frontal gyri; 2) extensive interconnectivity between the four subcomponents of Broca’s region, pars orbitalis, pars triangularis, pars opercularis, and the inferior precentral gyrus; 3) connectivity between the mid-superior temporal gyrus and the transverse gyrus; 4) connectivity between the mid-superior temporal gyrus, the transverse gyrus, and the planum temporale and the inferior and middle temporal gyri; and 5) connectivity between mid- and anterior superior temporal gyrus and all components of Broca’s region.
Discussion
These results, which replicate the results of prior DTT studies, also considerably extend them and thereby provide a fuller picture of the structural basis of language function and the basis for a novel model of the neural network architecture of language function. This new model is entirely consistent with discoveries from the aphasia literature and with parallel distributed processing conceptualizations of language function.}
}
@article{GU2025105551,
title = {Semantic memory structure mediates the role of brain functional connectivity in creative writing},
journal = {Brain and Language},
volume = {264},
pages = {105551},
year = {2025},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2025.105551},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X25000203},
author = {Jing Gu and Xueyang Wang and Cheng Liu and Kaixiang Zhuang and Li Fan and Jingyi Zhang and Jiangzhou Sun and Jiang Qiu},
keywords = {Creativity, Writing, Semantic network, Functional connectivity},
abstract = {Associative theories of creativity posit that high-creativity individuals possess flexible semantic memory structures that allow broad access to varied information. However, the semantic memory structure characteristics and neural substrates of creative writing are unclear. Here, we explored the semantic network features and the predictive whole-brain functional connectivity associated with creative writing and generated mediation models. Participants completed two creative story continuation tasks. We found that keywords from written texts with superior creative writing performance encompassed more semantic categories and were highly interconnected and transferred efficiently. Connectome predictive modeling (CPM) was conducted with resting-state functional magnetic resonance imaging (fMRI) data to identify whole-brain functional connectivity patterns related to creative writing, dominated by default mode network (DMN). Semantic network features were found to mediate the relationship between brain functional connectivity and creative writing performance. These results highlight how semantic memory structure and the DMN-driven brain functional connectivity patterns support creative writing performance. Our findings extend prior research on the role of semantic memory structure and the DMN in creativity, expand upon previous research on semantic creativity, and provide insight into the cognitive and neural foundations of creative writing.}
}
@article{TRAN2019284,
title = {Creating material data for thermoset injection molding simulation process},
journal = {Polymer Testing},
volume = {73},
pages = {284-292},
year = {2019},
issn = {0142-9418},
doi = {https://doi.org/10.1016/j.polymertesting.2018.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S0142941818316295},
author = {Ngoc Tu Tran and Michael Gehde},
keywords = {Thermoset injection molding, Reactive viscosity and cure kinetics model, Thermoset material data, Reactive injection molding simulation, Wall slip boundary condition},
abstract = {Thermoset material data for reactive injection molding simulation process is found in limited sources and seldom available from data bank of simulation tools because of complication not only in rheological and thermal properties measurement but also in writing optimization algorithm to model rheological and thermal mathematical equations. In this paper, rheological and thermal properties of thermoset injection molding compounds were successfully measured. In addition, a numerical method was developed to create material data of thermoset injection molding compounds, which was directly imported into a simulation tool, namely, Moldex3D to investigate its application in thermoset injection molding simulation process. Furthermore, a strong slip phenomenon on the interface between thermoset melt and wall surface which was investigated and detected during injection molding experiments was taken into account in the filling simulation process. The computation was found to be in good agreement with the experimental results, indicating that the new generated material data is reasonable and the influence of wall slip on the mold filling characterization of thermoset injection compounds during simulation process is not ignorable.}
}
@article{YEUNG2024104999,
title = {A systematic review of Drone integrated STEM education at secondary schools (2005–2023): Trends, pedagogies, and learning outcomes},
journal = {Computers & Education},
volume = {212},
pages = {104999},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.104999},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000137},
author = {Richard Chung Yiu Yeung and Chi Ho Yeung and Daner Sun and Chee-Kit Looi},
keywords = {Systematic review, Drone-integrated learning, STEM education, Secondary schools},
abstract = {As the prominence of drone technology continues to captivate interest for its myriad applications in education, an understanding of the current status of drone-integrated education becomes imperative. This systematic review endeavors to furnish an updated and comprehensive analysis of the drone education studies across academic levels, with a specific emphasis on secondary education settings. To accomplish this objective, a review study with 181 publications was conducted, with a particular focus on 41 publications explicitly addressing the integration of drones in secondary STEM education. Employing a systematic approach, this review identifies, analyzes, and synthesizes pertinent literature, ensuring a thorough comprehension of the current state of the field. The key findings of this review can be summarized as follows: 1) Among the diverse array of subjects incorporating drones, STEM disciplines emerge as the most prominently featured. 2) Experiential and project-based learning stand out as the most commonly adopted pedagogical methods in drone-integrated STEM education. The incorporation of teamwork and hands-on activities is frequently cited as instructional strategies aimed at enhancing drone-integrated STEM learning experiences. 3) Beyond the acquisition of drone-related technical skills, the reported learning outcomes encompass a spectrum of aspects, including heightened STEM career awareness, increased engagement and learning interest, and collaborative problem-solving abilities. The findings underscore the potential of drones to ignite passion for STEM subjects among secondary students, achieved through interdisciplinary, hands-on applications that foster problem-solving and design competencies.}
}
@article{WANG201837,
title = {Linguistic terms with weakened hedges: A model for qualitative decision making under uncertainty},
journal = {Information Sciences},
volume = {433-434},
pages = {37-54},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.12.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517311593},
author = {Hai Wang and Zeshui Xu and Xiao-Jun Zeng},
keywords = {Decision making, Linguistic hedges, Linguistic term sets, Multi-granularity linguistic decision making, Semantics},
abstract = {When expressing the experts’ opinions in qualitative decision making (QDM), linguistic hedges can be considered to modify the force expressed by a predefined linguistic term. If an expert is not sure to select one term, weakened hedges would be a natural way to express the uncertainty. This is usually implemented by using a hedge to modify the most possible term, like the expression “more or less good”. To model the uncertainty implied by hedges in QDM, this paper presents a novel linguistic representational and computational model in which the linguistic expressions take the form of a weakened hedge and a linguistic term, which is named as linguistic term with weakened hedge (LTWH). The syntax of LTWHs is defined by a set of hedges and a set of linguistic terms. The semantics of a LTWH is determined, objectively, based on the semantics of the term and a similarity measure of the reference domain. Accordingly, the negation, order relations and some basic operations of LTWHs are defined. To illustrate the effectiveness of LTWHs in granular computing, the connection to some multi-granularity linguistic models is exploited and a process for unifying multi-granularity linguistic information is developed. The major contritions of this paper are: (1) The proposed model enables a new manner to express and operate uncertain linguistic information in QDM; (2) it possesses clear syntax and semantics and the computational results are very interpretable; and (3) the proposed solution of multi-granularity linguistic unification maintains the semantics of the original linguistic information.}
}
@incollection{SUKHAI2017249,
title = {22 - Simulation learning},
editor = {Mahadeo A. Sukhai and Chelsea E. Mohler},
booktitle = {Creating a Culture of Accessibility in the Sciences},
publisher = {Academic Press},
pages = {249-255},
year = {2017},
isbn = {978-0-12-804037-9},
doi = {https://doi.org/10.1016/B978-0-12-804037-9.00022-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012804037900022X},
author = {Mahadeo A. Sukhai and Chelsea E. Mohler},
keywords = {Simulation learning, accommodation, teaching tool, computer technology, application of best practices},
abstract = {Simulation learning can be a valuable tool deployed in support of the learning of students with disabilities in the sciences. In thinking about simulation learning, we must consider two scenarios: (1) When simulation learning will benefit a student with a disability, because other accommodation methods are not appropriate or feasible; and, (2) When simulation learning is applied to all students, where accessibility considerations of the simulation must be taken into account for students with disabilities in the class. In this chapter, we will review the application of both scenarios for simulation learning to students with disabilities in the sciences.}
}
@article{JADHAV2022127935,
title = {Scale-up of the bioelectrochemical system: Strategic perspectives and normalization of performance indices},
journal = {Bioresource Technology},
volume = {363},
pages = {127935},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2022.127935},
url = {https://www.sciencedirect.com/science/article/pii/S0960852422012688},
author = {Dipak A. Jadhav and Ashvini D. Chendake and Vandana Vinayak and Abdulaziz Atabani and Mohammad {Ali Abdelkareem} and Kyu-Jung Chae},
keywords = {Energy balance, Microbial electrochemical technology, Net energy recovery, Normalization of performance, Resource recovery, Techno-economic feasibility},
abstract = {Electrochemists and ecological engineers find environmental bioelectrochemistry appealing; however, there is a big gap between expectations and actual progress in bioelectrochemical system (BES). Implementing such technology opens new opportunities for novel electrochemical reactions for resource recovery and effective wastewater treatment. Loopholes of BES exist in its scaling-up applications, and numerous attempts toward practical applications (200, 1000, and 1500 L) are key successive indicators toward its commercialization. This review emphasized the critical rethinking of standardization of performance indices i.e. current generation (A/m2), net energy recovery (kWh/kg·COD), product/resource yield (mM), and economic feasibility ($/kWh) to make fair comparison with the existing treatment system. Therefore, directional perspectives, including modularity, energy-cost balance, energy and resource recovery, have been proposed for the sustainable market of BES. The current state of the art and up-gradation in resource recovery and contaminant removal warrants a systematic rethinking of functional worth and niches of BES for practical applications.}
}
@article{MAHMOUD202263,
title = {Where to from here? On the future development of autonomous vehicles from a cognitive systems perspective},
journal = {Cognitive Systems Research},
volume = {76},
pages = {63-77},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000444},
author = {Sara Mahmoud and Erik Billing and Henrik Svensson and Serge Thill},
keywords = {Artificial cognition, Self-driving cars, Cognitive paradigms},
abstract = {Self-driving cars not only solve the problem of navigating safely from location A to location B; they also have to deal with an abundance of (sometimes unpredictable) factors, such as traffic rules, weather conditions, and interactions with humans. Over the last decades, different approaches have been proposed to design intelligent driving systems for self-driving cars that can deal with an uncontrolled environment. Some of them are derived from computationalist paradigms, formulating mathematical models that define the driving agent, while other approaches take inspiration from biological cognition. However, despite the extensive work in the field of self-driving cars, many open questions remain. Here, we discuss the different approaches for implementing driving systems for self-driving cars, as well as the computational paradigms from which they originate. In doing so, we highlight two key messages: First, further progress in the field might depend on adapting new paradigms as opposed to pushing technical innovations in those currently used. Specifically, we discuss how paradigms from cognitive systems research can be a source of inspiration for further development in modelling driving systems, highlighting emergent approaches as a possible starting point. Second, self-driving cars can themselves be considered cognitive systems in a meaningful sense, and are therefore a relevant, yet underutilized resource in the study of cognitive mechanisms. Overall, we argue for a stronger synergy between the fields of cognitive systems and self-driving vehicles.}
}
@article{THEOFILIDIS2024219,
title = {Mental Imagery: Investigating the Limits of Mental Partitioning},
journal = {Revista Colombiana de Psiquiatría (English ed.)},
volume = {53},
number = {3},
pages = {219-228},
year = {2024},
issn = {2530-3120},
doi = {https://doi.org/10.1016/j.rcpeng.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2530312024000602},
author = {Antonios Theofilidis and Maria-Valeria Karakasi and Filippos Kargopoulos},
keywords = {Mental imagery, Mental partitioning, Memory, Cognition, Neuroscience, Imaginería mental, Partición mental, Memoria, Cognición, Neurociencia},
abstract = {Introduction
Do we form mental models which bear an analogical relation to the real world like those of a photograph? Has the language of thought an analogue nature (it makes use of mental imagery) or whether it is exclusively of digital nature like language?
Objectives
The basic aim of the present study is to contribute to the ongoing work on mental imagery by extending the research to an unexplored area that of mental partitioning.
Methods
The present research sample consisted of 498 participants (234 males and 264 females). We used the SPSS software package in order to analyze our data.
Results
According to our results, we detected significant peculiarities in the cognitive performance of the participants in the tasks of mental partitioning of the Moebius strip, indicating certain limitations inherent in human thinking.
Conclusions
The position we are led to adopt is closer to that of Pylyshyn (2003), who maintained that visual mental imagery depends on abstract form of thought and on previous knowledge. Specifically, it rests on previous abstract propositional thought and knowledge rather than on concrete perceptual processes like the ones proposed by Kosslyn and Sheppard. The present work investigates a potentially valuable theoretical basis in imagery research for understanding maladaptive imagery across various related clinical disorders, while encouraging multidisciplinary approaches among cognitive psychological/neuroscientific and clinical domains.
Resumen
Introducción
¿Formamos modelos mentales que guardan una relación analógica con el mundo real como los de una fotografía? ¿Tiene el lenguaje del pensamiento una naturaleza analógica (hace uso de imágenes mentales) o es exclusivamente de naturaleza digital como el lenguaje?
Objetivos
El objetivo básico del presente estudio es contribuir al trabajo en curso sobre la imaginería mental extendiendo la investigación a un área inexplorada que es la partición mental.
Métodos
La muestra de la presente investigación estuvo compuesta por 498 participantes (234 varones y 264 mujeres). Usamos el paquete de software SPSS® para analizar nuestros datos.
Resultados
De acuerdo con nuestros resultados, detectamos peculiaridades significativas en el desempeño cognitivo de los participantes en las tareas de partición mental de la tira de Moebius, indicando ciertas limitaciones inherentes al pensamiento humano.
Conclusiones
La posición a la que nos vemos llevados a adoptar se acerca más a la de Pylyshyn (2003), quien sostenía que la imaginería mental visual depende de formas abstractas de pensamiento y de conocimientos previos. Específicamente, se basa en el pensamiento y el conocimiento proposicionales abstractos previos más que en procesos de percepción concretos como los propuestos por Kosslyn y Sheppard. El presente trabajo investiga una base teórica potencialmente valiosa en la investigación de imágenes para comprender las imágenes desadaptativas en varios trastornos clínicos relacionados, al tiempo que fomenta enfoques multidisciplinarios entre los dominios cognitivos psicológicos/neurocientíficos y clínicos.}
}
@article{KHAN2024e31470,
title = {Catch-up growth with alpha and beta decoupling and their relationships between CO2 emissions by GDP, population, energy production, and consumption},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31470},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31470},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024075017},
author = {Rabnawaz Khan},
keywords = {Economic growth, Alpha and beta decoupling, CO emissions, Energy production and consumption, Populace},
abstract = {This study explores the relationship between CO2 emissions by GDP, population, energy production, and consumption in the United States, China, Romania, and Thailand economies from 1990 to 2019. It evaluates the phenomenon of catch-up growth, which transpires when an lagging economy goes through an expansionary phase after a period of below-average performance. We used the stochastic model to illustrate in terms of alpha and beta decoupling techniques. The outcomes validated by positive and negative decoupling attitudes play a crucial role in predicting a rise in CO2 emissions owing to oil, gas, and coal use in comparison to Romania. Thailand and Romania have a more viable road to sustainability than the United States and China. The United States and China appear to have an antagonistic relationship, as suggested by decoupling attitudes. Thailand and Romania are considered to be highly environmentally sustainable countries on account of their minimal carbon emissions, efficient energy usage, and forward-thinking environmental policies. Accordingly, policy recommendations are offered based on CO2 emissions and effective mitigation policies, since this allows for determining which countries with high emissions need technological advances, best practices, and intersectoral policies.}
}
@article{PRASAD2023104,
title = {Irrigation development under uncertainty: A call for adaptive investment pathways},
journal = {Environmental Science & Policy},
volume = {140},
pages = {104-110},
year = {2023},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122003653},
author = {Pooja Prasad and Annelieke Duker and Charlotte {de Fraiture} and Pieter {van der Zaag}},
keywords = {Adaptation pathways, Irrigation, Investments, Uncertainty, Development, Sub-Saharan Africa},
abstract = {There is an urgent need in sub-Saharan Africa (SSA) to enhance irrigation access to meet the challenges of growing population and climate risk. To achieve this, big investments are currently planned in large irrigation infrastructure. We believe there is danger in following this conventional approach, which requires big lumpsum investments, locking large capital into projects that do not adapt to deep uncertainties from climatic or socio-political factors. Instead, in this Perspective article, we propose an alternate “adaptive investment pathways” (AdIP) approach for planning step-wise investments towards desired objectives, implemented progressively depending on how the future unfolds, in order to gain flexibility. AdIP extends the adaptation pathways concept, which refers to a sequence of actions to be taken in response to a changing reality, and applies it to the context of development under uncertainty. Monitoring and learning is at the heart of this approach, which ensures that the plan adapts as new knowledge becomes available. Thus, AdIP internalizes risk and reduces chances of failures. For financial institutions backing development projects, following a pathway of smaller de-centralized investments lowers risk and incorporates a learning approach that allows re-thinking and adapting along the path. We illustrate the AdIP approach using the case of ephemeral sand river based small-scale irrigation in the drylands of SSA. We conclude that in face of deep uncertainties, the path to successful irrigation development in SSA requires a shift from making few large upfront investments in large-scale projects to making large numbers of smaller investments that assure flexibility.}
}
@article{ALLISON2018147,
title = {Dilemmas of modelling and decision-making in environmental research},
journal = {Environmental Modelling & Software},
volume = {99},
pages = {147-155},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217300749},
author = {Andrew E.F. Allison and Mark E. Dickson and Karen T. Fisher and Simon F. Thrush},
keywords = {Wicked problems, Agent-based modelling, Post-normal science, Social-ecological systems, Shallow coastal systems},
abstract = {Multiple dilemmas confound social-ecological modelling. This review paper focuses on two: a modeller's dilemma associated with determining appropriate levels of model simplification, and a dilemma of decision-making relating to the use of models that were never designed to predict. We analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling. Simplified inter- and trans-disciplinary models have the potential to identify directions of system change, challenge thinking in disciplinary silos, and ultimately confront the dilemmas of social-ecological modelling.}
}
@article{ROGOWSKI2024109246,
title = {Unlocking massively parallel spectral proper orthogonal decompositions in the PySPOD package},
journal = {Computer Physics Communications},
volume = {302},
pages = {109246},
year = {2024},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2024.109246},
url = {https://www.sciencedirect.com/science/article/pii/S0010465524001693},
author = {Marcin Rogowski and Brandon C.Y. Yeung and Oliver T. Schmidt and Romit Maulik and Lisandro Dalcin and Matteo Parsani and Gianmarco Mengaldo},
keywords = {Spectral proper orthogonal decomposition, SPOD, Parallel, Distributed, MPI, Modal decomposition, Dynamical systems},
abstract = {We propose a parallel (distributed) version of the spectral proper orthogonal decomposition (SPOD) technique. The parallel SPOD algorithm distributes the spatial dimension of the dataset preserving time. This approach is adopted to preserve the non-distributed fast Fourier transform of the data in time, thereby avoiding the associated bottlenecks. The parallel SPOD algorithm is implemented in the PySPOD library and makes use of the standard message passing interface (MPI) library, implemented in Python via mpi4py. An extensive performance evaluation of the parallel package is provided, including strong and weak scalability analyses. The open-source library allows the analysis of large datasets of interest across the scientific community. Here, we present applications in fluid dynamics and geophysics, that are extremely difficult (if not impossible) to achieve without a parallel algorithm. This work opens the path toward modal analyses of big quasi-stationary data, helping to uncover new unexplored spatio-temporal patterns.
Program summary
Program Title: PySPOD CPC Library link to program files: https://doi.org/10.17632/jf5bf26jcj.1 Developer's repository link: https://github.com/MathEXLab/PySPOD Licensing provisions: MIT License Programming language: Python Nature of problem: Large spatio-temporal datasets may contain coherent patterns that can be leveraged to better understand, model, and possibly predict the behavior of complex dynamical systems. To this end, modal decomposition methods, such as the proper orthogonal decomposition (POD) and its spectral counterpart (SPOD), constitute powerful tools. The SPOD algorithm allows the systematic identification of space-time coherent patterns. This can be used to understand better the physics of the process of interest, and provide a path for mathematical modeling, including reduced order modeling. The SPOD algorithm has been successfully applied to fluid dynamics, geophysics and other domains. However, the existing open-source implementations are serial, and they prevent running on the increasingly large datasets that are becoming available, especially in computational physics. The inability to analyze via SPOD large dataset in turn prevents unlocking novel mechanisms and dynamical behaviors in complex systems. Solution method: We provide an open-source parallel (MPI distributed) code, namely PySPOD, that is able to run on large datasets (the ones considered in the present paper reach about 200 Terabytes). The code is built on the previous serial open-source code PySPOD that was published in https://joss.theoj.org/papers/10.21105/joss.02862.pdf. The new parallel implementation is able to scale on several nodes (we show both weak and strong scalability) and solve some of the bottlenecks that are commonly found at the I/O stage. The current parallel code allows running on datasets that was not easy or possible to analyze with serial SPOD algorithms, hence providing a path towards unlocking novel findings in computational physics. Additional comments including restrictions and unusual features: The code comes with a set of built-in postprocessing tools, for visualizing the results. It also comes with extensive continuous integration, documentation, and tutorials, as well as a dedicated website in addition to the associated GiHub repository. Within the package we also provide a parallel implementation of the proper orthogonal decomposition (POD), that leverages the I/O parallel capabilities of the SPOD algorithm.}
}