@article{CAMARENA2020122574,
title = {Artificial intelligence in the design of the transitions to sustainable food systems},
journal = {Journal of Cleaner Production},
volume = {271},
pages = {122574},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.122574},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620326214},
author = {Stéphanie Camaréna},
keywords = {Artificial intelligence, Design ethics, Transdisciplinary research, Design for sustainability, Sustainable food systems, Systems thinking},
abstract = {Food systems and our ability to secure food and nutrition for current and future generations is challenged by population growth, climate change, resource depletion and pollution. The current agricultural and supply chain systems are one of the main contributors to the issues. Transformational, not incremental change is needed to transition to sustainable food systems capable of feeding close to 10 billion people in less than 30 years. Artificial intelligence (AI) is pervading all parts of food systems in ways that indicate transformative system changes are possible. Designers, as mediators between people, technology and the environment have a responsibility to recognise and reflect on ways AI could bring the change needed to move to sustainable food systems. This literature review is situated at the intersection of Food systems, Design, Artificial Intelligence and Sustainability. The transdisciplinary approach reveals what exists across the disciplines, what can be done with AI to transition to sustainable food systems, how Design proposes to approach the change, and which ethical or philosophical considerations start to emerge. The discussion reflects on AI as a potential leverage point to bring changes in the system and on the designer's role in establishing the human-technology-environmental relationships. Further research and recommendations are provided.}
}
@article{WANG2016747,
title = {Towards felicitous decision making: An overview on challenges and trends of Big Data},
journal = {Information Sciences},
volume = {367-368},
pages = {747-765},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516304868},
author = {Hai Wang and Zeshui Xu and Hamido Fujita and Shousheng Liu},
keywords = {Big Data, Data deluge, Decision making, Data analysis, Data-intensive applications, Computational social science},
abstract = {The era of Big Data has arrived along with large volume, complex and growing data generated by many distinct sources. Nowadays, nearly every aspect of the modern society is impacted by Big Data, involving medical, health care, business, management and government. It has been receiving growing attention of researches from many disciplines including natural sciences, life sciences, engineering and even art & humanities. It also leads to new research paradigms and ways of thinking on the path of development. Lots of developed and under-developing tools improve our ability to make more felicitous decisions than what we have made ever before. This paper presents an overview on Big Data including four issues, namely: (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art techniques for decision making in Big Data; (iii) felicitous decision making applications of Big Data in social science; and (iv) the current challenges of Big Data as well as possible future directions.}
}
@article{GUO2025,
title = {Enhancing Doctor-Patient Shared Decision-Making: Design of a Novel Collaborative Decision Description Language},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/55341},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003152},
author = {XiaoRui Guo and Liang Xiao and Xinyu Liu and Jianxia Chen and Zefang Tong and Ziji Liu},
keywords = {shared decision-making, speech acts, agent, argumentation, interaction protocol},
abstract = {Background
Effective shared decision-making between patients and physicians is crucial for enhancing health care quality and reducing medical errors. The literature shows that the absence of effective methods to facilitate shared decision-making can result in poor patient engagement and unfavorable decision outcomes.
Objective
In this paper, we propose a Collaborative Decision Description Language (CoDeL) to model shared decision-making between patients and physicians, offering a theoretical foundation for studying various shared decision scenarios.
Methods
CoDeL is based on an extension of the interaction protocol language of Lightweight Social Calculus. The language utilizes speech acts to represent the attitudes of shared decision-makers toward decision propositions, as well as their semantic relationships within dialogues. It supports interactive argumentation among decision makers by embedding clinical evidence into each segment of decision protocols. Furthermore, CoDeL enables personalized decision-making, allowing for the demonstration of characteristics such as persistence, critical thinking, and openness.
Results
The feasibility of the approach is demonstrated through a case study of shared decision-making in the disease domain of atrial fibrillation. Our experimental results show that integrating the proposed language with GPT can further enhance its capabilities in interactive decision-making, improving interpretability.
Conclusions
The proposed novel CoDeL can enhance doctor-patient shared decision-making in a rational, personalized, and interpretable manner.}
}
@incollection{KALBFLEISCH2010641,
title = {2.33 - Genomics, Bioinformatics, and Computational Biology},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {641-661},
year = {2010},
isbn = {978-0-08-046884-6},
doi = {https://doi.org/10.1016/B978-0-08-046884-6.00236-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780080468846002360},
author = {T.S. Kalbfleisch and G.A. Rempala and K.S. Ramos},
abstract = {In this chapter, we describe how computational biology can be aided by informatics infrastructure to provide the basis for in silico studies that no longer require the generation of data, and instead facilitate the collection, organization, and analysis of existing datasets that can drive discovery. A new reality is that we are awash in data and tools to analyze these data and one of the most significant challenges is that of enabling the researcher to discover datasets relevant to their work, collect these data, assess its quality, and analyze it. The development of an adequate infrastructure within a researcher’s institution greatly facilitates progress on this front, both in terms of the development of tools and the development of local informatics expertise necessary to complement the domain-specific expertise of the researcher. As an informatics community we often ponder the heterogeneity of tools and resources on a global scale at the expense of the more immediate local problems encountered on a routine basis. Here, we suggest that getting our own houses in order by first employing interoperable solutions that support and facilitate collaboration amongst the complementary disciplines within our own institutions places the informatics community in a better position to address global informatics challenges. This approach can ensure that the solutions implemented employ an architecture and standards that support interoperability. Indeed, this is an organizational and cultural challenge rather than a technological one. Organizational structure and practices are described that provide a comprehensive base of talent capable of creating an environment that supports a sustainable informatics infrastructure, and that can quickly grow as needed to support the specific and rapidly evolving needs unique to that institution.}
}
@article{BOELSENROBINSON2021102032,
title = {Mapping factors associated with a successful shift towards healthier food retail in community-based organisations: A systems approach},
journal = {Food Policy},
volume = {101},
pages = {102032},
year = {2021},
issn = {0306-9192},
doi = {https://doi.org/10.1016/j.foodpol.2021.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0306919221000105},
author = {Tara Boelsen-Robinson and Miranda R. Blake and Andrew D. Brown and Oliver Huse and Claire Palermo and Neetu A. George and Anna Peeters},
keywords = {Food retail, Systems mapping, Intervention, Community, Implementation, START map, Nutrition, Policy, Qualitative, Interviews},
abstract = {Background
Food retailers in community settings are gatekeepers to the crucial food systems changes needed to improve population nutrition. Evidence-based models of change are needed to enable shifts in these complex retail environments. Systems thinking offers unique insights by capturing potential unintended consequences and multiple pathways to success. This study sought to create a systems map for retailers, public health practitioners and other stakeholders seeking to implement healthy food retail policies. It aimed to identify (i) points of intervention through which community-based organisations can shift to healthier food provision, and (ii) key feedback loops that could drive potential unintended consequences of such policies in a complex system.
Methods
Semi-structured interviews (n = 26) were conducted, from 2015 to 2018, across four community food retail settings where healthy food retail policies had been implemented in Victoria, Australia. Interviews were coded by identifying causal relationships and their direction between factors. Vensim software was used to merge interview results and then reduce the map to the strongest and most frequent factors and relationships. Illustrative implementation stories and points of intervention were identified.
Findings
The resulting map is titled the Systems Thinking Approach for Retail Transformation (START) map. Five prominent implementation stories incorporating 17 factors highlighted that: 1) retailer resistance to change is strongest in the beginning but decreases with the demonstration of favourable initiative outcomes; 2) successive changes tend to be increasingly complex, and therefore harder for retailers to implement; 3) organisational resourcing can be influenced through multiple pathways; 4) customer acceptability of healthy changes and retailers' willingness to engage in changes influence each other; and 5) challenges in accessing healthy supply options make retailers more resistant to implementing healthy changes.
Conclusions
The application of systems thinking to the challenge of unhealthy food retail creates novel and practical insights for retailers and health promotion practitioners into what actions are most likely to promote healthy changes in complex retail environments.}
}
@article{CARNEY2004135,
title = {Denis Noble discusses his career in computational biology},
journal = {Drug Discovery Today: BIOSILICO},
volume = {2},
number = {4},
pages = {135-137},
year = {2004},
issn = {1741-8364},
doi = {https://doi.org/10.1016/S1741-8364(04)02414-X},
url = {https://www.sciencedirect.com/science/article/pii/S174183640402414X},
author = {Stephen Carney},
keywords = {Interview, computer modeling, grid computing, cardiac electrophysiology, whole organ models, arrhythmia},
abstract = {Denis Noble was born in 1936 and obtained a BSc and PhD from University College London. He is one of the pioneers of computational biology related to cardiac cell electrophysiology and its incorporation into the first detailed biophysical models of the whole organ. He has made many major contributions to this work spanning from his groundbreaking work in 1960, showing that in heart, contrary to the situation in nerve, the first effect of membrane depolarisation is to greatly reduce potassium conductance, which in turn is greatly dependent on plasma potassium levels. His work over the last forty years has culminated in a highly successful virtual model of the heart, which has allowed theoretical interpretation of cardiac arrhythmias and the development of antiarrhythmic drugs. Professor Noble was made a fellow of the Royal Society in 1979, one of the highlights of his many awards. He is in great demand as a presenter of plenary lectures at many august meetings. In addition to his abilities as a computational biologist, Professor Noble is an accomplished linguist and has given lectures in French and Italian, and has significant abilities in Japanese, Korean and even Maori.}
}
@article{LAZARO2021111384,
title = {Policy and governance dynamics in the water-energy-food-land nexus of biofuels: Proposing a qualitative analysis model},
journal = {Renewable and Sustainable Energy Reviews},
volume = {149},
pages = {111384},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111384},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121006699},
author = {Lira Luz Benites Lazaro and Leandro Luiz Giatti and Celio Bermann and Angelica Giarolla and Jean Ometto},
keywords = {Water–energy–food nexus, Nexus thinking, Governance, Policy, Biofuels, Nexus methodology, Nexus method, Innovation},
abstract = {The production of biofuels is inextricably linked with the water-energy-food-land (WEFL) nexus. Understanding these linkages is necessary to formulate effective policies that can influence positive outcomes and contribute to the realization of long-term economic, environmental, and social goals. The use of biofuels can help achieve the United Nation's Sustainable Development Goals (SDGs) and implement the Paris Agreement on climate change. However, the biofuels sector must account for its interdependencies and trade-offs with other sectors. In this study, we formulate a qualitative analytical model that goes beyond the three water-energy-food nexus components by incorporating other elements, such as policy, innovation, governance, and labor to examine their effect as influencing factors and to understand how synergies, trade-offs, and long-overlooked interlinkages between sectors and among existing policies and institutions can become visible. This qualitative model was applied to the case of ethanol in Brazil, for which a large corpus was constructed from the scientific literature, documents and sustainability reports from sugarcane ethanol companies. We used a supervised latent Dirichlet allocation (sLDA) algorithm along with co-occurrence and network analyses. The results demonstrate this approach can be used to evaluate the interfaces between science, policy, and businesses within the WEFL-biofuels nexus. This is done by identifying how best to integrate the development of policies, governance, and stakeholder actions to support cost-effective decisions for optimal resource management and regulatory processes while enabling better integration of scientific insight and policy-making. We also identified how these four influencing factors are of vital importance within the nexus and, if properly addressed, can contribute to more holistic nexus thinking management.}
}
@article{IMJAI2025100308,
title = {Fraud detection skills of Thai Gen Z accountants: The roles of digital competency, data science literacy and diagnostic skills},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100308},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000971},
author = {Narinthon Imjai and Watcharawat Promma and Nimnual Visedsun and Berto Usman and Somnuk Aujirapongpan},
keywords = {Fraud detection skills, Digital competency, Data science literacy, Diagnostic skills, Thai Gen Z accountants},
abstract = {The issue of accounting fraud presents a significant challenge within the business sector, prompting an increase in scholarly investigations across various contexts. Despite this growing interest, research specifically addressing the Thai context has remained scarce. Thus, this quantitative study aimed to bridge this gap by assessing the proficiency of Thai Gen Z accountants in detecting accounting fraud, with a particular emphasis on their digital, data science, and diagnostic skills. The study collected data from 150 participants using a structured survey questionnaire distributed to licensed accountants affiliated with the Thailand accounting program. It adopted a theoretical framework inspired by social learning theory and information processing theory to examine both direct and mediated relationships among the key variables under investigation. The results were analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM) to examine these relationships. The results showed that digital competency have significant direct effects on the fraud detection skills, with diagnostic skills playing a key role in the process. The study revealed that digital competency not only furnishes accountants with necessary technological expertise but also bolsters their analytical skills, which are vital for identifying fraudulent activities. Likewise, data science literacy—encompassing skills in predictive analytics, big data management, and data insight communication—significantly enhances accountants' capacity to identify and understand fraudulent patterns. The emergent role of diagnostic skills as a key intermediary emphasizes the importance of comprehensive training programs that foster both technical prowess and critical analytical thinking.}
}
@article{WEBB2008360,
title = {The role of teacher instructional practices in student collaboration},
journal = {Contemporary Educational Psychology},
volume = {33},
number = {3},
pages = {360-381},
year = {2008},
note = {Collaborative Discourse, Argumentation, and Learning},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2008.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X0800026X},
author = {Noreen M. Webb and Megan L. Franke and Marsha Ing and Angela Chan and Tondra De and Deanna Freund and Dan Battey},
keywords = {Instructional practices, Student collaboration},
abstract = {Prior research on collaborative learning identifies student behaviors that significantly predict student achievement, such as giving explanations of one’s thinking. Less often studied is the role of teachers’ instructional practices in collaboration among students. This article investigates the extent to which teachers engage in practices that support students’ explanations of their thinking, and how these teacher practices might be related to the nature of explanations that students give when asked by the teacher to collaborate with each other. The teachers observed here, all of whom received specific instruction in eliciting the details of student thinking, varied significantly in the extent to which they asked students to elaborate on their suggestions. This variation corresponded to variation across classrooms in the nature and extent of student explanations during collaborative conversations and to differences in student achievement.}
}
@incollection{MAURYA2010175,
title = {Chapter 8 - Computational Challenges in Systems Biology},
editor = {Edison T. Liu and Douglas A. Lauffenburger},
booktitle = {Systems Biomedicine},
publisher = {Academic Press},
address = {San Diego},
pages = {175-223},
year = {2010},
isbn = {978-0-12-372550-9},
doi = {https://doi.org/10.1016/B978-0-12-372550-9.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123725509000080},
author = {Mano Ram Maurya and Shankar Subramaniam},
abstract = {Publisher Summary
This chapter examines the challenges and some of the recent advances in computational systems biology. Research in computational systems biology has moved beyond interaction networks based simply on clustering and correlation. There are two paradigms in computational systems biology: the iterative cycle of biochemical model—mathematical model—computational model, and integration of novel data and legacy knowledge to develop context-specific biochemical, mathematical, and computational models. Challenges in building biochemical models include the complexity of proteomic states and interactions, integration of diverse data to infer biochemical interactions, and the temporal state of biochemical models. Challenges in building mathematical models include incorporating statistical/probabilistic information into analytical models, using qualitative constraints in mathematical models, and incomplete knowledge and coarse-graining. Challenges in computational modeling include the absence of knowledge about model parameters such as rate constants, local versus global concentrations of species and multiple scales of distance and time, and variation among different cell types and subpopulation variability, or variability among biological repeats. Advanced research in coarse graining will pave the way for progress in the development of multiscale multidomain modeling that can connect fundamental research in network biology to clinical research.}
}
@article{SANTOS2023102749,
title = {Policy entrepreneurs in the global education complex: The case of Finnish education experts working in international organisations},
journal = {International Journal of Educational Development},
volume = {98},
pages = {102749},
year = {2023},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2023.102749},
url = {https://www.sciencedirect.com/science/article/pii/S0738059323000263},
author = {Íris Santos and Elias Pekkola},
keywords = {Development cooperation for education, Influence, Finnish education experts, Complexity, Multiple streams approach},
abstract = {This article analyses the perceived role of Finnish education experts working in development cooperation for education. We interviewed 31 education experts working in international organisations representing Finland. A theoretically pluralist approach is utilised combining complexity thinking with a multiple streams approach. The analysis demonstrates that the context of educational development cooperation is ambiguous and complex. Influencing policymaking is a strategic, non-linear task which takes time, resources, and personal skills. Policy entrepreneurs need to understand the dynamics of development cooperation, identify actors that trust them, and recognise when policy windows are likely to open.}
}
@article{AKTAYEVA2022285,
title = {Aesthetic education: the process of teaching mathematics with the open-source software},
journal = {Transportation Research Procedia},
volume = {63},
pages = {285-293},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522002708},
author = {Alena Aktayeva and Elena Zubareva and Aibek Dautov and Kymbat Saginbayeva and Rozamgul Niyazova and Sergey Khan and Aigerim Shonasheva},
keywords = {Aesthetic education, mathematical education, software, computer programs},
abstract = {In the article one of leading aims of educating mathematics is examined is aesthetic education of student facilities of mathematics. Presentation of aesthetic beauty at her decisions possibility of students is investigated, specifying them on the decision of one problem in several ways that assists the detailed consideration of idea of aesthetic education, through Open-source Software. The technical capabilities and elegant ease of use of systems Open-source Software provides a seamless, integrated and constantly expanding system that covers the breadth and depth of mathematical computing, and is available seamlessly through any web browser along with all modern systems used in the educational process. The article will describe understanding of beauty the decision of a problem; methods of decisions that are accompanied by the use make possible a uniquely flexible and convenient approach to charting and information visualization in a mathematical calculate. Such sort of activity assists aesthetic education, allowing to develop a culture and logical thinking, forming at students a different choice, grace of decision of problems.}
}
@incollection{MACWHINNEY2008229,
title = {CHAPTER 22 - Neurolinguistic Computational Models},
editor = {BRIGITTE STEMMER and HARRY A. WHITAKER},
booktitle = {Handbook of the Neuroscience of Language},
publisher = {Elsevier},
address = {San Diego},
pages = {229-236},
year = {2008},
isbn = {978-0-08-045352-1},
doi = {https://doi.org/10.1016/B978-0-08-045352-1.00022-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080453521000227},
author = {BRIAN MACWHINNEY and PING LI}
}
@article{HAWES201560,
title = {Effects of mental rotation training on children’s spatial and mathematics performance: A randomized controlled study},
journal = {Trends in Neuroscience and Education},
volume = {4},
number = {3},
pages = {60-68},
year = {2015},
issn = {2211-9493},
doi = {https://doi.org/10.1016/j.tine.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211949315000083},
author = {Zachary Hawes and Joan Moss and Beverly Caswell and Daniel Poliszczuk},
keywords = {Spatial thinking, Mental rotation, Spatial training, Computerized cognitive training, Mathematics education, STEM},
abstract = {The purpose of the current study was to (i) investigate the malleability of children’s spatial thinking, and (ii) the extent to which training-related gains in spatial thinking generalize to mathematics performance. Sixty-one 6- to 8-year-olds were randomly assigned to either computerized mental rotation training or literacy training. Training took place on iPad devices over a 6-week period as part of regular classroom activity. Results revealed that in comparison to the control group, children who received spatial training demonstrated significant gains on two measures of mental rotation and marginally significant improvements on an untrained mental transformation task; a finding that suggests that training may have had a general effect on children’s spatial ability. However, contrary to theoretical claims and prior empirical findings, there was no evidence that spatial training transferred to mathematics performance.}
}
@article{IWASE20211,
title = {Towards a Noncompliant Pedagogy of the Image: Reading Negentropic Bifurcatory Potentials in Video Images},
journal = {Video Journal of Education and Pedagogy},
volume = {6},
number = {1},
pages = {1-27},
year = {2021},
issn = {2364-4583},
doi = {https://doi.org/10.1163/23644583-bja10020},
url = {https://www.sciencedirect.com/science/article/pii/S236445832300023X},
author = {Masayuki Iwase and Joff P. N. Bradley},
keywords = {urban film-making, critique, metamodelization, global mnemotechnical system, proletarianized knowledge, mnemonic control, artificial and living engines, machinic enslavement, negentropic bifurcation, Deleuze, Heidegger, Virilio, time-image, lectosign, spiritual automation, zooming-in/out, autistic milieus, diffractive becoming, radical pedagogy},
abstract = {The authors explore the noncompliant pedagogy of the image based on their video Autopoietic Veering: Schizo Socius of Tokyo and Vancouver (2021). It is not the kind of trendy modelized video abstract or kinetic presentation eagerly promoted by international publishers; it is a cross-cultural collaborative work intended to generate affirmative temporal ruptures of entropic habitual modes of seeing, memorizing, and thinking of human and nonhuman life in the cities of Tokyo (Japan) and Vancouver (Canada). The authors elucidate Stiegler’s (2015b) concept of a “global mnemotechnical system” that stores and produces human memories in vast digital archives and databases (tertiary retentions) through “mnemonic control” (Parisi & Goodman, 2011). The authors repurpose video images to interrupt and recontrol human perception and memories as “living engines” (Lazzarato, 2006). They foreground the philosophical work of Deleuze, Heidegger, and Virilio to rethink and revive the creative act of “critique” (Foucault, 1997) through “metamodelization” (Guattari, 1995; Manning, 2020); therefore, they plug these apparently incommensurable modes of thinking into their readings of the video’s images. They read the images as “time-images” and focus on their five dimensions that possibly activate “spiritual automation” (Deleuze, 1989), which they assess as “negentropic bifurcatory” potentials (Bradley & Kennedy, 2019).}
}
@article{LOPEZORTEGA20133459,
title = {Computer-assisted creativity: Emulation of cognitive processes on a multi-agent system},
journal = {Expert Systems with Applications},
volume = {40},
number = {9},
pages = {3459-3470},
year = {2013},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.12.054},
url = {https://www.sciencedirect.com/science/article/pii/S095741741201295X},
author = {Omar López-Ortega},
keywords = {Computer-assisted creativity, Cognitive processes, Agent-oriented programming, Recursive systems},
abstract = {For creativity to be computed, it is paramount to understand the cognitive processes involved, which have been elucidated by either surveying creative people or discovering regions of the human brain that activate during creative endeavors. From this scattering, the author proposes a holistic framework to describe them and their interaction. Hence, creativity can be regarded as a meta process which coordinates autonomous cognitive processes such as planning or divergent thinking. To represent the interplay of cognitive processes around creativity, models are developed in the Agent Unified Modeling Language (AUML). Then, the execution of each process is delegated to autonomous agents and a global coordination protocol is devised. The implementation of the MAS is done on the JADE platform. Two modules of the resultant system are exemplified: opus planning and divergent exploration. The coordination protocol is also presented. The domain in which the software system is tested is the creation of musical pieces.}
}
@article{ZHENG2025192,
title = {The unbearable slowness of being: Why do we live at 10 bits/s?},
journal = {Neuron},
volume = {113},
number = {2},
pages = {192-204},
year = {2025},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324008080},
author = {Jieyu Zheng and Markus Meister},
keywords = {human behavior, speed of cognition, neural computation, bottleneck, attention, neural efficiency, information rate, memory sports},
abstract = {Summary
This article is about the neural conundrum behind the slowness of human behavior. The information throughput of a human being is about 10 bits/s. In comparison, our sensory systems gather data at ∼109 bits/s. The stark contrast between these numbers remains unexplained and touches on fundamental aspects of brain function: what neural substrate sets this speed limit on the pace of our existence? Why does the brain need billions of neurons to process 10 bits/s? Why can we only think about one thing at a time? The brain seems to operate in two distinct modes: the “outer” brain handles fast high-dimensional sensory and motor signals, whereas the “inner” brain processes the reduced few bits needed to control behavior. Plausible explanations exist for the large neuron numbers in the outer brain, but not for the inner brain, and we propose new research directions to remedy this.}
}
@article{MUST20167,
title = {Predicting the Flynn Effect through word abstractness : Results from the National Intelligence Tests support Flynn's explanation},
journal = {Intelligence},
volume = {57},
pages = {7-14},
year = {2016},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0160289616300253},
author = {Olev Must and Aasa Must and Jaan Mikk},
keywords = {Flynn Effect, National Intelligence Tests, Abstract thinking, Guessing, Tork, Estonia},
abstract = {The current study investigates the Flynn Effect (FE) and its relation to abstract thinking ability. We compare two cohorts of Estonian students (1933/36, n=888; 2006, n=912) using the Concepts (Logical Selection) subtest of the Estonian adaptation of the National Intelligence Tests (NIT). The item presentation order of the subtest correlates with the abstractness of the words used in the items (r=.609) of the subtest. The different test results (right, wrong and missing answers) were analysed in order to make an estimate of the FE magnitude. The FE for abstract thinking ability of those samples was 1.06 Hedges' g (adjusted for guessing). The magnitude of the FE is dependent upon the degree of difficulty of the items (an item's difficulty is estimated by determining its abstractness and its familiarity to students). The more difficult part of the subtest (the second half) showed a FE=1.80 whereas the easier part (the first half) of the subtest showed a FE=.72. Word abstractness was a strong predictor of all the testing results in both cohorts (Beta=.700). The familiarity of words used in the test items has no correlation with the test results if word abstractness is controlled in both cohorts. Our findings support Flynn's explanation that the FE is primarily an indicator of the rise in abstract thinking ability.}
}
@article{CHATURVEDI2005694,
title = {Agent-based simulation for computational experimentation: Developing an artificial labor market},
journal = {European Journal of Operational Research},
volume = {166},
number = {3},
pages = {694-716},
year = {2005},
note = {Advances in Complex Systems Modeling},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2004.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0377221704004102},
author = {Alok Chaturvedi and Shailendra Mehta and Daniel Dolk and Rick Ayer},
keywords = {Artificial intelligence, Decision support systems, Simulation, Modelling systems and languages, Economics},
abstract = {This paper discusses the creation of an artificial labor market (ALM) as an agent-based simulation model. We trace the development of the ALM by adapting the traditional simulation life cycle into two main parts: the model phase and the simulation phase. In the modeling phase of the life cycle, we focus upon agent representation and specification within the virtual world. In the simulation phase, we discuss the use of scenario planning as the experimentation vehicle. Throughout, we use military recruit market as an example to illustrate the methodology. The benefits of the ALM are (1) it provides a virtual world for continuous computational experimentation, (2) it supports market segmentation by allowing “drilldowns” to finer and finer levels of granularity, and (3) when connected via a common OLAP interface to a “real world” counterpart, it facilitates a tightly integrated, persistent, “sense and respond” decision support functionality.}
}
@article{DUAN2024100234,
title = {Making waves: Knowledge and data fusion in urban water modelling},
journal = {Water Research X},
volume = {24},
pages = {100234},
year = {2024},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2024.100234},
url = {https://www.sciencedirect.com/science/article/pii/S2589914724000240},
author = {Haoran Duan and Jiuling Li and Zhiguo Yuan},
keywords = {Modelling, Data-driven, Machine learning, Hybrid model, Urban water systems},
abstract = {Mathematical modeling plays a crucial role in understanding and managing urban water systems (UWS), with mechanistic models often serving as the foundation for their design and operations. Despite the wide adoptions, mechanistic models are challenged by the complexity of dynamic processes and high computational demands. Data-driven models bring opportunities to capture system complexities and reduce computational cost, by leveraging the abundant data made available by recent advance in sensor technologies. However, the interpretability and data availability hinder their wider adoption. This paper advocates for a paradigm shift in the application of data-driven models within the context of UWS. Integrating existing mechanistic knowledge into data-driven modeling offers a unique solution that reduces data requirements and enhances model interpretability. The knowledge-informed approach balances model complexity with dataset size, enabling more efficient and interpretable modeling in UWS. Furthermore, the integration of mechanistic and data-driven models offers a more accurate representation of UWS dynamics, addressing lingering uncertainties and advancing modelling capabilities. This paper presents perspectives and conceptual framework on developing and implementing knowledge-informed data-driven modeling, highlighting their potential to improve UWS management in the digital era.}
}
@article{SVOZIL2005845,
title = {Computational universes},
journal = {Chaos, Solitons & Fractals},
volume = {25},
number = {4},
pages = {845-859},
year = {2005},
note = {TRANSFINITE PHYSICS Treading the Path of Cantor and Einstein A collection of papers in honour of the Egyptian Engineering Scientist},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2004.11.055},
url = {https://www.sciencedirect.com/science/article/pii/S0960077904007830},
author = {Karl Svozil},
abstract = {Suspicions that the world might be some sort of a machine or algorithm existing “in the mind” of some symbolic number cruncher have lingered from antiquity. Although popular at times, the most radical forms of this idea never reached mainstream. Modern developments in physics and computer science have lent support to the thesis, but empirical evidence is needed before it can begin to replace our contemporary world view.}
}
@article{CHENG2024104948,
title = {Exploring differences in self-regulated learning strategy use between high- and low-performing students in introductory programming: An analysis of eye-tracking and retrospective think-aloud data from program comprehension},
journal = {Computers & Education},
volume = {208},
pages = {104948},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104948},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002257},
author = {Gary Cheng and Di Zou and Haoran Xie and Fu Lee Wang},
keywords = {Introductory programming, Self-regulated learning strategies, Eye tracking, Retrospective think aloud, Higher education},
abstract = {Previous studies have reported mixed results regarding the relationship between students’ use of self-regulated learning (SRL) strategies and their performance in introductory programming courses. These studies were constrained by their reliance on self-report questionnaires as a means of collecting and analysing data. To address this limitation, this study aimed to employ eye-tracking and retrospective think-aloud techniques to identify differences in SRL strategy use for program comprehension tasks between high-performing students (N = 31) and low-performing students (N = 31) in an undergraduate programming course. All participants attended individual eye-tracking sessions to comprehend two Python program codes with different constructs. Their eye-tracking data and video-recalled retrospective think-aloud data were captured and recorded for analysis. The findings reveal that higher-order cognitive skills, such as elaboration and critical thinking, were mostly adopted by high-performing students, while basic cognitive and resource management strategy, such as rehearsal and help-seeking, were mostly employed by low-performing students when comprehending the program codes. This study not only demonstrates the design of combining eye-tracking and retrospective think-aloud data to explore students’ use of SRL strategies but also provides evidence to support the notion that program comprehension is a complex process that cannot be effectively addressed by employing merely rudimentary strategies, such as repetitively reading the same code segment. In the future, researchers could explore the possibility of using a webcam to monitor and assess students’ online programming processes and provide feedback based on their eye movements. They could also examine the effects of SRL strategies training on students’ motivation, engagement, and performance in various types of programming activities.}
}
@article{CRILLY2021309,
title = {The Evolution of “Co-evolution” (Part I): Problem Solving, Problem Finding, and Their Interaction in Design and Other Creative Practices},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {309-332},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000915},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Design history, Interdisciplinarity},
abstract = {One of the most influential descriptions of design activity emphasizes how problems and solutions “co-evolve.” This concept has somehow escaped critical review and cross-disciplinary comparison, resulting in a fragmented approach to the subject. Reviewing the published literature on design co-evolution reveals that the term is used to refer to a range of distinct concepts, and the study of co-evolution has generated a number of elaborations and alternatives. Reviewing the broader literature in design and other disciplines further reveals that discussions of design co-evolution are disconnected from the history of relevant concepts in design research, and disconnected from a range of relevant concepts in other disciplines that describe creative work. Here I examine what the different concepts of design co-evolution are, how they have been modified and what they are related to. This leads to questioning the distinction between problems and solutions, defining them in relative terms, and drawing a connection between design co-evolution and design fixation.}
}
@article{CHISCI1995487,
title = {Fast Computation of Stabilizing Predictive Control Laws},
journal = {IFAC Proceedings Volumes},
volume = {28},
number = {5},
pages = {487-493},
year = {1995},
note = {3rd IFAC/IFIP Workshop on Algorithms and Architectures for Real-Time Control 1995 (AARTC'95), Ostend, Belgium, 31 May-2 June 1995},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)47270-3},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017472703},
author = {L. Chisci and A. Garulli and G. Zappa},
keywords = {Predictive control, linear quadratic regulators, control algorithms, fast parallel algorithms, fast Kalman algorithms, computational methods, adaptive control},
abstract = {A fast algorithm for Linear Quadratic(LQ) control with linear equality constraints is derived and exploited for stabilizing predictive control synthesis. The algorithm requires only O(Nn) computations for an nth order plant and N-steps prediction horizon, and possesses a remarkable numerical accuracy.}
}
@article{PIAW20114019,
title = {Establishing a Brain Styles Test: The YBRAINS Test},
journal = {Procedia - Social and Behavioral Sciences},
volume = {15},
pages = {4019-4027},
year = {2011},
note = {3rd World Conference on Educational Sciences - 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.04.407},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811009530},
author = {Chua Yan Piaw},
keywords = {Brain style, thinking and learning, YBRAINS, validity and reliability},
abstract = {Teaching with knowledge of students’ thinking and learning styles increases its effectiveness. The YBRAINS test is developed to help school teachers to understand the thinking and learning readiness levels of their students in the process of providing effective teaching and learning activities. The test was established based on theories and brain experiment research evidences. This article reports the rationale of establishing the test and its validity and reliability.}
}
@article{LEE2021100737,
title = {Turbulent boundary layer trailing-edge noise: Theory, computation, experiment, and application},
journal = {Progress in Aerospace Sciences},
volume = {126},
pages = {100737},
year = {2021},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2021.100737},
url = {https://www.sciencedirect.com/science/article/pii/S0376042121000427},
author = {Seongkyu Lee and Lorna Ayton and Franck Bertagnolio and Stephane Moreau and Tze Pei Chong and Phillip Joseph},
keywords = {Trailing-edge noise, Aeroacoustics, Turbulent boundary layer},
abstract = {When the pressure fluctuations caused by turbulence vorticity in the boundary layer are scattered by a sharp trailing edge, acoustic energy is generated and propagated to the far field. This trailing edge noise is emitted from aircraft wings, turbomachinery blades, wind turbine blades, helicopter blades, etc. Being dominant at high frequencies, this trailing-edge noise is a key element that annoys human hearing. This article covers virtually the entire landscape of modern research into trailing-edge noise including theoretical developments, numerical simulations, wind tunnel experiments, and applications of trailing-edge noise. The theoretical approach includes Green’s function formulations, Wiener–Hopf methods that solve the mixed boundary-value problem, Howe’s and Amiet’s models that relate the wall pressure spectrum to acoustic radiation. Recent analytical developments for poroelasticity and serrations are also included. We discuss a hierarchy of numerical approaches that range from semi-empirical schemes that estimate the wall pressure spectrum using mean-flow and turbulence statistics to high-fidelity unsteady flow simulations such as Large Eddy Simulation (LES) or Direct Numerical Simulation (DNS) that resolve the sound generation and scattering process based on the first-principles flow physics. Wind tunnel experimental research that provided benchmark data for numerical simulations and unravel flow physics is reviewed. In each theoretical, numerical, and experimental approach, noise control methods for mitigating trailing-edge noise are discussed. Finally, highlights of practical applications of trailing-edge noise prediction and reduction to wind turbine noise, fan noise, and rotorcraft noise are given. The current challenges in each approach are summarized with a look toward the future developments. The review could be useful as a primer for new researchers or as a reference point to the state of the art for experienced professionals.}
}
@article{MILLER1993205,
title = {Educational tools for computational modelling},
journal = {Computers & Education},
volume = {21},
number = {3},
pages = {205-261},
year = {1993},
issn = {0360-1315},
doi = {https://doi.org/10.1016/0360-1315(93)90019-F},
url = {https://www.sciencedirect.com/science/article/pii/036013159390019F},
author = {Rob Miller and Jon Ogborn and Jonathan Briggs and Derek Brough and Joan Bliss and Richard Boohan and Tim Brosnan and Harvey Mellar and Babis Sakonidis},
abstract = {The paper reports both a theoretical analysis and a comparison of educational tools for computational modelling, and describes three prototype tools developed in the Programme for use in empirical studies of children reasoning with the aid of computational tools, together with an outline of the result obtained by using the tools with children.}
}
@article{CHU20181,
title = {Supporting scientific modeling through curriculum-based making in elementary school science classes},
journal = {International Journal of Child-Computer Interaction},
volume = {16},
pages = {1-8},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300545},
author = {Sharon Lynn Chu and Elizabeth Deuermeyer and Francis Quek},
keywords = {Making, Maker movement, Children, Science, Science models, Scientific modeling, Model thinking, Electronics, Programming},
abstract = {Our work investigates how Making may be used in the context of scientific modeling in formal elementary school science classes. This paper presents an investigation of fourth- and fifth-grade students engaging in Making activities to create simulation, concept-process, and illustrative models in the science classroom. Based on video analyses of the Making-based class sessions, a generalized process model was developed for each type of science model. In addition, cross-cutting themes were found in Making-based science modeling: first, there are two loops that intersect and interact with each other (modeling for Making and modeling for Science content), and they interrelate in various ways depending on science model type; and second, showcasing Making products (sharing with peers, teachers, or helpers) is a primary factor that determines students’ overall engagement with science in the activity. We suggest that Making-based science kit and lesson design needs to support students to showcase their Making output, on top of science-related reflections, and to consider the balance between Making and science activity. We conclude that Making has the potential to support the development of scientific model thinking in the elementary science classroom, but much further research is needed in this area.}
}
@article{ZILLES20101072,
title = {The computational complexity of avoiding spurious states in state space abstraction},
journal = {Artificial Intelligence},
volume = {174},
number = {14},
pages = {1072-1092},
year = {2010},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2010.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370210000950},
author = {Sandra Zilles and Robert C. Holte},
keywords = {Abstraction, Heuristic search, Planning},
abstract = {Abstraction is a powerful technique for speeding up planning and search. A problem that can arise in using abstraction is the generation of abstract states, called spurious states, from which the goal state is reachable in the abstract space but for which there is no corresponding state in the original space from which the goal state can be reached. Spurious states can be harmful, in practice, because they can create artificial shortcuts in the abstract space that slow down planning and search, and they can greatly increase the memory needed to store heuristic information derived from the abstract space (e.g., pattern databases). This paper analyzes the computational complexity of creating abstractions that do not contain spurious states. We define a property—the downward path preserving property (DPP)—that formally captures the notion that an abstraction does not result in spurious states. We then analyze the computational complexity of (i) testing the downward path preserving property for a given state space and abstraction and of (ii) determining whether this property is achievable at all for a given state space. The strong hardness results shown carry over to typical description languages for planning problems, including sas+ and propositional strips. On the positive side, we identify and illustrate formal conditions under which finding downward path preserving abstractions is provably tractable.}
}
@article{SELBY20001491,
title = {Computational Aspects of Complex Securities},
journal = {Journal of Economic Dynamics and Control},
volume = {24},
number = {11},
pages = {1491-1497},
year = {2000},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(99)00084-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188999000846},
author = {Michaël J.P Selby}
}
@article{ATALLAH2022B2,
title = {Society for Maternal-Fetal Medicine Special Statement: Cognitive bias and medical error in obstetrics—challenges and opportunities},
journal = {American Journal of Obstetrics and Gynecology},
volume = {227},
number = {2},
pages = {B2-B10},
year = {2022},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2022.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0002937822003143},
author = {Fouad Atallah and Rebecca F. Hamm and Christina M. Davidson and C. Andrew Combs},
keywords = {decision-making, diagnostic error, disparities, implicit bias, inequity, medical error, racism},
abstract = {The processes of diagnosis and management involve clinical decision-making. However, decision-making is often affected by cognitive biases that can lead to medical errors. This statement presents a framework of clinical thinking and decision-making and shows how these processes can be bias-prone. We review examples of cognitive bias in obstetrics and introduce debiasing tools and strategies. When an adverse event or near miss is reviewed, the concept of a cognitive autopsy—a root cause analysis of medical decision-making and the potential influence of cognitive biases—is promoted as part of the review process. Finally, areas for future research on cognitive bias in obstetrics are suggested.}
}
@incollection{VALLERO2024613,
title = {Chapter 20 - Future},
editor = {Daniel A. Vallero and Trevor M. Letcher},
booktitle = {Unraveling Environmental Disasters (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {613-634},
year = {2024},
isbn = {978-0-443-18651-6},
doi = {https://doi.org/10.1016/B978-0-443-18651-6.00004-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443186516000044},
author = {Daniel A. Vallero and Trevor M. Letcher},
keywords = {Deconstructing disasters, Failure, Integrated pest management (IPM), Land use, Maslow's hierarchy of needs, Information technology, Interoperability, Systems thinking, Spills, Life-cycle analysis, Design for the environment (DfE), Design for disassembly (DfD), Aesop's fables, Tragedy of the Commons, Triple bottom line, Categorical imperative},
abstract = {This chapter revisits the concept of disasters as failures introduced in Chapter 2. This entails approaches to consider the many factors and causes. System thinking is introduced as a means of preventing or reducing the damage of disasters. Systematic approaches must make use of various tools, including regulatory measures; economic incentives; property rights; infrastructure installment; public education; for international projects, international inspections; and cooperation. Disaster prevention and mitigation must integrate planning and engineering approaches, especially thoughtful land use. This also requires an understanding of how people expect to meet basic and advanced needs, as exemplified by Maslow's hierarchy. Other tools include optimizing information technologies and interoperability. The good news is that with education and consideration of past disasters, the implementation of rules and regulations there can be a reduction of number and severity of disasters; e.g., decrease in oil tanker spills over the past half century.}
}
@article{ELLIOT201878,
title = {A Proposal to Integrate System Dynamics and Carbon Metabolism for Urban Planning},
journal = {Procedia CIRP},
volume = {69},
pages = {78-82},
year = {2018},
note = {25th CIRP Life Cycle Engineering (LCE) Conference, 30 April – 2 May 2018, Copenhagen, Denmark},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2017.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212827117307618},
author = {Thomas Elliot and Benedetto Rugani and Javier Babí Almenar and Samuel Niza},
keywords = {Life-cycle thinking, system dynamics, urban metabolism, urban planning},
abstract = {Coupling of life-cycle thinking with urban metabolism (UM) has the potential to improve sustainable urban planning. Current urban metabolism models are largely ‘black-box’ methods which do not reveal the non-linearity of feedback loops and complex internal dynamics of urban systems. The integration of system dynamics (SD) with UM based on a life-cycle thinking approach can provide built environment professionals (e.g. town planners, civil engineers, architects) with a ‘transparent-box’ solution for assessing the potential of urban projects, plans, and their implementation. This paper describes the development of a method that integrates input-output (IO) table flows with SD modelling to improve the completeness of UM assessments. This modelling framework can also allow for a ‘nested’ multi-region assessment which takes into account sustainability burdens consequent to urban system changes occurring elsewhere in the national and/or global economy. Pros and cons of this proposal are showcased by the illustration of a model for Lisbon.}
}
@article{ZHANG2024,
title = {Crowdsourcing Adverse Events Associated With Monoclonal Antibodies Targeting Calcitonin Gene–Related Peptide Signaling for Migraine Prevention: Natural Language Processing Analysis of Social Media},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/58176},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24006255},
author = {Pengfei Zhang and Brad K Kamitaki and Thien Phu Do},
keywords = {internet, patient reported outcome, headache, health information, Reddit, registry, monoclonal antibody, crowdsourcing, postmarketing, safety, surveillance, migraine, preventives, prevention, self-reported, calcitonin gene–related peptide, calcitonin, therapeutics, social media, medication-related, posts, propranolol, topiramate, erenumab, fremanezumab, cross-sectional, surveys},
abstract = {Background
Clinical trials demonstrate the efficacy and tolerability of medications targeting calcitonin gene–related peptide (CGRP) signaling for migraine prevention. However, these trials may not accurately reflect the real-world experiences of more diverse and heterogeneous patient populations, who often have higher disease burden and more comorbidities. Therefore, postmarketing safety surveillance is warranted. Regulatory organizations encourage marketing authorization holders to screen digital media for suspected adverse reactions, applying the same requirements as for spontaneous reports. Real-world data from social media platforms constitute a potential venue to capture diverse patient experiences and help detect treatment-related adverse events. However, while social media holds promise for this purpose, its use in pharmacovigilance is still in its early stages. Computational linguistics, which involves the automatic manipulation and quantitative analysis of oral or written language, offers a potential method for exploring this content.
Objective
This study aims to characterize adverse events related to monoclonal antibodies targeting CGRP signaling on Reddit, a large online social media forum, by using computational linguistics.
Methods
We examined differences in word frequencies from medication-related posts on the Reddit subforum r/Migraine over a 10-year period (2010-2020) using computational linguistics. The study had 2 phases: a validation phase and an application phase. In the validation phase, we compared posts about propranolol and topiramate, as well as posts about each medication against randomly selected posts, to identify known and expected adverse events. In the application phase, we analyzed posts discussing 2 monoclonal antibodies targeting CGRP signaling—erenumab and fremanezumab—to identify potential adverse events for these medications.
Results
From 22,467 Reddit r/Migraine posts, we extracted 402 (2%) propranolol posts, 1423 (6.33%) topiramate posts, 468 (2.08%) erenumab posts, and 73 (0.32%) fremanezumab posts. Comparing topiramate against propranolol identified several expected adverse events, for example, “appetite,” “weight,” “taste,” “foggy,” “forgetful,” and “dizziness.” Comparing erenumab against a random selection of terms identified “constipation” as a recurring keyword. Comparing erenumab against fremanezumab identified “constipation,” “depression,” “vomiting,” and “muscle” as keywords. No adverse events were identified for fremanezumab.
Conclusions
The validation phase of our study accurately identified common adverse events for oral migraine preventive medications. For example, typical adverse events such as “appetite” and “dizziness” were mentioned in posts about topiramate. When we applied this methodology to monoclonal antibodies targeting CGRP or its receptor—fremanezumab and erenumab, respectively—we found no definite adverse events for fremanezumab. However, notable flagged words for erenumab included “constipation,” “depression,” and “vomiting.” In conclusion, computational linguistics applied to social media may help identify potential adverse events for novel therapeutics. While social media data show promise for pharmacovigilance, further work is needed to improve its reliability and usability.}
}
@article{KUMAR20101805,
title = {A generalized computational approach to stability of static equilibria of nonlinearly elastic rods in the presence of constraints},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {199},
number = {25},
pages = {1805-1815},
year = {2010},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2010.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045782510000654},
author = {Ajeet Kumar and Timothy J. Healey},
keywords = {Stability, Elasticity, Rods, Constraints},
abstract = {We present a generalized approach to stability of static equilibria of nonlinearly elastic rods, subjected to general loading, boundary conditions and constraints (of both point-wise and integral type), based upon the linearized dynamics stability criterion. Discretization of the governing equations leads to a non-standard (singular) generalized eigenvalue problem. A new efficient sparse-matrix-friendly algorithm is presented to determine its few left-most eigenvalues, which, in turn, yield stability/instability information. For conservative problems, the eigenvalue problem arising from the linearized dynamics stability criterion is also shown to be equivalent to that arising in the determination of constrained local minima of the potential energy. We illustrate the method with several examples. A novel variational formulation for extensible and unshearable rods is also proposed within the context of one of the example problems.}
}
@article{HABIB2020445,
title = {Computation Analysis of Brand Experience Dimensions: Indian Online Food Delivery Platforms},
journal = {Computers, Materials and Continua},
volume = {67},
number = {1},
pages = {445-462},
year = {2020},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2021.014047},
url = {https://www.sciencedirect.com/science/article/pii/S1546221820001575},
author = {Sufyan Habib and Nawaf N. Hamadneh and S. Al wadi and Ra’ed Masa’deh},
keywords = {Hypothesis tests, brand experience, online food delivery platform, statistical tests, COVID-19},
abstract = {Online Food Delivery Platforms (OFDPs) has witnessed phenomenal growth in the past few years, especially this year due to the COVID-19 pandemic. This Pandemic has forced many governments across the world to give momentum to OFD services and make their presence among the customers. The Presence of several multinational and national companies in this sector has enhanced the competition and companies are trying to adapt various marketing strategies and exploring the brand experience (BEX) dimension that helps in enhancing the brand equity (BE) of OFDPs. BEXs are critical for building brand loyalty (BL) and making companies profitable. Customers can experience different kinds of brand experiences through feeling, emotions, affection, behavior, and intellect. The present research work is taken up to analyze the factors affecting BEX and its impact on BL and BE of the OFDPs and analyze the mediating role of BL in the relationship between BEX and BE of the OFDPs in the Indian context. A survey of 457 Indian customers was carried out. A questionnaire was used for data collection and a mediation study was used to test hypothesized relationships. Our computational analysis reveals that BEX influences the BL and BE of OFDPs. The study further indicates that BL mediates the relationship between BEX and BE of OFDPs. The effective marketing and relationship management practices will help company to enhance BEX that will enable in enhancing BL and raising BE of their product. It therefore provides a more thorough analysis of BEX constructs and their consequences than previous research. Some of the managerial implication, limitations, and scope of future research are also presented in the study.}
}
@article{NOROOZI2019295,
title = {Multidisciplinary innovations and technologies for facilitation of self-regulated learning},
journal = {Computers in Human Behavior},
volume = {100},
pages = {295-297},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302638},
author = {Omid Noroozi and Sanna Järvelä and Paul A. Kirschner},
abstract = {Technology-enhanced learning environments provide ample opportunities for learners to self-regulate their learning processes and activities for achieving the intended learning outcomes in various disciplines from soft to hard sciences and from humanities to the natural and social sciences. This special issue discusses the emerging technological advancements and cutting-edge research on self-regulated learning dealing with different cognitive, motivational, emotional, and social processes of learning both at the individual and group levels. Specifically, it discusses how to optimally use advanced technologies to facilitate learners’ self-regulated learning for achieving their own individual learning needs and goals. In this special issue, seven researchers/research teams from the fields of collaborative learning, computational thinking, educational psychology, and learning analytics presented contributions to self-regulated learning with the goal of stimulating cross-border discussion in the field.}
}
@article{GALLISTEL201266,
title = {Extinction from a rationalist perspective},
journal = {Behavioural Processes},
volume = {90},
number = {1},
pages = {66-80},
year = {2012},
note = {Society for the Quantitative Analyses of Behavior: Extinction},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2012.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0376635712000447},
author = {C.R. Gallistel},
keywords = {Acquisition, Extinction, Partial reinforcement, Spontaneous recovery, Renewal, Reinstatement, Resurgence, Information theory, Bayesian inference},
abstract = {The merging of the computational theory of mind and evolutionary thinking leads to a kind of rationalism, in which enduring truths about the world have become implicit in the computations that enable the brain to cope with the experienced world. The dead reckoning computation, for example, is implemented within the brains of animals as one of the mechanisms that enables them to learn where they are (Gallistel, 1990, Gallistel, 1995). It integrates a velocity signal with respect to a time signal. Thus, the manner in which position and velocity relate to one another in the world is reflected in the manner in which signals representing those variables are processed in the brain. I use principles of information theory and Bayesian inference to derive from other simple principles explanations for: (1) the failure of partial reinforcement to increase reinforcements to acquisition; (2) the partial reinforcement extinction effect; (3) spontaneous recovery; (4) renewal; (5) reinstatement; (6) resurgence (aka facilitated reacquisition). Like the principle underlying dead-reckoning, these principles are grounded in analytic considerations. They are the kind of enduring truths about the world that are likely to have shaped the brain's computations.}
}
@article{AGRE19951,
title = {Computational research on interaction and agency},
journal = {Artificial Intelligence},
volume = {72},
number = {1},
pages = {1-52},
year = {1995},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0004370294000545},
author = {Philip E. Agre},
abstract = {Recent research in artificial intelligence has developed computational theories of agents' involvements in their environments. Although inspired by a great diversity of formalisms and architectures, these research projects are unified by a common concern: using principled characterizations of agents' interactions with their environments to guide analysis of living agents and design of artificial ones. This article offers a conceptual framework for such theories, surveys several other fields of research that hold the potential for dialogue with these new computational projects, and summarizes the principal contributions of the articles in this special double volume. It also briefly describes a case study in these ideas—a computer program called Toast that acts as a short-order breakfast cook. Because its designers have discovered useful structures in the world it inhabits, Toast can employ an extremely simple mechanism to decide what to do next.}
}
@article{NAJJAR19991907,
title = {Advances in the dataflow computational model},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {1907-1929},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00070-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000708},
author = {Walid A Najjar and Edward A Lee and Guang R Gao},
keywords = {Computational models, Dataflow, Multithreaded computer architecture, von Neumann computer, Dataflow history, Memory models},
abstract = {The dataflow program graph execution model, or dataflow for short, is an alternative to the stored-program (von Neumann) execution model. Because it relies on a graph representation of programs, the strengths of the dataflow model are very much the complements of those of the stored-program one. In the last thirty or so years since it was proposed, the dataflow model of computation has been used and developed in very many areas of computing research: from programming languages to processor design, and from signal processing to reconfigurable computing. This paper is a review of the current state-of-the-art in the applications of the dataflow model of computation. It focuses on three areas: multithreaded computing, signal processing and reconfigurable computing.}
}
@article{GREGOR19981481,
title = {A computational study of the focus-of-attention EM-ML algorithm for PET reconstruction1Research supported in part by the National Science Foundation under grant CDA-95-29459.1},
journal = {Parallel Computing},
volume = {24},
number = {9},
pages = {1481-1497},
year = {1998},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(98)00067-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167819198000672},
author = {Jens Gregor and Dean A. Huff},
keywords = {Distributed computing, Expectation-maximization, Image reconstruction, Positron emission tomography},
abstract = {The expectation-maximization maximum-likelihood (EM-ML) algorithm for image reconstruction in positron emission tomography (PET) essentially solves a large linear system of equations. In this paper, we study computational aspects of a recently developed preprocessing scheme for focusing the attention, and thus the computational resources, on a subset of the equations and unknowns in order to reduce the storage, computation, and communication requirements of the EM-ML algorithm. The approach is completely data-driven and uses no prior anatomic knowledge. The experimental results are obtained from runs on a small network of workstations using simulated phantom data as well as data obtained from a clinical ECAT 921 PET scanner.}
}
@incollection{CHORAFAS2004141,
title = {7 - Five models by the Basel Committee for computation of operational risk},
editor = {Dimitris N. Chorafas},
booktitle = {Operational Risk Control with Basel II},
publisher = {Butterworth-Heinemann},
address = {Oxford},
pages = {141-162},
year = {2004},
isbn = {978-0-7506-5909-3},
doi = {https://doi.org/10.1016/B978-075065909-3.50009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780750659093500098},
author = {Dimitris N. Chorafas},
abstract = {Publisher Summary
This chapter analyzes the four methods of capital allocation for operational risk by the Basel Committee on Banking Supervision: (1) the basic indicator approach, (2) standard approach, (3) internal measurement approach, and (4) loss distribution approach. The chapter also explains why the internal measurement approach and loss distribution approach require leadership in databasing and datamining. The chapter depicts these four methods for computation of operational risk charges on a double scale: expected amount of capital allocation and complexity. Valid solutions take account of different perspectives and definitions of operational risk. The way operational risk is managed is affected by the manner in it is viewed, added with how the board and CEO come to grips with operational risk, the skills and tools at the regulators' disposal, and the resolve to put the risk under lock and key. This is the reason why Basel II wants banks to put aside capital for operational risk control.}
}
@article{WATKINS200867,
title = {Specifying Properties of Concurrent Computations in CLF},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {199},
pages = {67-87},
year = {2008},
note = {Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages (LFM 2004)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2007.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108000790},
author = {Kevin Watkins and Iliano Cervesato and Frank Pfenning and David Walker},
keywords = {logical frameworks, type theory, linear logic, concurrency},
abstract = {CLF (the Concurrent Logical Framework) is a language for specifying and reasoning about concurrent systems. Its most significant feature is the first-class representation of concurrent executions as monadic expressions. We illustrate the representation techniques available within CLF by applying them to an asynchronous pi-calculus with correspondence assertions, including its dynamic semantics, safety criterion, and a type system with latent effects due to Gordon and Jeffrey.}
}
@article{CASTRO2006811,
title = {Patient-Specific Computational Modeling of Cerebral Aneurysms With Multiple Avenues of Flow From 3D Rotational Angiography Images},
journal = {Academic Radiology},
volume = {13},
number = {7},
pages = {811-821},
year = {2006},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2006.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1076633206001826},
author = {Marcelo A. Castro and Christopher M. Putman and Juan R. Cebral},
abstract = {Rationale and Objectives
Previous studies of aneurysm flow dynamics based on three-dimensional (3D) rotational angiography (RA) images were limited to aneurysms with a single route of blood inflow. However, aneurysms of the circle of Willis frequently involve locations with more than one source of inflow, such as aneurysms of the anterior communicating artery. The highest resolution images of cerebral vessels are from RA images, but this technique is limited to visualizing only one route of inflow at a time, leaving a significant limitation in the application of 3DRA image sets for clinical studies of patient-specific computational fluid dynamics (CFD) simulations. In this report, subject-specific models of cerebral aneurysms with multiple avenues of flow are constructed from RA images by using a novel combination of image coregistration and surface merging techniques.
Materials and Methods
RA images are obtained by means of contrast injection in each vessel that provides inflow to the aneurysm. Anatomic models are constructed independently of each of these vascular trees and fused together into a single model. The model is used to construct a finite element grid for CFD simulations of hemodynamics.
Results
Three examples of patient-specific models are presented: an anterior communicating artery aneurysm, a basilar tip aneurysm, and a model of an entire circle of Willis with five coincident aneurysms. The method is evaluated with a numeric phantom of an aneurysm in the anterior communicating artery.
Conclusion
These examples show that this new technique can be used to create merged network numeric models for CFD modeling. Furthermore, intra-aneurysmal flow patterns are influenced strongly by merging of the two inflow streams. This effect decreases as distance from the merging streams increases.}
}
@article{BERGER2016337,
title = {Cognitive hierarchies in the minimizer game},
journal = {Journal of Economic Behavior & Organization},
volume = {130},
pages = {337-348},
year = {2016},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2016.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167268116301639},
author = {Ulrich Berger and Hannelore {De Silva} and Gerlinde Fellner-Röhling},
keywords = {Behavioral game theory, Experimental games, Poisson cognitive hierarchy, Level- model, Minimizer game},
abstract = {Experimental tests of choice predictions in one-shot games show only little support for Nash equilibrium (NE). Poisson Cognitive Hierarchy (PCH) and level-k (LK) are behavioral models of the thinking-steps variety where subjects differ in the number of levels of iterated reasoning they perform. Camerer et al. (2004) claim that substituting the Poisson parameter τ=1.5 yields a parameter-free PCH model (pfPCH) which predicts experimental data considerably better than NE. We design a new multi-person game, the Minimizer Game, as a testbed to compare initial choice predictions of NE, pfPCH and LK. Data obtained from two large-scale online experiments strongly reject NE and LK, but are well in line with the point-prediction of pfPCH.}
}
@article{COURTNEY2025168819,
title = {memerna: Sparse RNA folding including coaxial stacking},
journal = {Journal of Molecular Biology},
volume = {437},
number = {3},
pages = {168819},
year = {2025},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2024.168819},
url = {https://www.sciencedirect.com/science/article/pii/S0022283624004418},
author = {Eliot Courtney and Amitava Datta and David H. Mathews and Max Ward},
keywords = {RNA secondary structure, sparsification, dynamic programming, nearest neighbor, energy model},
abstract = {Determining RNA secondary structure is a core problem in computational biology. Fast algorithms for predicting secondary structure are fundamental to this task. We describe a modified formulation of the Zuker-Stiegler algorithm with coaxial stacking, a stabilising interaction in which the ends of helices in multi-loops are stacked. In particular, optimal coaxial stacking is computed as part of the dynamic programming state, rather than in an inner loop. We introduce a new notion of sparsity, which we call replaceability. Replaceability is a more general condition and applicable in more places than the triangle inequality that is used by previous sparse folding methods. We also introduce non-monotonic candidate lists as an additional sparsification tool. Existing usages of the triangle inequality for sparsification can be thought of as an application of both replaceability and monotonicity together. The modified recurrences along with replaceability allows sparsification to be applied to coaxial stacking as well, which increases the speed of the algorithm. We implemented this algorithm in software we call memerna, which we show to have the fastest exact (non–heuristic) implementation of RNA folding under the complete Turner 2004 model with coaxial stacking, out of several popular RNA folding tools supporting coaxial stacking. We also introduce a new notation for secondary structure which includes coaxial stacking, terminal mismatches, and dangles (CTDs) information. The memerna package 0.1 release is available at https://github.com/Edgeworth/memerna/tree/release/0.1.}
}
@article{KUHN202428,
title = {A landscape of consciousness: Toward a taxonomy of explanations and implications},
journal = {Progress in Biophysics and Molecular Biology},
volume = {190},
pages = {28-169},
year = {2024},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2023.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0079610723001128},
author = {Robert Lawrence Kuhn},
keywords = {Consciousness, Mind-body problem, Materialism, Monism, Dualism, Idealism},
abstract = {Diverse explanations or theories of consciousness are arrayed on a roughly physicalist-to-nonphysicalist landscape of essences and mechanisms. Categories: Materialism Theories (philosophical, neurobiological, electromagnetic field, computational and informational, homeostatic and affective, embodied and enactive, relational, representational, language, phylogenetic evolution); Non-Reductive Physicalism; Quantum Theories; Integrated Information Theory; Panpsychisms; Monisms; Dualisms; Idealisms; Anomalous and Altered States Theories; Challenge Theories. There are many subcategories, especially for Materialism Theories. Each explanation is self-described by its adherents, critique is minimal and only for clarification, and there is no attempt to adjudicate among theories. The implications of consciousness explanations or theories are assessed with respect to four questions: meaning/purpose/value (if any); AI consciousness; virtual immortality; and survival beyond death. A Landscape of Consciousness, I suggest, offers perspective.}
}
@article{YANG20242009,
title = {Maximum Power Point Tracking Technology for PV Systems: Current Status and Perspectives},
journal = {Energy Engineering},
volume = {121},
number = {8},
pages = {2009-2022},
year = {2024},
issn = {0199-8595},
doi = {https://doi.org/10.32604/ee.2024.049423},
url = {https://www.sciencedirect.com/science/article/pii/S0199859524000708},
author = {Bo Yang and Rui Xie and Zhengxun Guo},
keywords = {PV systems, MPPT, partial shading condition, DC-DC converter},
abstract = {Maximum power point tracking (MPPT) technology plays a key role in improving the energy conversion efficiency of photovoltaic (PV) systems, especially when multiple local maximum power points (LMPPs) occur under partial shading conditions (PSC). It is necessary to modify the operating point efficiently and accurately with the help of MPPT technology to maximize the collected power. Even though a lot of research has been carried out and impressive progress achieved for MPPT technology, it still faces some challenges and dilemmas. Firstly, the mathematical model established for PV cells is not precise enough. Second, the existing algorithms are often optimized for specific conditions and lack comprehensive adaptability to the actual operating environment. Besides, a single algorithm may not be able to give full play to its advantages. In the end, the selection criteria for choosing the suitable MPPT algorithm/converter combination to achieve better performance in a given scenario is very limited. Therefore, this paper systematically discusses the current research status and challenges faced by PV MPPT technology around the three aspects of MPPT models, algorithms, and hardware implementation. Through in-depth thinking and discussion, it also puts forward positive perspectives on future development, and five forward-looking solutions to improve the performance of PV systems MPPT are suggested.}
}
@article{ALIABADI2000243,
title = {Stabilized-finite-element/interface-capturing technique for parallel computation of unsteady flows with interfaces},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {3},
pages = {243-261},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00200-0},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500002000},
author = {Shahrouz Aliabadi and Tayfun E. Tezduyar},
abstract = {We present the stabilized-finite-element/interface-capturing (SFE/IC) method developed for parallel computation of unsteady flow problems with two-fluid interfaces and free surfaces. The SFE/IC method involves stabilized formulations, an interface-sharpening technique, and the enforcement of global mass conservation for each fluid. The SFE/IC method has been efficiently implemented on the CRAY T3E parallel supercomputer. A number of 2D test problems are presented to demonstrate how the SFE/IC method works and the accuracy it attains. We also show how the SFE/IC method can be very effectively applied to 3D simulation of challenging flow problems, such as two-fluid interfaces in a centrifuge tube and operational stability of a partially filled tanker truck driving over a bump.}
}
@article{MENGOV2022101944,
title = {Virtual social networking increases the individual's economic predictability},
journal = {Journal of Behavioral and Experimental Economics},
volume = {101},
pages = {101944},
year = {2022},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2022.101944},
url = {https://www.sciencedirect.com/science/article/pii/S221480432200115X},
author = {George Mengov and Nikolay Georgiev and Irina Zinovieva and Anton Gerunov},
keywords = {Decision making, Virtual social network, Emotional economic choice, Neural model},
abstract = {Forecasting economic choice is hard because today we still do not know enough about human motivation. A fundamental problem is the lack of knowledge about how the neural networks in the brain give rise to thinking and decision making. One way to address the issue has been to develop simplified economic experiments, in which participants need skills of little complexity and their minds employ cognitive mechanisms, already well understood by mathematical psychology and neuroscience. Here we take a neural model for rudimentary emotion generation and memorizing and use it as a guiding theory to understand decision making in an experimental oligopoly market. For the first time in that line of research, participants are put in a lab virtual social network serving to exchange opinions about deals with companies. On average, choices become significantly more predictable when people participate in the network, in contrast to working alone with expert information. Calibrating the model for each person, we find that some people are predicted with startling precision.}
}
@incollection{YANG20151,
title = {Chapter 1 - Bio-Inspired Computation and Optimization: An Overview},
editor = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
booktitle = {Bio-Inspired Computation in Telecommunications},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {1-21},
year = {2015},
isbn = {978-0-12-801538-4},
doi = {https://doi.org/10.1016/B978-0-12-801538-4.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012801538400001X},
author = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
keywords = {Algorithm, Ant algorithm, Bee algorithm, Bat algorithm, Bio-inspired computation, Cuckoo search, Firefly algorithm, Harmony search, Particle swarm optimization, Metaheuristics, Swarm intelligence, Telecommunications},
abstract = {All design problems in telecommunications can be formulated as optimization problems, and thus may be tackled by some optimization techniques. However, these problems can be extremely challenging due to the stringent time requirements, complex constraints, and a high number of design parameters. Solution methods tend to use conventional methods such as Lagrangian duality and fractional programming in combination with numerical solvers, while new trends tend to use evolutionary algorithms and swarm intelligence. This chapter provides a summary review of the bio-inspired optimization algorithms and their applications in telecommunications. We also discuss key issues in optimization and some active topics for further research.}
}
@article{CARTER2021100065,
title = {Comparing manual and computational approaches to theme identification in online forums: A case study of a sex work special interest community},
journal = {Methods in Psychology},
volume = {5},
pages = {100065},
year = {2021},
issn = {2590-2601},
doi = {https://doi.org/10.1016/j.metip.2021.100065},
url = {https://www.sciencedirect.com/science/article/pii/S2590260121000229},
author = {Pelham Carter and Matt Gee and Hollie McIlhone and Harkeeret Lally and Robert Lawson},
keywords = {Sex work, Online forums, Language, gender and sexuality, Mixed methods, Corpus linguistics},
abstract = {Online forums afford individuals opportunities to take part in a community with shared interests and goals. This involves the sharing of experiences and advice (Attard and Coulson, 2012) and can lead to positive effects (Pendry and Salvatore, 2015). Online forums also afford access to rich sources of detailed data, personal experiences, and hard-to-reach or taboo communities. Such online research, though well-suited to qualitative analysis, leads to a number of practical problems in terms of range, depth, and ease of access to data. Even extensive data collection and manual analysis often only engage with a small percentage of the data available in online communities. In this article, we present a traditional manual collection and thematic analysis of data (2631 posts across 60 different threads, approximately 300,000 words) from forums where sex workers and men who pay for sex discuss matters relating to prostitution. This analysis revealed five themes of forum use: preference sharing, personal narrative sharing, practical advice, philosophical issues, and community maintenance. Further automated data collection and corpus analysis, such as keyness and topic modelling, are presented as a potential innovation within online qualitative research. This approach allowed for the analysis of a larger dataset of 255,891 posts, across 14,232 threads (16,472,006 words), revealing additional themes such as sexual hygiene, desire, legality, and ethnicity, as well as differences in the use of terms of address and slang by punters and sex workers. The automated methods presented allow for more comprehensive investigations of online communities than traditional approaches, but we also note that manual interpretation should still be incorporated into the analysis.}
}
@article{FARRELL20175597,
title = {N‐Aryl‐9,10‐phenanthreneimines as Scaffolds for Exploring Noncovalent Interactions: A Structural and Computational Study},
journal = {European Journal of Organic Chemistry},
volume = {2017},
number = {37},
pages = {5597-5609},
year = {2017},
issn = {1434-193X},
doi = {https://doi.org/10.1002/ejoc.201700884},
url = {https://www.sciencedirect.com/science/article/pii/S1434193X22035940},
author = {David Farrell and Samuel J. Kingston and Dmitry Tungulin and Stefano Nuzzo and Brendan Twamley and James A. Platts and Robert J. Baker},
keywords = {Stacking interactions, Noncovalent interactions, Density functional calculations},
abstract = {A series of 10‐[(4‐halo‐2,6‐diisopropylphenyl)imino]phenanthren‐9‐ones and derivatives of the phenanthrene‐9,10‐dione ligand have been synthesised and structurally characterised to explore two types of noncovalent interactions, namely the influence of the steric bulk upon the resulting C–H···π and π‐stacking interactions and halogen bonding. Selected noncovalent interactions have additionally been analysed by DFT and AIM techniques. No halogen bonding has been observed in these systems, but X lone pair···π, C–H···O=C and C–H···π interactions are the prevalent ones in the halogenated systems. Removal of the steric bulk in N‐(2,4,6‐trimethylphenyl)‐9,10‐iminophenanthrenequinone affords different noncovalent interactions, but the C–H···O=C hydrogen bonds are observed. Surprisingly, in N‐(2,6‐dimethylphenyl)‐9,10‐iminophenanthrenequinone and N‐(phenyl)‐9,10‐iminophenanthrenequinone these C–H···O=C hydrogen bonds are not observed. However, they are observed in the related 2,6‐di‐tert‐butylphenanthrene‐9,10‐dione. The π‐interactions in dimers extracted from the crystal structures have been analysed by DFT and AIM. Spectroscopic investigations are also presented and these show only small perturbations to the O=C–C=N fragment.}
}
@article{NORTON2006600,
title = {Computational fluid dynamics (CFD) – an effective and efficient design and analysis tool for the food industry: A review},
journal = {Trends in Food Science & Technology},
volume = {17},
number = {11},
pages = {600-620},
year = {2006},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2006.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0924224406001981},
author = {Tomás Norton and Da-Wen Sun},
abstract = {Computational fluid dynamics (CFD) is a powerful numerical tool that is becoming widely used to simulate many processes in the food industry. Recent progression in computing efficacy coupled with reduced costs of CFD software packages has advanced CFD as a viable technique to provide effective and efficient design solutions. This paper discusses the fundamentals involved in developing a CFD solution. It also provides a state-of-the-art review on various CFD applications in the food industry such as ventilation, drying, sterilisation, refrigeration, cold display and storage, and mixing and elucidates the physical models most commonly used in these applications. The challenges faced by modellers using CFD in the food industry are also discussed.}
}
@article{ZHANG2024101587,
title = {Effects of a problem posing instructional interventions on student learning outcomes: A three-level meta-analysis},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101587},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101587},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001251},
author = {Cheng Zhang and Ying Zhou and Tommy Tanu Wijaya and Jihe Chen and Yimin Ning},
keywords = {Problem posing, Learning outcomes, Three-level meta-analysis, Instructional interventions},
abstract = {Problem posing is increasingly being considered in the field of education, with many experts exploring its positive effects on student learning outcomes. In this case, different perspectives have emerged regarding the impact of the intervention, claiming the overall effect remains uncertain. Therefore, this study aims to explore the effects of a problem posing instructional intervention on student learning outcomes at the cognitive and non-cognitive levels from 2000 to 2023, using a three-level meta-analysis. 32 studies and 4,068 participants were included to compare the classrooms with and without problem posing instructional interventions in elementary to higher education. The results showed a moderate-positive and small positive effect on students cognitive (Hedges' g = 0.681, 95 % CI [0.552, 0.810], p < 0.001) and non-cognitive (Hedges' g = 0.367, 95 % CI [0.113, 0.620], p = 0.003) levels, respectively. Based on the moderator analysis, there were differences in the learning outcomes among students across various task formats. Notably, tasks that included specific information and involved problem posing in context demonstrated significantly better performance. In conclusion, these results indicate the importance of problem posing instructional interventions in promoting student's development and their impact on cognitive and non-cognitive dimensions.}
}
@article{ARTHUR2023638,
title = {Economics in nouns and verbs},
journal = {Journal of Economic Behavior & Organization},
volume = {205},
pages = {638-647},
year = {2023},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2022.10.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167268122003936},
author = {W. Brian Arthur},
keywords = {Economic theory, Mathematics in economics, Algorithms, Complexity economics, Computational economics},
abstract = {Standard economic theory uses mathematics as its main means of understanding, and this brings clarity of reasoning and logical power. But there is a drawback: algebraic mathematics restricts economic modeling to what can be expressed only in quantitative nouns, and this forces theory to leave out matters to do with process, formation, adjustment, and creation—matters to do with nonequilibrium. For these we need a different means of understanding, one that allows verbs as well as nouns. Algorithmic expression is such a means. It allows verbs—processes—as well as nouns—objects and quantities. It allows fuller description in economics, and can include heterogeneity of agents, actions as well as objects, and realistic models of behavior in ill-defined situations. The world that algorithms reveal is action-based as well as object-based, organic, possibly ever-changing, and not fully knowable. But it is strangely and wonderfully alive.}
}
@article{JAUK2012219,
title = {Tackling creativity at its roots: Evidence for different patterns of EEG alpha activity related to convergent and divergent modes of task processing},
journal = {International Journal of Psychophysiology},
volume = {84},
number = {2},
pages = {219-225},
year = {2012},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2012.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167876012000748},
author = {Emanuel Jauk and Mathias Benedek and Aljoscha C. Neubauer},
keywords = {EEG, Creativity, Alpha synchronization, Divergent thinking, Convergent thinking},
abstract = {The distinction between convergent and divergent cognitive processes given by Guilford (1956) had a strong influence on the empirical research on creative thinking. Neuroscientific studies typically find higher event-related synchronization in the EEG alpha rhythm for individuals engaged in creative ideation tasks compared to intelligence-related tasks. This study examined, whether these neurophysiological effects can also be found when both cognitive processing modes (convergent vs. divergent) are assessed by means of the same task employing a simple variation of instruction. A sample of 55 participants performed the alternate uses task as well as a more basic word association task while EEG was recorded. On a trial-by-trial basis, participants were either instructed to find a most common solution (convergent condition) or a most uncommon solution (divergent condition). The answers given in the divergent condition were in both tasks significantly more original than those in the convergent condition. Moreover, divergent processing was found to involve higher task-related EEG alpha power than convergent processing in both the alternate uses task and the word association task. EEG alpha synchronization can hence explicitly be associated with divergent cognitive processing rather than with general task characteristics of creative ideation tasks. Further results point to a differential involvement of frontal and parietal cortical areas by individuals of lower versus higher trait creativity.}
}
@article{MOORE2021,
title = {Age-Related Differences in Experiences With Social Distancing at the Onset of the COVID-19 Pandemic: A Computational and Content Analytic Investigation of Natural Language From a Social Media Survey},
journal = {JMIR Human Factors},
volume = {8},
number = {2},
year = {2021},
issn = {2292-9495},
doi = {https://doi.org/10.2196/26043},
url = {https://www.sciencedirect.com/science/article/pii/S2292949521000274},
author = {Ryan C Moore and Angela Y Lee and Jeffrey T Hancock and Meghan C Halley and Eleni Linos},
keywords = {COVID-19, natural language processing, public health messaging, social distancing compliance, age differences, older adults, younger adults, age, NLP, public health, elderly, youth, adult, emotion, compliance, guideline},
abstract = {Background
As COVID-19 poses different levels of threat to people of different ages, health communication regarding prevention measures such as social distancing and isolation may be strengthened by understanding the unique experiences of various age groups.
Objective
The aim of this study was to examine how people of different ages (1) experienced the impact of the COVID-19 pandemic and (2) their respective rates and reasons for compliance or noncompliance with social distancing and isolation health guidance.
Methods
We fielded a survey on social media early in the pandemic to examine the emotional impact of COVID-19 and individuals’ rates and reasons for noncompliance with public health guidance, using computational and content analytic methods of linguistic analysis.
Results
A total of 17,287 participants were surveyed. The majority (n=13,183, 76.3%) were from the United States. Younger (18-31 years), middle-aged (32-44 years and 45-64 years), and older (≥65 years) individuals significantly varied in how they described the impact of COVID-19 on their lives, including their emotional experience, self-focused attention, and topical concerns. Younger individuals were more emotionally negative and self-focused, while middle-aged people were other-focused and concerned with family. The oldest and most at-risk group was most concerned with health-related terms but were lower in anxiety (use of fewer anxiety-related terms) and higher in the use of emotionally positive terms than the other less at-risk age groups. While all groups discussed topics such as acquiring essential supplies, they differentially experienced the impact of school closures and limited social interactions. We also found relatively high rates of noncompliance with COVID-19 prevention measures, such as social distancing and self-isolation, with younger people being more likely to be noncompliant than older people (P<.001). Among the 43.1% (n=7456) of respondents who did not fully comply with health orders, people differed substantially in the reasons they gave for noncompliance. The most common reason for noncompliance was not being able to afford to miss work (n=4273, 57.3%). While work obligations proved challenging for participants across ages, younger people struggled more to find adequate space to self-isolate and manage their mental and physical health; middle-aged people had more concerns regarding childcare; and older people perceived themselves as being able to take sufficient precautions.
Conclusions
Analysis of natural language can provide insight into rapidly developing public health challenges like the COVID-19 pandemic, uncovering individual differences in emotional experiences and health-related behaviors. In this case, our analyses revealed significant differences between different age groups in feelings about and responses to public health orders aimed to mitigate the spread of COVID-19. To improve public compliance with health orders as the pandemic continues, health communication strategies could be made more effective by being tailored to these age-related differences.}
}
@article{KONOPKA1994V,
title = {Computational experiments in molecular biology: Searching for the ‘big picture’},
journal = {Computers & Chemistry},
volume = {18},
number = {3},
pages = {V-VIII},
year = {1994},
issn = {0097-8485},
doi = {https://doi.org/10.1016/0097-8485(94)85013-5},
url = {https://www.sciencedirect.com/science/article/pii/0097848594850135},
author = {AndrzejK. Konopka}
}
@article{BULLEN2022101933,
title = {Patterns of math and reading achievement in children and adolescents with autism spectrum disorder},
journal = {Research in Autism Spectrum Disorders},
volume = {92},
pages = {101933},
year = {2022},
issn = {1750-9467},
doi = {https://doi.org/10.1016/j.rasd.2022.101933},
url = {https://www.sciencedirect.com/science/article/pii/S1750946722000204},
author = {Jennifer C. Bullen and Matthew C. Zajic and Nancy McIntyre and Emily Solari and Peter Mundy},
keywords = {Autism spectrum disorder, Academic achievement, Hierarchical cluster analysis, Math achievement, Reading fluency},
abstract = {Background
There has been an increase of autistic students without intellectual disabilities (autisticWoID) placed in general education settings (Hussar et al., 2020), but there is a lack of understanding of how to best support classroom learning for these children. Previous research has pointed to subgroups of autisticWoID children who display difficulty with mathematics and reading achievement (Chen et al., 2018; Estes et al., 2011; Jones et al., 2009; Wei et al., 2015). Research has primarily focused on symptomatology and communication factors related to learning in subgroups of autistic children. The current study sought to expand upon this research by assessing the validity of these previous studies and by investigating the specific contribution of domain-general cognitive abilities to differences in these subgroups.
Method
Seventy-eight autisticWoID individuals (M = 11.34 years, SD = 2.14) completed measures of mathematics and reading achievement, IQ, working memory, inferential thinking, and Theory of Mind (ToM). A hierarchical cluster analysis was performed on the math and reading measures.
Results
The analysis revealed two unique achievement groups: one group that performed lower than expected on math and reading achievement and a second group that performed higher than expected. Groups differed significantly on IQ and working memory and were distinguished by performance on reading fluency. Groups did not differ on ToM, inferential thinking, or symptomatology.
Conclusion
These findings describe a group of autisticWoID individuals that may be more likely to experience difficulty learning, which should be accounted for in general education settings.}
}
@incollection{DAVIES2025414,
title = {Software Tools for Green and Sustainable Chemistry},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {414-425},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00049-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000491},
author = {Joseph C. Davies and Jonathan D. Hirst},
keywords = {Computer aided synthesis planning., Digitalization, Electronic laboratory notebook, Green metrics, Solvent selection},
abstract = {We present the concepts of green and sustainable chemistry and related software tools. Making chemistry greener and more sustainable is a growing priority for researchers and software tools have been developed to aid in this pursuit. Software tools for green and sustainable chemistry have been developed to assess existing methods, propose new ones, and replace some experimental methods altogether with in silico approaches. We discuss the digitalization of chemistry and the computational advances that enable software tools to play a growing role in all aspects of chemical research. Barriers and limitations of current tools are discussed along with future trajectories.}
}
@article{WESTRA2023645,
title = {Accounting for systemic complexity in the assessment of climate risk},
journal = {One Earth},
volume = {6},
number = {6},
pages = {645-655},
year = {2023},
issn = {2590-3322},
doi = {https://doi.org/10.1016/j.oneear.2023.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2590332223002063},
author = {Seth Westra and Jakob Zscheischler},
abstract = {Summary
Widespread changes to climate-sensitive systems are placing increased demands on risk assessments as a foundation for managing risk. Recent attention to compounding and cascading risks, deep uncertainty, and “bottom-up” risk assessment frameworks have foregrounded the need to account for systemic complexity in risk assessment methodology. We describe the sources of systemic complexity and highlight the role of risk assessments as a formal sense-making device that enables learning and organizing knowledge of the dynamic interplay between the climate-sensitive system and its (climatological) environment. We highlight boundary judgments as a core concern of risk assessments, helping to create islands of analytical and cognitive tractability in a complex, uncertain, and ambiguous world. We then point to three key concepts—boundary critique, multi-methodology, and second-order learning—as critical elements of contemporary risk assessment practice, and we weave these into an overarching framework to better account for systemic complexity in the assessment of climate risk.}
}
@article{HAMZYANOLIA2025109984,
title = {A comprehensive review of neurotransmitter modulation via artificial intelligence: A new frontier in personalized neurobiochemistry},
journal = {Computers in Biology and Medicine},
volume = {189},
pages = {109984},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.109984},
url = {https://www.sciencedirect.com/science/article/pii/S001048252500335X},
author = {Jaleh Bagheri {Hamzyan Olia} and Arasu Raman and Chou-Yi Hsu and Ahmad Alkhayyat and Alireza Nourazarian},
keywords = {AI, Neurotransmitter agents, Drug discovery, Machine learning, DBS, Personalized medicine},
abstract = {The deployment of artificial intelligence (AI) is revolutionizing neuropharmacology and drug development, allowing the modulation of neurotransmitter systems at the personal level. This review focuses on the neuropharmacology and regulation of neurotransmitters using predictive modeling, closed-loop neuromodulation, and precision drug design. The fusion of AI with applications such as machine learning, deep-learning, and even computational modeling allows for the real-time tracking and enhancement of biological processes within the body. An exemplary application of AI is the use of DeepMind's AlphaFold to design new GABA reuptake inhibitors for epilepsy and anxiety. Likewise, Benevolent AI and IBM Watson have fast-tracked drug repositioning for neurodegenerative conditions. Furthermore, we identified new serotonin reuptake inhibitors for depression through AI screening. In addition, the application of Deep Brain Stimulation (DBS) settings using AI for patients with Parkinson's disease and for patients with major depressive disorder (MDD) using reinforcement learning-based transcranial magnetic stimulation (TMS) leads to better treatment. This review highlights other challenges including algorithm bias, ethical concerns, and limited clinical validation. Their proposal to incorporate AI with optogenetics, CRISPR, neuroprosthesis, and other advanced technologies fosters further exploration and refinement of precision neurotherapeutic approaches. By bridging computational neuroscience with clinical applications, AI has the potential to revolutionize neuropharmacology and improve patient-specific treatment strategies. We addressed critical challenges, such as algorithmic bias and ethical concerns, by proposing bias auditing, diverse datasets, explainable AI, and regulatory frameworks as practical solutions to ensure equitable and transparent AI applications in neurotransmitter modulation.}
}
@article{BECKER2003164,
title = {A computational model of the role of dopamine and psychotropic drugs in modulating motivated action},
journal = {Schizophrenia Research},
volume = {60},
number = {1, Supplement },
pages = {164},
year = {2003},
note = {Abstracts of the IXth International Congress on Schizophrenia Research},
issn = {0920-9964},
doi = {https://doi.org/10.1016/S0920-9964(03)81019-8},
url = {https://www.sciencedirect.com/science/article/pii/S0920996403810198},
author = {S. Becker and A. Chan and P. Fletcher and A. Smith and S. Kapur}
}
@article{BRIMKOV20071631,
title = {Digital hyperplane recognition in arbitrary fixed dimension within an algebraic computation model},
journal = {Image and Vision Computing},
volume = {25},
number = {10},
pages = {1631-1643},
year = {2007},
note = {Discrete Geometry for Computer Imagery 2005},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2006.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0262885606002988},
author = {Valentin E. Brimkov and Stefan Dantchev},
keywords = {Digital hyperplane, Digital plane recognition, Integer programming, Euclidean algorithm},
abstract = {In this paper we present an algorithm for the integer linear programming (ILP) problem within an algebraic model of computation and use it to solve the following digital plane segment recognition problem: Given a set of points M={p1,p2,…,pm}⊆Rn, decide whether M is a portion of a digital hyperplane and, if so, determine its analytical representation. In our setting p1, p2, …,pm may be arbitrary points (possibly, with rational and/or irrational coefficients) and the dimension n may be any arbitrary fixed integer. We reduce this last problem to an ILP to which our general integer programming algorithm applies. It performs O(mlogD) arithmetic operations, where D is a bound on the norm of the domain elements. For the special case of problem dimension two, we propose an elementary algorithm that takes advantage of the specific geometry of the problem and appears to be optimal. It implies an efficient algorithm for digital line segment recognition.}
}
@article{WU2019104407,
title = {A review of performance assessment methods for construction and demolition waste management},
journal = {Resources, Conservation and Recycling},
volume = {150},
pages = {104407},
year = {2019},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2019.104407},
url = {https://www.sciencedirect.com/science/article/pii/S0921344919303027},
author = {Huanyu Wu and Jian Zuo and Hongping Yuan and George Zillante and Jiayuan Wang},
keywords = {Construction and demolition waste, Waste management, Performance assessment methods, System thinking, Life cycle assessment},
abstract = {Significant efforts have been devoted to assessing construction and demolition waste management (CDWM). However, there is little knowledge to understand the utilisation of the developed models for assessing CDWM performance, thus limiting the comparison and generalization of recognized methods and tools. By reviewing the prior published literature, this study assesses the current research methods, in particular, data collection. It also reviews the range of critical indicators for CDWM performance assessment considered by the literature and put forwards a new framework for better assessing CDWM performance. The proposed framework summarises the system boundary, research scale and performance assessment aspects documented by previous studies, and further integrate an integrated framework with procedures for better assessing CDWM performance. The literature review found that while some studies adopt a system thinking and life cycle thinking to assess CDWM performance, other research they adopt a sustainability based model to finalize CDWM performance assessment. The results also demonstrate that compared with environmental and economic aspects, the social aspect has attracted less attention. Social factors, however are crucial in CDWM. The findings about current performance assessment practices in CDWM and the proposed procedures are possible to implement for researchers and practitioners to develop sound CDWM approaches.}
}
@article{VELDHUIS2025100708,
title = {Critical Artificial Intelligence literacy: A scoping review and framework synthesis},
journal = {International Journal of Child-Computer Interaction},
volume = {43},
pages = {100708},
year = {2025},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100708},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000771},
author = {Annemiek Veldhuis and Priscilla Y. Lo and Sadhbh Kenny and Alissa N. Antle},
keywords = {Artificial intelligence, Critical literacy, AI ethics, AI literacy, Computational empowerment, Literature review},
abstract = {The proliferation of Artificial Intelligence (AI) in everyday life raises concerns for children, other marginalized groups, and the general public. As new AI implementations continue to emerge, it is crucial to enable children to engage critically with AI. Critical literacy objectives and practices can encourage children to question, critique, and transform the social, political, cultural, and ethical implications of AI. As an initial step towards critical AI education, we conducted a 10-year scoping review to identify publications reporting on activities that engage children, between the ages of 5 and 18, to address the critical implications of AI. Our review identifies a wide range of participants, content, and pedagogical approaches. Through framework synthesis guided by an established critical literacy model, we examine the critical literacy learning objectives embedded in the reported activities and propose a critical AI literacy framework. This paper outlines future opportunities for critical AI literacies in the field of child–computer interaction including inspiring new learning activities, encouraging inclusive perspectives, and supporting pragmatic curriculum integration.}
}
@article{REDKO2016105,
title = {Epistemological foundations of investigation of cognitive evolution},
journal = {Biologically Inspired Cognitive Architectures},
volume = {18},
pages = {105-115},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300597},
author = {Vladimir G. Red’ko},
keywords = {Modeling of cognitive evolution, Cognitive agents, Animal cognitive features, Epistemological foundations},
abstract = {Epistemological foundations for modeling of cognitive evolution are characterized. Cognitive evolution is the evolution of cognitive abilities of biological organisms. The important result of this evolution is the human thinking, which is used at scientific cognition of nature. The related epistemological viewpoints of David Hume, Immanuel Kant, Konrad Lorenz, and Eugene Wigner are outlined. The sketch program for future investigations of cognitive evolution is proposed; initial models of these studies are outlined. According to the presented analysis, it is possible to believe the following. Investigations of cognitive evolution are directed to analyze the fundamental problems: “Why is human thinking applicable to cognition of nature?”, “How did human thinking origin in the process of biological evolution?” There are powerful backgrounds for considered investigations: (1) models of autonomous cognitive agents, (2) biological investigations of animal cognitive features. Studies of cognitive evolution would have broad interdisciplinary relations. These studies should contribute significantly to the development of the scientific point of view.}
}
@incollection{KRAAK2020141,
title = {Geovisualization},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {141-151},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10552-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105529},
author = {Menno-Jan Kraak},
keywords = {Alternative visualization, Cartography, Cognition, Coordinated multiple views, Geocomputation, Geovisualization, Information visualization, Interfaces, Maps, Representation, Spatiotemporal data, Usability, Visual analytics, Visual exploration, Visual representation, Visual thinking},
abstract = {Due to technological developments and societal needs cartography, scientific visualization, image analysis and remote sensing, information visualization, exploratory data analysis, visual analytics, and GIScience have undergone fundamental changes in recent years. Interactivity and dynamics allow not only maps and diagrams to present known facts but also to analyze and explore unknown data. The environment in which the maps and diagrams are used has also changed and often includes coordinated multiple views display via the Internet. Such environments allow for simultaneous alternative views of the data and stimulate visual thinking, resulting in geovisualization.}
}
@article{RUSSWINKEL2011336,
title = {Predicting temporal errors in complex task environments: A computational and experimental approach},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {336-354},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000143},
author = {Nele Russwinkel and Leon Urbas and Manfred Thüring},
keywords = {Cognitive modelling, Time perception, Working memory, Expectations, Surprise, ACT-R},
abstract = {Management in complex environments requires knowledge about temporal contingencies. Expectations about durations enable us to prepare for important events in good time, but also to detect irregularities. Unfortunately, time perception is not invariant. Situational aspects as well as features of the task at hand may dramatically change our sense of time. Particularly under varying workload conditions, temporal distortions may lead to performance errors. A valid and reliable model of time perception must account for these characteristics. Based on the cognitive architecture ACT-R (Anderson et al., 2004), we developed a computational model in line with this requirement. Specific emphasis was placed on mechanisms of coordinative working memory which seem to influence time encoding and perception. The model’s assumptions were tested in three steps. First, the model was applied to account for time distortions ‘a posteriori’. Effects of varying working memory demands reported by Dutke (2005) were replicated and explained by simulations of the model. Second, the model was used for predicting effects ‘a priori’. Augmenting Dutke’s (2005) approach by switching between different degrees of memory demands, predictions of time distortions were derived from the model. These predictions were compared with experimental data. Central assumptions of the model were supported, but there were also some deviations that the model had not captured. Based on the conclusions from the results of the experiment, a second a priori testing addressed temporal expectations in a complex task using a micro-world scenario. The results support the interpretation of the previous experiment and provide new insights for modelling time perception. In summary, our results indicate that coordinative working memory – in contrast to general attention – causes differences in timing performance. This characteristic is captured by our approach. The model we propose heavily relies on mechanisms of working memory and can be applied to explain effects for different time intervals, under a variety of experimental conditions and in different task environments.}
}
@article{FLANIGAN2017179,
title = {Implicit intelligence beliefs of computer science students: Exploring change across the semester},
journal = {Contemporary Educational Psychology},
volume = {48},
pages = {179-196},
year = {2017},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2016.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X16300479},
author = {Abraham E. Flanigan and Markeya S. Peteranetz and Duane F. Shell and Leen-Kiat Soh},
keywords = {Motivation, Implicit intelligence beliefs, Computer science, Self-regulation, Engagement},
abstract = {This study investigated introductory computer science (CS1) students’ implicit beliefs of intelligence. Referencing Dweck and Leggett’s (1988) framework for implicit beliefs of intelligence, we examined how (1) students’ implicit beliefs changed over the course of a semester, (2) these changes differed as a function of course enrollment and students’ motivated self-regulated engagement profile, and (3) implicit beliefs predicted student learning based on standardized course grades and performance on a computational thinking knowledge test. For all students, there were significant increases in entity beliefs and significant decreases in incremental beliefs across the semester. However, examination of effect sizes suggests that significant findings for change across time were driven by changes in specific subpopulations of students. Moreover, results showed that students endorsed incremental belief more strongly than entity belief at both the beginning and end of the semester. Furthermore, the magnitude of changes differed based on students’ motivated self-regulated engagement profiles. Additionally, students’ achievement outcomes were weakly predicted by their implicit beliefs of intelligence. Finally, results showed that the relationship between changes in implicit intelligence beliefs and student achievement varied across different CS1 courses. Theoretical implications for implicit intelligence beliefs and recommendations for STEM educators are discussed.}
}
@article{FALLOON2019138,
title = {Using simulations to teach young students science concepts: An Experiential Learning theoretical analysis},
journal = {Computers & Education},
volume = {135},
pages = {138-159},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S036013151930051X},
author = {Garry Falloon},
keywords = {Simulations, Young students, Electricity, Circuits, Experiential learning},
abstract = {Early research investigated young students' understandings of science concepts using physical equipment, but technological advances now mean there are new options to introduce these ideas, through devices such as iPads and simulations. However, research investigating the use of simulations in early years' science learning is limited. This study applied revisions of Kolb's Experiential Learning theoretical model to determine if age-indicated science simulations were effective for teaching 5 year olds simple circuit building procedures and electricity concepts, and the function of circuit components. It also explored whether their engagement with the simulations provided worthwhile opportunities to exercise higher order capabilities such as reflective thinking and abstraction – skills oftencited in literature as valuable outcomes from older student and adult use of simulations. Findings indicate students developed a solid base of procedural knowledge about constructing different circuits, and functional knowledge about circuit components they applied to different circuit designs. The emergence of tentative, generalised theories about current and the effects of different circuit designs on the performance of resistors - linked to the exercise of reflective and descriptive thinking, were also noted in many students. However, examples were found of some simulations appearing to foster common misconceptions, such as current being ‘consumed’ by resistors – indicating teachers need to be highly vigilant and work closely with students, to ensure accurate understandings are developed. Overall, with appropriate teacher support and careful selection and review, the study concludes simulations can be effective for introducing young students to simple physical science concepts, and for providing them with opportunities to engage in higher order thinking processes.}
}
@article{SWARUP2006273,
title = {A new evolutionary computation technique for economic dispatch with security constraints},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {28},
number = {4},
pages = {273-283},
year = {2006},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2006.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142061506000020},
author = {K.S. Swarup and P. Rohit Kumar},
keywords = {Power system optimization, Economic load dispatch, Particle swarm optimization, Line-flow, Voltage constraints},
abstract = {This paper presents an efficient and reliable evolutionary based approach to solve the economic load dispatch (ELD) with security constraints. A new approach is proposed which employs attractive and repulsive particle swarm optimization (ARPSO) algorithm for ELD. Incorporation of ARPSO as a derivative-free optimization technique in solving ELD with security (voltages and line-flows) constraints significantly relieves the assumptions imposed on the optimized objective function. The proposed approach has been implemented on three representative systems, i.e. IEEE 14 bus, IEEE 30 bus and IEEE 57 bus systems, respectively. The feasibility of the proposed method is demonstrated and the results are compared with linear programming, quadratic programming and genetic algorithm, respectively. The premature convergence problem, that is common in all evolutionary computation techniques, is solved in ARPSO by including the diversity factor in the Type 1 PSO algorithm. The developed algorithms are computationally faster (in terms of the number of load flows carried out) than the other methods because only one run is required.}
}
@article{OLCAYSOYOKTEN2022111606,
title = {When knowledge is blinding: The dangers of being certain about the future during uncertain societal events},
journal = {Personality and Individual Differences},
volume = {195},
pages = {111606},
year = {2022},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2022.111606},
url = {https://www.sciencedirect.com/science/article/pii/S0191886922001106},
author = {Irmak {Olcaysoy Okten} and Anton Gollwitzer and Gabriele Oettingen},
keywords = {Subjective certainty, Future thinking, COVID-19, Elections, Information seeking, Uncertainty},
abstract = {Past research has independently examined the concepts of certainty and future thought. Here we combine these concepts by examining the cognitive and behavioral outcomes of certainty about the future during periods of societal uncertainty. Three studies (N = 1218) examined future certainty, defined as feeling certain about some future event or outcome, during two major societal events of uncertainty—the COVID-19 pandemic and the 2020 U.S. Presidential Election. In Study 1, certainty about positive or negative futures of COVID-19 (e.g., the pandemic will end soon; the pandemic will never end) predicted poorer information seeking—ignorance of medical experts, adherence to conspiratorial thinking, and lower objective knowledgeability about COVID-19. Building on these findings, in Study 2, future certainty predicted antisocial health behaviors, including failing to social distance. Study 3 extended these findings to the political domain—the 2020 Presidential Election. Future certainty that one's preferred candidate would win the election predicted poor information seeking and antisocial behaviors in terms of claiming that the election was rigged, endorsing violence if one's candidate lost, and, among Trump supporters, identifying with Capitol insurrectionists. These findings suggest that future certainty is linked to intellectual blindness and antisocial behaviors during important periods of societal uncertainty.}
}
@article{MORRIS2015,
title = {Efficacy of a Web-Based, Crowdsourced Peer-To-Peer Cognitive Reappraisal Platform for Depression: Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {3},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4167},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115000783},
author = {Robert R Morris and Stephen M Schueller and Rosalind W Picard},
keywords = {Web-based intervention, crowdsourcing, randomized controlled trial, depression, cognitive behavioral therapy, mental health, social networks},
abstract = {Background
Self-guided, Web-based interventions for depression show promising results but suffer from high attrition and low user engagement. Online peer support networks can be highly engaging, but they show mixed results and lack evidence-based content.
Objective
Our aim was to introduce and evaluate a novel Web-based, peer-to-peer cognitive reappraisal platform designed to promote evidence-based techniques, with the hypotheses that (1) repeated use of the platform increases reappraisal and reduces depression and (2) that the social, crowdsourced interactions enhance engagement.
Methods
Participants aged 18-35 were recruited online and were randomly assigned to the treatment group, “Panoply” (n=84), or an active control group, online expressive writing (n=82). Both are fully automated Web-based platforms. Participants were asked to use their assigned platform for a minimum of 25 minutes per week for 3 weeks. Both platforms involved posting descriptions of stressful thoughts and situations. Participants on the Panoply platform additionally received crowdsourced reappraisal support immediately after submitting a post (median response time=9 minutes). Panoply participants could also practice reappraising stressful situations submitted by other users. Online questionnaires administered at baseline and 3 weeks assessed depression symptoms, reappraisal, and perseverative thinking. Engagement was assessed through self-report measures, session data, and activity levels.
Results
The Panoply platform produced significant improvements from pre to post for depression (P=.001), reappraisal (P<.001), and perseverative thinking (P<.001). The expressive writing platform yielded significant pre to post improvements for depression (P=.02) and perseverative thinking (P<.001), but not reappraisal (P=.45). The two groups did not diverge significantly at post-test on measures of depression or perseverative thinking, though Panoply users had significantly higher reappraisal scores (P=.02) than expressive writing. We also found significant group by treatment interactions. Individuals with elevated depression symptoms showed greater comparative benefit from Panoply for depression (P=.02) and perseverative thinking (P=.008). Individuals with baseline reappraisal deficits showed greater comparative benefit from Panoply for depression (P=.002) and perseverative thinking (P=.002). Changes in reappraisal mediated the effects of Panoply, but not the expressive writing platform, for both outcomes of depression (ab=-1.04, SE 0.58, 95% CI -2.67 to -.12) and perseverative thinking (ab=-1.02, SE 0.61, 95% CI -2.88 to -.20). Dropout rates were similar for the two platforms; however, Panoply yielded significantly more usage activity (P<.001) and significantly greater user experience scores (P<.001).
Conclusions
Panoply engaged its users and was especially helpful for depressed individuals and for those who might ordinarily underutilize reappraisal techniques. Further investigation is needed to examine the long-term effects of such a platform and whether the benefits generalize to a more diverse population of users.
Trial Registration
ClinicalTrials.gov NCT02302248; https://clinicaltrials.gov/ct2/show/NCT02302248 (Archived by WebCite at http://www.webcitation.org/6Wtkj6CXU).}
}
@incollection{ESFELD2015131,
title = {Atomism and Holism: Philosophical Aspects},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {131-135},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.63003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868630039},
author = {Michael Esfeld},
keywords = {Atomism, Collectivism, Confirmation, Externalism, Holism, Human nature, Individualism, Internalism, Meaning, Ontological dependence, Rationality, Rule-following, Thought},
abstract = {In the philosophy of the social sciences, atomism is the view that human beings can be thinking, rational beings independently of social relations. Holism, by contrast, is the view that social relations are essential to human beings insofar as they are thinking, rational beings. This article first provides an overview of different sorts of atomism and holism (see Section Types of Atomism and Holism). It then briefly sketches the historical background of these notions in modern philosophy (Section The Historical Background of Atomism and Holism). The main part is a systematic characterization of atomism and holism (see Section A Characterization of Atomism and Holism) and a summary of the most important arguments for both these positions (see Section Arguments for Atomism and Holism).}
}
@article{RAPAKA2025100809,
title = {Revolutionizing learning − A journey into educational games with immersive and AI technologies},
journal = {Entertainment Computing},
volume = {52},
pages = {100809},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100809},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124001770},
author = {Anuj Rapaka and S.C. Dharmadhikari and Kishori Kasat and Chinnem Rama Mohan and Kuldeep Chouhan and Manu Gupta},
keywords = {Artificial intelligence (AI), Educational games, Learning styles, Stochastic swing golf optimization (SSGOA)},
abstract = {Educational games rapidly integrate entertainment technology and learning, engaging individuals in dynamic educational experiences. These games incorporate multimedia content to encourage critical thinking, problem-solving and information retention. Educational games employ immersive technology such as virtual and augmented reality to transfer individuals to simulated worlds, hence improving learning. Furthermore, artificial intelligence (AI) technologies optimize educational experiences by adjusting information to individual learning styles, providing focused feedback as well as encouraging a more effective and entertaining learning technology. The integration of educational games with immersive and AI technology provides great potential for transforming how individuals acquire and apply information sharing. This research determined the creation of significant educational applications that are personalized and adaptive through the use of image, emotional recognition and speech, intelligent agents that replicate the effects of an individual opponent and control over the complexities of game levels along with information. The study evaluated the different tools that educators and learners could utilize to develop immersive and artificial intelligence-based instructional games without a requirement for programming knowledge. The study demonstrates that immersive technology and AI technology could represent beneficial resources for creating educational video games and entertainment technology. The research highlights the novel possibilities of stochastic swing golf optimization (SSGOA) immersive and AI technologies providing an innovative approach to developing effective as well as attractive learning environments.}
}
@article{WEHNER202387,
title = {On the ‘cognitive map debate’ in insect navigation},
journal = {Studies in History and Philosophy of Science},
volume = {102},
pages = {87-89},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S003936812300105X},
author = {Rüdiger Wehner and Thierry Hoinville and Holk Cruse},
keywords = {Insect navigation, Cognitive map, Neural network model, Path integration, Landmark guidance, Ants, Bees},
abstract = {In a historical account recently published in this journal Dhein argues that the current debate whether insects like bees and ants use cognitive maps (centralized map hypothesis) or other means of navigation (decentralized network hypothesis) largely reflects the classical debate between American experimental psychologists à la Tolman and German ethologists à la Lorenz, respectively. In this dichotomy we, i.e., the proponents of the network hypothesis, are inappropriately placed on the Lorenzian line. In particular, we argue that in contrast to Dhein's claim our concepts are not based on merely instinctive or peripheral modes of information processing. In general, on the one side our approaches have largely been motivated by the early biocybernetics way of thinking. On the other side they are deeply rooted in studies on the insect's behavioral ecology, i.e., in the ecological setting within which the navigational strategies have evolved and within which the animal now operates. Following such a bottom-up approach we are not “anti-cognitive map researchers” but argue that the results we have obtained in ants, and also the results of some decisive experiments in bees, can be explained and simulated without the need of invoking metric maps.}
}
@article{SAHA2024,
title = {Predicting depression level based on human activities and feelings: A fuzzy logic-based analysis},
journal = {Data Science and Management},
year = {2024},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S266676492400064X},
author = {Urmi Saha and Syed Mohammod {Minhaz Hossain} and Iqbal H. Sarker},
keywords = {Depression Level Prediction, Human Activities, Human Feelings, Pearson Correlation Method, R-Squared Method, Uncertainty, Fuzzy Rules},
abstract = {Millions of individuals die by suicide each year, and many more suffer from severe depression. Furthermore, these deaths harm education, the economy, and healthcare worldwide. An individual’s persistent feelings and activities, which include sleep disorders such as insomnia, sleeping overtime, or spending the majority of time lying down; pessimistic thinking about the future; and thoughts of committing suicide, help uncover the cause of depression. Several attempts have been made to prevent these losses and deaths. Our study proposes a simple fuzzy inference model that accurately predicts depression levels based on emotions and activities—even with incomplete data and uncertainties—and enhances mental health prediction, bridging theory and practice effectively. Psychologists and professors collaborated to create a survey to collect data for this study. The experiment was conducted using a Google survey form. This method effectively captures the ambiguity and imprecision in depression evaluation by combining linguistic elements of psychological traits. Using the Pearson correlation and R-squared methods, 15 features were chosen from 30 features, followed by five membership functions (poor, mediocre, average, decent, and good) and fuzzy rules to evaluate and create accurate forecasts of depression severity. Our proposed architecture can correctly classify depression levels based on human activities and feelings with 94% accuracy using a less sophisticated rules dictionary than previous pre-trained or hybrid models. Fuzzy logic performs better here by accurately categorizing ambiguous human emotional inputs into distinct degrees.}
}
@article{MASON2020103898,
title = {Development and analysis of the Elementary Student Coding Attitudes Survey},
journal = {Computers & Education},
volume = {153},
pages = {103898},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103898},
url = {https://www.sciencedirect.com/science/article/pii/S036013152030097X},
author = {Stacie L. Mason and Peter J. Rich},
keywords = {Elementary education, Computational thinking, Coding, Attitude scale, Instrument validation},
abstract = {There is an increasing emphasis on teaching young learners to code; yet, there are few tools designed to measure the effect of learning to code on children. The purpose of this study was to develop and validate a tool to assess changes in young learners' attitudes toward coding: the Elementary Student Coding Attitudes Survey (ESCAS). We validated the scale using Confirmatory Factory Analysis and Structural Equation Modeling with responses from over 6000 4th-6th grade students (aged 9–12 years). Survey validation revealed a scale consisting of five constructs that comprise young learners' attitudes toward coding: social value, coding confidence, coding interest, perception of coders, and coding utility. In our analysis, students' grade level, ethnicity, gender, coding frequency, coding experience, and math interest influenced social value, which in turn influenced coding interest, perception of coders, and coding utility. Students' math confidence, coding frequency, coding experience, ethnicity, and coding interest predicted their coding confidence. Among observable variables, coding frequency and math interest had the greatest influence on social value, which substantially influenced all other factors. We discuss how this tool can help those who teach coding to young children to better measure and understand the variables that may influence young learners’ attitudes toward coding over time.}
}
@article{HICKOK2011407,
title = {Sensorimotor Integration in Speech Processing: Computational Basis and Neural Organization},
journal = {Neuron},
volume = {69},
number = {3},
pages = {407-422},
year = {2011},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2011.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627311000675},
author = {Gregory Hickok and John Houde and Feng Rong},
abstract = {Sensorimotor integration is an active domain of speech research and is characterized by two main ideas, that the auditory system is critically involved in speech production and that the motor system is critically involved in speech perception. Despite the complementarity of these ideas, there is little crosstalk between these literatures. We propose an integrative model of the speech-related “dorsal stream” in which sensorimotor interaction primarily supports speech production, in the form of a state feedback control architecture. A critical component of this control system is forward sensory prediction, which affords a natural mechanism for limited motor influence on perception, as recent perceptual research has suggested. Evidence shows that this influence is modulatory but not necessary for speech perception. The neuroanatomy of the proposed circuit is discussed as well as some probable clinical correlates including conduction aphasia, stuttering, and aspects of schizophrenia.}
}
@article{CROOKS2014344,
title = {Defining and measuring conceptual knowledge in mathematics},
journal = {Developmental Review},
volume = {34},
number = {4},
pages = {344-377},
year = {2014},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2014.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0273229714000380},
author = {Noelle M. Crooks and Martha W. Alibali},
keywords = {Mathematical thinking, Conceptual knowledge, Equivalence, Cardinality, Inversion},
abstract = {A long tradition of research on mathematical thinking has focused on procedural knowledge, or knowledge of how to solve problems and enact procedures. In recent years, however, there has been a shift toward focusing, not only on solving problems, but also on conceptual knowledge. In the current work, we reviewed (1) how conceptual knowledge is defined in the mathematical thinking literature, and (2) how conceptual knowledge is defined, operationalized, and measured in three mathematical domains: equivalence, cardinality, and inversion. We uncovered three general issues. First, few investigators provide explicit definitions of conceptual knowledge. Second, the definitions that are provided are often vague or poorly operationalized. Finally, the tasks used to measure conceptual knowledge do not always align with theoretical claims about mathematical understanding. Together, these three issues make it challenging to understand the development of conceptual knowledge, its relationship to procedural knowledge, and how it can best be taught to students. In light of these issues, we propose a general framework that divides conceptual knowledge into two facets: knowledge of general principles and knowledge of the principles underlying procedures.}
}
@article{HEYN2023111604,
title = {A compositional approach to creating architecture frameworks with an application to distributed AI systems},
journal = {Journal of Systems and Software},
volume = {198},
pages = {111604},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111604},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222002801},
author = {Hans-Martin Heyn and Eric Knauss and Patrizio Pelliccione},
keywords = {AI systems, Architectural frameworks, Compositional thinking, Requirements engineering, Systems engineering},
abstract = {Artificial intelligence (AI) in its various forms finds more and more its way into complex distributed systems. For instance, it is used locally, as part of a sensor system, on the edge for low-latency high-performance inference, or in the cloud, e.g. for data mining. Modern complex systems, such as connected vehicles, are often part of an Internet of Things (IoT). This poses additional architectural challenges. To manage complexity, architectures are described with architecture frameworks, which are composed of a number of architectural views connected through correspondence rules. Despite some attempts, the definition of a mathematical foundation for architecture frameworks that are suitable for the development of distributed AI systems still requires investigation and study. In this paper, we propose to extend the state of the art on architecture framework by providing a mathematical model for system architectures, which is scalable and supports co-evolution of different aspects for example of an AI system. Based on Design Science Research, this study starts by identifying the challenges with architectural frameworks in a use case of distributed AI systems. Then, we derive from the identified challenges four rules, and we formulate them by exploiting concepts from category theory. We show how compositional thinking can provide rules for the creation and management of architectural frameworks for complex systems, for example distributed systems with AI. The aim of the paper is not to provide viewpoints or architecture models specific to AI systems, but instead to provide guidelines based on a mathematical formulation on how a consistent framework can be built up with existing, or newly created, viewpoints. To put in practice and test the approach, the identified and formulated rules are applied to derive an architectural framework for the EU Horizon 2020 project “Very efficient deep learning in the IoT” (VEDLIoT) in the form of a case study.}
}
@article{BARBER200798,
title = {Interplay between computational models and cognitive electrophysiology in visual word recognition},
journal = {Brain Research Reviews},
volume = {53},
number = {1},
pages = {98-123},
year = {2007},
issn = {0165-0173},
doi = {https://doi.org/10.1016/j.brainresrev.2006.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165017306000853},
author = {Horacio A. Barber and Marta Kutas},
keywords = {Language, Reading, Visual word recognition, Computational model, Event-related potential (ERP), EEG, MEG, Cognitive electrophysiology},
abstract = {In this article, we discuss the relevance of electrophysiological data to the enterprise of analyzing and understanding the reading process. Specifically, we detail how the event-related brain potential (ERP) technique (and its magnetic counterpart) can aid in development of models of visual word recognition. Any viable and accurate account of reading must take into account the temporal and anatomical constraints imposed by the fact that reading is a human brain function. We believe that neurophysiological (especially, although not limited to electrophysiological) data can serve an essential reference in the development of biologically realistic models of reading. We assess just how well extant electrophysiological data comport with specific predictions of existing computational models and offer some suggestions for the kinds of research that can address some of the remaining open questions.}
}
@article{WOLFE197853,
title = {The rise of network thinking in anthropology},
journal = {Social Networks},
volume = {1},
number = {1},
pages = {53-64},
year = {1978},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(78)90012-6},
url = {https://www.sciencedirect.com/science/article/pii/0378873378900126},
author = {Alvin W. Wolfe},
abstract = {The encyclopedic inventory of the first half of the twentieth century, “Anthropology Today”, published in 1953, gave little inkling that within a few decades developing trends in social theory, in field experience, in electronic data processing, and in mathematics would combine to bring to prominence a distinctive theoretical approach using a quite formal network model for social systems. Now, sophisticated mathematics and computer programming permit sophisticated network models — networks seen as sets of links, networks seen as generated structures, and networks seen as flow processes. Although network thinking has shown a dramatic rise from the “Anthropology Today” of 1953 to the current anthropology of 1978, it is predicted to soar in the next quarter century, much of the weighty burden of network analysis having been lifted from us by ever more rapid electronic data processing.}
}
@article{MATTHEWS2021100278,
title = {Reconceptualising feedback: Designing educational tangible technologies to be a creative material},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100278},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000210},
author = {Sarah Matthews and Ben Matthews},
keywords = {Tangible technologies, Feedback, Educational technologies, Creative material, Interaction design, Empirical studies},
abstract = {This paper investigates how children who are engaged in a creative project with tangible technology kits make sense of the system feedback the technology provides. A micro-analytic video study was conducted of primary school children designing their own technologies using existing educational microcontrollers. Our investigation reveals that the roles feedback plays in children’s interactions cannot easily be assimilated within the existing approaches to understand feedback that have been articulated in HCI literature. Our qualitative analysis shows how children do not make sense of feedback as semantic communication from the system, but make sense of it with respect to its embeddedness in a sequence of activities they are performing with the system and each other. The principal contribution to emerge from our study is a conception of feedback as a process, rather than as a semantic communicative event, nor a direct coupling of action and system response. Our discussion identifies how feedback participates in the institutional agendas of classrooms (e.g. discovery, computational thinking), and draws out initial implications for the design of feedback in educational tangible technologies, identifying possibilities for how feedback might be redesigned to better promote children’s diagnostic practices with open-ended technology kits.}
}
@article{MENGOV2014232,
title = {Person-by-person prediction of intuitive economic choice},
journal = {Neural Networks},
volume = {60},
pages = {232-245},
year = {2014},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014002123},
author = {George Mengov},
keywords = {Decision making, Economic choice, Experimental economics, Gated dipole, Intuitive thinking, Differential equations},
abstract = {Decision making is an interdisciplinary field, which is explored with methods spanning from economic experiments to brain scanning. Its dominant paradigms such as utility theory, prospect theory, and the modern dual-process theories all resort to formal algebraic models or non-mathematical postulates, and remain purely phenomenological. An approach introduced by Grossberg deployed differential equations describing neural networks and bridged the gap between decision science and the psychology of cognitive–emotional interactions. However, the limits within which neural models can explain data from real people’s actions are virtually untested and remain unknown. Here we show that a model built around a recurrent gated dipole can successfully forecast individual economic choices in a complex laboratory experiment. Unlike classical statistical and econometric techniques or machine learning algorithms, our method calibrates the equations for each individual separately, and carries out prediction person-by-person. It predicted very well the behaviour of 15%–20% of the participants in the experiment–half of them extremely well–and was overall useful for two thirds of all 211 subjects. The model succeeded with people who were guided by gut feelings and failed with those who had sophisticated strategies. One hypothesis is that this neural network is the biological substrate of the cognitive system for primitive–intuitive thinking, and so we believe that we have a model of how people choose economic options by a simple form of intuition. We anticipate our study to be useful for further studies of human intuitive thinking as well as for analyses of economic systems populated by heterogeneous agents.}
}
@article{ZOMAYA2004551,
title = {Parallel and nature-inspired computational paradigms and applications},
journal = {Parallel Computing},
volume = {30},
number = {5},
pages = {551-552},
year = {2004},
note = {Parallel and nature-inspired computational paradigms and applications},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2004.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167819104000304},
author = {Albert Y Zomaya and Fikret Ercal and El-ghazali Talbi}
}
@incollection{HALL2006338,
title = {Computational Approaches to Fibril Structure and Formation},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {412},
pages = {338-365},
year = {2006},
booktitle = {Amyloid, Prions, and Other Protein Aggregates, Part B},
issn = {0076-6879},
doi = {https://doi.org/10.1016/S0076-6879(06)12020-0},
url = {https://www.sciencedirect.com/science/article/pii/S0076687906120200},
author = {Carol K. Hall and Victoria A. Wagoner},
abstract = {Assembly of normally soluble proteins into amyloid fibrils is a cause or associated symptom of numerous human disorders. Although some progress toward understanding the molecular‐level details of fibril structure has been made through in vitro experiments, the insoluble nature of fibrils make them difficult to study experimentally. We describe two computational approaches used to investigate fibril formation and structure: intermediate‐resolution discontinuous molecular dynamics simulations and atomistic molecular dynamics simulations. Each method has its strengths and weaknesses, but taken together the two approaches provide a useful molecular‐level picture of fibril structure and formation.}
}
@article{TUZUN202085,
title = {Introduction to systems engineering and sustainability PART I: Student-centred learning for chemical and biological engineers},
journal = {Education for Chemical Engineers},
volume = {31},
pages = {85-93},
year = {2020},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2020.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1749772820300269},
author = {U. Tuzun},
keywords = {Systems engineering & sustainability, Active learning, Formative assessment},
abstract = {Student-Centred Active Learning of Systems Engineering and Sustainability requires challenging metacognitive integration of high-level evaluation skills combined with discipline-based core knowledge. This two-part series aims to demonstrate the basic principles, methodology and specific examples of active learning with formative assessment implemented to achieve improved student academic performance. In this part I of the two-part series, firstly, a detailed description is introduced of the cognitive learning methodology which makes use of student-centered recognition, analysis and synthesis for decision-making when there is no entirely right or wrong decision. The concept of “decision situation” is described which combines several surrounding and contingency elements to arrive at a demonstration of the holistic decision-making through systems analysis. A Holistic thinking approach is further developed using a systems learning methodology that combines normative with descriptive analyses to arrive at a cognitive mode model of judgement and choice. Sustainability modelling using the three-gateway systems approach is introduced and compared with the multi-layered view of chemical and biochemical engineering education and research; see Gani et al. (2020). Holistic thinking strategy is applied most recently to integrating, backcasting and eco-design for the circular economy (CE); see Mendoza et al. (2017). A student-centred learning approach is advocated that makes use of these principles and enables the systematic embedding of sustainability modeling in industrial and economic activities whose success rely substantively on decision-making. Finally, the relative importance is evaluated using classroom data available with specific engineering topics of the didactic “rule-based” methods of knowledge transfer in contrast with the experiential accumulation of practical information amassed through social interactions in a co-operative learning environment that relies on sustained improvement through active communication and feedback between the teacher/instructor and the student/learner; see Stephan et al. (2017) and Shallcross and Alpay (2018).}
}
@article{BOKHOVE2023100497,
title = {Using Social Network Analysis to gain insight into social creativity while designing digital mathematics books},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100497},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100497},
url = {https://www.sciencedirect.com/science/article/pii/S259029112300102X},
author = {Christian Bokhove and Marios Xenos and Manolis Mavrikis},
keywords = {Technological environment, Co-creation, Social creativity, Social network analysis},
abstract = {Analysing the processes and products of creativity to better understand and support individuals and teams, is a difficult and elusive challenge despite years of research in creativity. In this article, we are particularly interested in social creativity in communities of interest. Building on Guilford's classic model of Divergent Thinking of fluency, flexibility, originality and elaboration, we employ Social Network Analysis to model the creative design process. The creative process in the current study takes place in a technological environment called the ‘MC-squared platform’, in which members of a community of interest collaborate in a social, co-creative process for designing digital, mathematical textbooks. Both the technological environment and the methodology are exemplified through two case examples, one on the design process of a digital book about a bioclimatic amusement park and one on the design process of a digital book about fractions. We conclude that, for these examples, both the technological tool and the data analysis approach provide insight into the social creativity process of the community of interest.}
}
@article{SAVARD2025109184,
title = {Toward cognitive models of misophonia},
journal = {Hearing Research},
volume = {458},
pages = {109184},
year = {2025},
issn = {0378-5955},
doi = {https://doi.org/10.1016/j.heares.2025.109184},
url = {https://www.sciencedirect.com/science/article/pii/S0378595525000036},
author = {Marie-Anick Savard and Emily B.J. Coffey},
keywords = {Misophonia, Cognitive science, Cognitive neuroscience, Sound sensitivity, Models},
abstract = {Misophonia is a disorder in which specific common sounds such as another person breathing or chewing, or the ticking of a clock, cause an atypical negative emotional response. Affected individuals may experience anger, irritability, annoyance, disgust, and anxiety, as well as physiological autonomic responses, and may find everyday environments and contexts to be unbearable in which their ‘misophonic stimuli’ (often called ‘trigger sounds’) are present. Misophonia is gradually being recognized as a genuine problem that causes significant distress and has negative consequences for individuals and their families. It has only recently come under scientific scrutiny, as researchers and clinicians are establishing its prevalence, distinguishing it from other disorders of sensory sensitivity such as hyperacusis, establishing its neurobiological bases, and evaluating the effectiveness of potential treatments. While ideas abound as to the mechanisms involved in misophonia, few have coalesced into models. The aim of the present work is to summarize and extend recent thinking on the mechanistic basis of misophonia, with a focus on moving towards neurologically-informed cognitive models that can (a) account for extant findings, and (b) generate testable predictions. We hope this work will facilitate future refinements in our understanding of misophonia, and ultimately inform treatments.}
}
@article{SCHEENSTRA2022,
title = {Digital Health Solutions to Reduce the Burden of Atherosclerotic Cardiovascular Disease Proposed by the CARRIER Consortium},
journal = {JMIR Cardio},
volume = {6},
number = {2},
year = {2022},
issn = {2561-1011},
doi = {https://doi.org/10.2196/37437},
url = {https://www.sciencedirect.com/science/article/pii/S256110112200037X},
author = {Bart Scheenstra and Anke Bruninx and Florian {van Daalen} and Nina Stahl and Elizabeth Latuapon and Maike Imkamp and Lianne Ippel and Sulaika Duijsings-Mahangi and Djura Smits and David Townend and Inigo Bermejo and Andre Dekker and Laura Hochstenbach and Marieke Spreeuwenberg and Jos Maessen and Arnoud {van 't Hof} and Bas Kietselaer},
keywords = {atherosclerotic cardiovascular disease, ASCVD, cardiovascular risk management, CVRM, eHealth, digital Health, personalized e-coach, big data, clinical prediction models, federated data infrastructure},
abstract = {Digital health is a promising tool to support people with an elevated risk for atherosclerotic cardiovascular disease (ASCVD) and patients with an established disease to improve cardiovascular outcomes. Many digital health initiatives have been developed and employed. However, barriers to their large-scale implementation have remained. This paper focuses on these barriers and presents solutions as proposed by the Dutch CARRIER (ie, Coronary ARtery disease: Risk estimations and Interventions for prevention and EaRly detection) consortium. We will focus in 4 sections on the following: (1) the development process of an eHealth solution that will include design thinking and cocreation with relevant stakeholders; (2) the modeling approach for two clinical prediction models (CPMs) to identify people at risk of developing ASCVD and to guide interventions; (3) description of a federated data infrastructure to train the CPMs and to provide the eHealth solution with relevant data; and (4) discussion of an ethical and legal framework for responsible data handling in health care. The Dutch CARRIER consortium consists of a collaboration between experts in the fields of eHealth development, ASCVD, public health, big data, as well as ethics and law. The consortium focuses on reducing the burden of ASCVD. We believe the future of health care is data driven and supported by digital health. Therefore, we hope that our research will not only facilitate CARRIER consortium but may also facilitate other future health care initiatives.}
}
@article{BROSSEAU2003373,
title = {Computational electromagnetics and the rational design of new dielectric heterostructures},
journal = {Progress in Materials Science},
volume = {48},
number = {5},
pages = {373-456},
year = {2003},
issn = {0079-6425},
doi = {https://doi.org/10.1016/S0079-6425(02)00013-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079642502000130},
author = {C. Brosseau and A. Beroual},
abstract = {Dielectric properties of heterogeneous materials for various condensed-matter systems have been gaining world-wide attention over the past 50 or so years in the design (or engineering) of materials structures for desired properties and functional purposes. These applications range from cable and current limiters to sensors. These multiscale systems lead to challenging problems of connecting micro- or meso-structural features to macroscopic materials response, i.e. permittivity, conductivity. This article first reviews progress made at that time of the underlying physics of dielectric heterostructures and points out the missing elements that have led to a resurgence of interest in these and related materials. Recent advances in computational electromagnetics provide unparalleled control over morphology in this class of materials to produce a seemingly unlimited number of exquisitely structured materials endowed with tailored electromagnetic, and other physical properties. In the text to follow, we illustrate how an ab initio computational technique can be used to accurately characterize structure–dielectric property relationships of periodic heterostructures in the quasistatic limit. More specifically, we have carried out two-dimensional (2D) and three-dimensional (3D) numerical studies of two-component materials in which equal-sized inclusions, with shape and orientation and possibly fused together, are fixed in a periodic square (2D) or cubic (3D) array. Boundary-integral equations (BIE) are derived from Green's theorem and are solved for the local field with appropriate periodicity conditions on a unit cell of the structures using the field calculation package PHI3D. A number of illustrative examples shows how this computational technique can provide very accurate predictions for the complex effective permittivity of translationally-invariant heterostructures. The performance of the method is also compared with those of other computational and analytical techniques. We comment on how this computational method helps identify some important characteristics for rationalizing and predicting the structure of composite materials in terms of the nature, size, shape and orientation of their constituents.}
}
@incollection{BUCHANAN2024,
title = {Semantic Feature Production Norms},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00045-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041000454},
author = {Erin M. Buchanan},
keywords = {Datasets, Features, Knowledge, Memory, Norms, Production task, Semantics},
abstract = {Feature production norms are collected by asking participants to name the defining features of a concept, such as tail, fur, and meow for the concept cat. Collection and analysis of features should include special considerations for methodology and data processing including the task instructions, segmentation, word removal, spell checking and more. The processed data can be used to define concept similarity, control stimuli for new experimental studies, and in computational models of memory and knowledge representation.}
}
@incollection{CAMERON200789,
title = {Designing Computational Clusters for Performance and Power},
editor = {Marvin V. Zelkowitz},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {69},
pages = {89-153},
year = {2007},
booktitle = {Architectural Issues},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(06)69002-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065245806690025},
author = {Kirk W. Cameron and Rong Ge and Xizhou Feng},
abstract = {Power consumption in computational clusters has reached critical levels. High-end cluster performance improves exponentially while the power consumed and heat dissipated increase operational costs and failure rates. Yet, the demand for more powerful machines continues to grow. In this chapter, we motivate the need to reconsider the traditional performance-at-any-cost cluster design approach. We propose designs where power and performance are considered critical constraints. We describe power-aware and low power techniques to reduce the power profiles of parallel applications and mitigate the impact on performance.}
}
@article{DRAGGIOTIS1998157,
title = {On the computation of multigluon amplitudes},
journal = {Physics Letters B},
volume = {439},
number = {1},
pages = {157-164},
year = {1998},
issn = {0370-2693},
doi = {https://doi.org/10.1016/S0370-2693(98)01015-6},
url = {https://www.sciencedirect.com/science/article/pii/S0370269398010156},
author = {Petros Draggiotis and Ronald H.P. Kleiss and Costas G. Papadopoulos},
abstract = {A computational algorithm based on recursive equations is developed in order to estimate multigluon production processes at high energy hadron colliders. The partonic reactions gg→(n−2)g with n≤9 are studied and comparisons with known approximations are presented.}
}
@article{VARTIAINEN2021100281,
title = {Machine learning for middle schoolers: Learning through data-driven design},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100281},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100281},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000222},
author = {Henriikka Vartiainen and Tapani Toivonen and Ilkka Jormanainen and Juho Kahila and Matti Tedre and Teemu Valtonen},
keywords = {AI, Machine learning, K-12, Computational thinking, Design-oriented pedagogy, Design-based research},
abstract = {An entire generation of children is growing up with machine learning (ML) systems that are greatly disrupting job markets as well as changing people’s everyday lives. Yet, that development and its societal effects have been given minor attention in computing education in schools, which mainly focuses on rule-based programming. This article presents a pedagogical framework for supporting middle schoolers to become co-designers and makers of their own machine learning applications. It presents a case study conducted in the 6th grade of a Finnish elementary school and analyzes students’ (N=34) evolving ML ideas and explanations. Data consists of a children’s artwork, students’ design ideas and co-designed applications, and structured group interviews organized at the end of the ML project. The qualitative content analysis revealed how hands-on exploration with ML-based technologies supported students in developing various kinds of design ideas that harnessed face recognition, gestures, or voice recognition for solving real-life problems. The results of the study further indicated that co-designing ML applications provided a promising entry point for students to develop their conceptual understanding of ML principles, its workflows, and its role in their everyday practices. The article concludes with a discussion on how to support students to become innovators and software designers in the age of machine learning.}
}
@article{ELABY2022101780,
title = {Does design-build concept improve problem-solving skills? An analysis of first-year engineering students},
journal = {Ain Shams Engineering Journal},
volume = {13},
number = {6},
pages = {101780},
year = {2022},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2022.101780},
url = {https://www.sciencedirect.com/science/article/pii/S2090447922000910},
author = {Mohammed F. Elaby and Hesham M. Elwishy and Saeed F. Moatamed and Mahmoud A. Abdelwahed and Ahmed E. Rashiedy},
keywords = {Problem-solving, Critical thinking, Design-build studio, Instructional design},
abstract = {The design-build studio (DBS) is an emergent paradigm in architecture education. Recently, researchers have addressed the success of integrating the design-build concept into the conventional studio in the advanced years of education to improve several issues related to the design process: social, environmental, technological, …etc. However, its efficiency in terms of contribution to the learning experience has not yet been addressed. This paper examines the implementation of the DBS concept as a new teaching model to improve the problem-solving skills (PSS) of first-year students in engineering education. It also discusses the effectson learning experiences and pedagogical outcomes in both quantitative and qualitative terms. The research’s results identify the significance of applying this model as a real-simulated method-based learning experience. It can help students to improve their learning experiences and to enhance students self-confidence regarding PSS.}
}
@incollection{YANG20133,
title = {1 - Swarm Intelligence and Bio-Inspired Computation: An Overview},
editor = {Xin-She Yang and Zhihua Cui and Renbin Xiao and Amir Hossein Gandomi and Mehmet Karamanoglu},
booktitle = {Swarm Intelligence and Bio-Inspired Computation},
publisher = {Elsevier},
address = {Oxford},
pages = {3-23},
year = {2013},
isbn = {978-0-12-405163-8},
doi = {https://doi.org/10.1016/B978-0-12-405163-8.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124051638000016},
author = {Xin-She Yang and Mehmet Karamanoglu},
keywords = {Algorithm, ant algorithm, bee algorithm, bat algorithm, bio-inspired, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, swarm intelligence, metaheuristics},
abstract = {Swarm intelligence (SI) and bio-inspired computing in general have attracted great interest in almost every area of science, engineering, and industry over the last two decades. In this chapter, we provide an overview of some of the most widely used bio-inspired algorithms, especially those based on SI such as cuckoo search, firefly algorithm, and particle swarm optimization. We also analyze the essence of algorithms and their connections to self-organization. Furthermore, we highlight the main challenging issues associated with these metaheuristic algorithms with in-depth discussions. Finally, we provide some key, open problems that need to be addressed in the next decade.}
}