@article{SHYJA2023100465,
title = {Link quality and energy efficient optimal simplified cluster based routing scheme to enhance lifetime for wireless body area networks},
journal = {Nano Communication Networks},
volume = {37},
pages = {100465},
year = {2023},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2023.100465},
url = {https://www.sciencedirect.com/science/article/pii/S1878778923000315},
author = {V. Irine Shyja and G. Ranganathan and V. Bindhu},
keywords = {WBAN, Clustering, Cluster head, Multipath routing scheme, Link quality},
abstract = {Monitoring of patient’s health in the medical industry can be enabled using wireless body area networks (WBANs), which are already used for various purposes, including assisting in human safety. It is imperative to use better power management strategies since the body sensors are small and the battery cannot hold a charge for a long time. Due to the vast amounts of information generated by medical sensors, resource-constrained networks face a significant challenge when guaranteeing the specified quality of service (QoS). Moreover, the WBAN regularly meets the primary hassle of QoS degradation because of congestion WBAN structure can easily compromise heterogeneous and complex networks. Either inappropriate data collection or using energy effectively to transmit medical data without the expense of travel and length has become an important one. To address this issue, the present research work ‘Link Quality and Energy Efficient Optimal Clustering-Multipath (LEOC-MP)’ scheme tries to explore an answer. The main goals of the LEOC-MP (Optimal Link Quality and Energy Efficient Optimal Clustering-Multipath) system are to guarantee node-to-node link quality, lengthen network life, and compute high-performing cluster heads to guarantee reliable multi path data transfer. This work was executed in three phases. First, an optimal simplified clustering technique for data collection from body sensors using an improved pelican optimization (ICO) algorithm is introduced. Next, multiple design constraints for node rank computation, energy efficiency, link quality, path loss, distance, and delay are used. Besides, an Auto-Regressive Probabilistic Neural Network (AR-PNN) is introduced to optimize those design constraints and compute the cluster head (CH) of each cluster. Multipath firing is then performed using a moderated puffer-fish optimization (MPO) algorithm that finds the closest optimal and shortest node to transmit optimal drug data. The work is simulated using an NS-3 environment, and the results are obtained. The outcome of this work is analyzed with existing methodologies, and the results prove that the present work consistently outperforms the existing methodologies.}
}
@article{ARORA2022108615,
title = {Music as a blend of spirituality, culture, and mind mollifying drug},
journal = {Applied Acoustics},
volume = {189},
pages = {108615},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108615},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X2100709X},
author = {Shefali Arora and Abhinav Tyagi},
keywords = {Music, Science, Emotions, Society, Health, COVID-19 etc},
abstract = {Science inspires music more often than human imagination. Music is an integral part of all societies, including animal ones. It is behaving like an instrument for digesting information. It has been proven to help in healing the body, mind, and culture. Music can maintain and regulate emotion. It is a common thread among large social groups and is used as a tool to navigate through life. Real science and real music require a steady thinking process. It is a way of finding compatibility within a society as well as developing a link with other societies. Music plays a developmental role in a person’s identity, cultural worldview and permeates through life. In nutshell “Science explains Music and Music makes us The Human”}
}
@article{SCHAEFER2024108796,
title = {GPT-4 as a biomedical simulator},
journal = {Computers in Biology and Medicine},
volume = {178},
pages = {108796},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108796},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524008813},
author = {Moritz Schaefer and Stephan Reichl and Rob {ter Horst} and Adele M. Nicolas and Thomas Krausgruber and Francesco Piras and Peter Stepper and Christoph Bock and Matthias Samwald},
keywords = {Biomedical simulation, Large language models, GPT-4, Computational biology, Artificial intelligence},
abstract = {Background
Computational simulation of biological processes can be a valuable tool for accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks. This study provides proof-of-concept for the use of GPT-4 as a versatile simulator of biological systems.
Methods
We introduce SimulateGPT, a proof-of-concept for knowledge-driven simulation across levels of biological organization through structured prompting of GPT-4. We benchmarked our approach against direct GPT-4 inference in blinded qualitative evaluations by domain experts in four scenarios and in two quantitative scenarios with experimental ground truth. The qualitative scenarios included mouse experiments with known outcomes and treatment decision support in sepsis. The quantitative scenarios included prediction of gene essentiality in cancer cells and progression-free survival in cancer patients.
Results
In qualitative experiments, biomedical scientists rated SimulateGPT's predictions favorably over direct GPT-4 inference. In quantitative experiments, SimulateGPT substantially improved classification accuracy for predicting the essentiality of individual genes and increased correlation coefficients and precision in the regression task of predicting progression-free survival.
Conclusion
This proof-of-concept study suggests that LLMs may enable a new class of biomedical simulators. Such text-based simulations appear well suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulations, but for which extensive knowledge is available as written text. Finally, we propose several directions for further development of LLM-based biomedical simulators, including augmentation through web search retrieval, integrated mathematical modeling, and fine-tuning on experimental data.}
}
@article{BIRHANE2021100205,
title = {Algorithmic injustice: a relational ethics approach},
journal = {Patterns},
volume = {2},
number = {2},
pages = {100205},
year = {2021},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2021.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2666389921000155},
author = {Abeba Birhane},
keywords = {justice, ethics, Afro-feminism, relational epistemology, data science, complex systems, enaction, embodiment, artificial intelligence, machine learning},
abstract = {Summary
It has become trivial to point out that algorithmic systems increasingly pervade the social sphere. Improved efficiency—the hallmark of these systems—drives their mass integration into day-to-day life. However, as a robust body of research in the area of algorithmic injustice shows, algorithmic systems, especially when used to sort and predict social outcomes, are not only inadequate but also perpetuate harm. In particular, a persistent and recurrent trend within the literature indicates that society's most vulnerable are disproportionally impacted. When algorithmic injustice and harm are brought to the fore, most of the solutions on offer (1) revolve around technical solutions and (2) do not center disproportionally impacted communities. This paper proposes a fundamental shift—from rational to relational—in thinking about personhood, data, justice, and everything in between, and places ethics as something that goes above and beyond technical solutions. Outlining the idea of ethics built on the foundations of relationality, this paper calls for a rethinking of justice and ethics as a set of broad, contingent, and fluid concepts and down-to-earth practices that are best viewed as a habit and not a mere methodology for data science. As such, this paper mainly offers critical examinations and reflection and not “solutions.”}
}
@incollection{LUND202435,
title = {3 - Choice Awareness strategies},
editor = {Henrik Lund},
booktitle = {Renewable Energy Systems (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {35-50},
year = {2024},
isbn = {978-0-443-14137-9},
doi = {https://doi.org/10.1016/B978-0-443-14137-9.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443141379000036},
author = {Henrik Lund},
keywords = {Alternatives assessment, Choice Awareness, Feasibility studies, Institutional barriers, Market barriers, Path dependency, Public regulation, Radical technological change, Renewable energy systems, Technical alternatives},
abstract = {This chapter introduces strategies to raise the awareness of how to implement smart energy systems in fully decarbonized societies using the Choice Awareness theory. Choice Awareness is based on the understanding that existing institutional perceptions and organizational interests will often seek to eliminate certain choices from the political decision-making process, when the introduction of radical technological change is discussed. The counterstrategy is to raise public awareness that alternatives do exist and that it is possible to make a choice. Counterstrategies may involve the design of technical alternatives, feasibility studies based on institutional economic thinking, and the design of public regulation measures seen in the light of conflicting interests as well as changes in the democratic decision-making infrastructure. Each of the strategies is elaborated on in this chapter.}
}
@article{YU2025101303,
title = {AI as a co-creator and a design material: Transforming the design process},
journal = {Design Studies},
volume = {97},
pages = {101303},
year = {2025},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2025.101303},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X25000158},
author = {Wendy Fangwen Yu},
keywords = {, , , , },
abstract = {Recent advancements in Artificial Intelligence (AI) have created new opportunities for incorporating AI into creative activities. Consequently, AI has become an increasingly significant tool in the design process, changing traditional workflows. This paper explores AI's role as both a co-creator and a design material, focusing on its impact on the ideation and evaluation stages of the design process. Through a transdisciplinary literature review, this study reveals that AI enhances creativity by providing inspirational stimuli, and supports evaluation and decision-making. However, it also introduces complexities such as cognitive overload and dependency. This paper emphasizes the need for design education reform, and training students as Designer Arbiters and Integrators to effectively collaborate with AI in a rapidly evolving technological landscape.}
}
@article{YANG20163,
title = {Modeling Urban Design with Energy Performance},
journal = {Energy Procedia},
volume = {88},
pages = {3-8},
year = {2016},
note = {CUE 2015 - Applied Energy Symposium and Summit 2015: Low carbon cities and urban energy systems},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2016.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1876610216300662},
author = {Perry Pei-Ju Yang and Jinyue Yan},
keywords = {Urban design computational model, Energy process model, Urban energy system, Urban design, Energy performance},
abstract = {Traditional urban design methods focus on the form-making process and lack performance dimensions such as energy efficiency. There are inherent differences between Urban Design as a model of decision-making for choosing form alternatives and Energy System Modeling as a model of evaluating and assessing system functions. To design a high energy performance city, the gap between the two models must be bridged. We propose a research design that combines the Urban Design Computational Model (UDCM) and the Optimization Model of Energy Process (OMEP) to demonstrate how an urban design computation can be integrated with an energy performance process and system. An evidence-based case study of community-level near zero energy districts will be needed for future work.}
}
@article{LAW2023112555,
title = {Frontopolar cortex represents complex features and decision value during choice between environments},
journal = {Cell Reports},
volume = {42},
number = {6},
pages = {112555},
year = {2023},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2023.112555},
url = {https://www.sciencedirect.com/science/article/pii/S2211124723005661},
author = {Chun-Kit Law and Nils Kolling and Chetwyn C.H. Chan and Bolton K.H. Chau},
keywords = {frontopolar cortex, ventromedial prefrontal cortex, decision making, environment choice, convolutional neural network, CNN},
abstract = {Summary
Important decisions often involve choosing between complex environments that define future item encounters. Despite its importance for adaptive behavior and distinct computational challenges, decision-making research primarily focuses on item choice, ignoring environment choice altogether. Here we contrast previously studied item choice in ventromedial prefrontal cortex with lateral frontopolar cortex (FPl) linked to environment choice. Furthermore, we propose a mechanism for how FPl decomposes and represents complex environments during decision making. Specifically, we trained a choice-optimized, brain-naive convolutional neural network (CNN) and compared predicted CNN activation with actual FPl activity. We showed that the high-dimensional FPl activity decomposes environment features to represent the complexity of an environment to make such choice possible. Moreover, FPl functionally connects with posterior cingulate cortex for guiding environment choice. Further probing FPl’s computation revealed a parallel processing mechanism in extracting multiple environment features.}
}
@article{NAWAZ2024102806,
title = {Grappling with a sea change: Tensions in expert imaginaries of marine carbon dioxide removal},
journal = {Global Environmental Change},
volume = {85},
pages = {102806},
year = {2024},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2024.102806},
url = {https://www.sciencedirect.com/science/article/pii/S0959378024000104},
author = {Sara Nawaz and Javier Lezaun},
abstract = {While research on marine carbon dioxide removal (mCDR) expands apace, significant unknowns persist regarding the risks and benefits of individual mCDR options. This paper analyses the assumptions and expectations that animate expert understandings of mCDR, with a focus on issues that are central to the responsible governance of this emerging field of climate action. Drawing upon interviews with experts involved in mCDR research projects both academic and entrepreneurial, we highlight four thematic tensions that orient their thinking but are often unstated or left implicit in scientific and technical assessments: (1) the relevance of ‘naturalness’ as a criterion of evaluation for mCDR approaches; (2) the perceived need to accelerate research and development activities via alternative paradigms of evidence-building; (3) a framing of mCDR as a form of waste management that will, in turn, generate new (and currently poorly understood) forms of environmental pollutants; and (4) a commitment to inclusive governance mixed with difficulty in identifying specific stakeholders or constituencies in mCDR interventions. Although expert consensus on these four issues is unlikely, we suggest ways of ensuring that consideration of these themes enriches debate on the responsible development of novel mCDR capabilities.}
}
@article{WOLFENGAGEN2016359,
title = {Migration of the Individuals},
journal = {Procedia Computer Science},
volume = {88},
pages = {359-364},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.449},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317057},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov and Irina A. Parfenova and Mikhail Yu. Ermak and Vasiliy D. Petrov and Ilya A. Nikulin and Victor A. Kholodov},
keywords = {data model, computational model, conceptual modeling, stage-by-stage cognition model, variable domains, Big Data, Thick Data},
abstract = {The individuals are modeled by the elements of variable domains. The primitive frame to detect the individual migration from domain to domain is proposed. The supporting computational model is based on a separation of individuals into actual, possible and virtual ones. As was shown, this leads to an adoption of the stage-by-stage cognition model with a pair of evolvents to capture dynamics of the domains – the 2-dimensions model. The first evolvent reflects the generation of the individuals in a domain, the beginning of and canceling out their existence in a domain. The second evolvent reflects the shifts in properties of the individuals. As awaited this unified data model will have the applications to a wide range of models in computer science and Information Technologies.}
}
@article{AKPOLAT2025,
title = {Enhancing operational reliability for high penetration of green hydrogen production in energy islands: A power-to-X case study},
journal = {International Journal of Hydrogen Energy},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.02.131},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925006962},
author = {Alper Nabi Akpolat},
keywords = {Distributed energy resources, Energy islands, Green hydrogen production, Power electronic converters, Machine learning, Power-to-X, Reliability},
abstract = {The production, storage, and conversion of hydrogen into energy, as well as its use in areas such as green ammonia production for agriculture or the catalysis of natural gas, are of significant interest due to their stable structure and source diversity. For this purpose, energy islands (EIs) have been established near consumption points, and renewable energy (RE) obtained from photovoltaic (PV) panels and wind turbines (WTs) is used for green hydrogen production (GHP). In these EIs, hydrogen production from renewable sources shows significant growth, contributing to the power-to-X (P2X) system in terms of storage and flexibility. GHP through renewables will likely become a prominent solution for EIs within the next ten years. One of the bottlenecks here is not to reflect the adverse effects of the variable nature of renewables while transferring sustainable energy. Herein, to enhance operation sustainability, stability, and reliability of renewable-based distributed energy resources (DERs), machine learning (ML)-based techniques can be neat and auxiliary solutions. Power electronic converters (PECs) have such a duty as being the backbone of transferring energy in renewables. The crucial matter is here to keep the inputs and outputs of the converters as stable as possible. In this context, this paper outlines an ML approach to reduce the computational burden and enhance reliability. Therefore, this paper proposes the utilization of an EI to strengthen the stability and reliability of the general scheme. This work is a preliminary attempt and effective solution to establish these EIs, including GHP, considering feasibility criteria and improving reliability. Furthermore, this study examines the essential components, design criteria, challenges, and future issues for system establishment. It aims to facilitate the work of researchers in this field and further enhance the development of EIs.}
}
@incollection{STAPLETON2014127,
title = {8.07 - Administrative Evil and Patient Health: A Critique of the Impact of Manufacturing Systems on Health Care},
editor = {Saleem Hashmi and Gilmar Ferreira Batalha and Chester J. {Van Tyne} and Bekir Yilbas},
booktitle = {Comprehensive Materials Processing},
publisher = {Elsevier},
address = {Oxford},
pages = {127-150},
year = {2014},
isbn = {978-0-08-096533-8},
doi = {https://doi.org/10.1016/B978-0-08-096532-1.00813-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008096532100813X},
author = {L. Stapleton},
keywords = {AMAT, Health, Manufacturing},
abstract = {Manufacturing systems principles underpin enterprise information systems. Nowadays these principles, and the systems that accompany them, are widely applied across various sectors, including health services management systems. The question arises: To what extent are these principles appropriate for health care management applications? This chapter explores the question from a human-centered systems perspective by examining the rationalities and assumptions that underpin manufacturing systems and applying these ideas to health care contexts. Human-centered systems have a long theoretical tradition within the automation and control community stretching back at least into the 1970s. It is a particularly strong theme in manufacturing systems research. As automation and control systems are increasingly important outside the factory, many researchers are revisiting core concepts within this tradition. One particularly important sector is health care, which, in recent years, has implemented a range of AMAT (automation and machine-assisted thinking)-type solutions not the least of which are enterprise resource planning systems (ERPs). These implementations have been accompanied by highly publicized systems failures. Ethical problems have also arisen. The chapter exposes an ‘administrative evil’ that relegates the patient to the status of a subassembly, a component in an ever-more complex health care production line. Humans are dehumanized in the rationality of our health care administrative systems. The chapter concludes that health care systems projects should adopt a human-centered approach that draws on research in manufacturing, automation, and control engineering as well as other disciplines.}
}
@article{VIDENOVIK2024100616,
title = {Game-based learning approach in computer science in primary education: A systematic review},
journal = {Entertainment Computing},
volume = {48},
pages = {100616},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100616},
url = {https://www.sciencedirect.com/science/article/pii/S187595212300071X},
author = {Maja Videnovik and Ana {Madevska Bogdanova} and Vladimir Trajkovik},
keywords = {Educational game, Game-based learning, Computer science, Primary education},
abstract = {This paper reviews the current situation concerning the implementation of game-based learning in computer science in primary education, providing insight into current trends, identifying strengths and potential research topics. Articles published in four databases from 2017 to 2021 are included in the analysis and an in-depth analysis of 32 articles is done. Different types of games, implemented in various educational contexts, are presented in these articles. Most of them describe implemented methodology, game-based environment or are evaluating the effectiveness of the created game or the approach. The possibility of implementing a game-based approach while learning other computer science topics or measuring the effectiveness of learning by designing a game as a pedagogical strategy are some areas for future research.}
}
@article{GRIFFIN1977127,
title = {On the application of boundary conditions to time dependent computations for quasi one-dimensional fluid flows},
journal = {Computers & Fluids},
volume = {5},
number = {3},
pages = {127-137},
year = {1977},
issn = {0045-7930},
doi = {https://doi.org/10.1016/0045-7930(77)90019-6},
url = {https://www.sciencedirect.com/science/article/pii/0045793077900196},
author = {Michael D. Griffin and Anderson {John D.}},
abstract = {A study is made of the influence of boundary and initial conditions on time-dependent finite-difference solutions of quasi-one-dimensional duct flows. Several questions are addressed: (1) Under what conditions will a time-dependent solution converge to a steady-state supersonic flow, (2) Under what conditions will it converge to subsonic flow and (3) What conditions are necessary to insure a particular unique solution for subsonic flows. The results provide an orientation, or way of thinking, about the role of such conditions in time-dependent solutions of steady-state flows. The results also show that supersonic solutions are readily obtained by holding only pressure and temperature fixed at the duct inlet, and allowing velocity to float. However, subsonic solutions require pressure, temperature and velocity to be fixed at both the duct inlet and exit. If no conditions are held fixed at the exit, the results always converge to the supersonic solution, even if the fixed inlet mass flow is less than critical. In such a case, the program appears to generate additional mass flow between the inlet and throat, sufficient to choke the flow. These results also have some impact on two- and three-dimensional time-dependent solutions where subsonic flow is present on some or all portions of the flow boundaries.}
}
@article{LIU2022102936,
title = {A review of spatially-explicit GeoAI applications in Urban Geography},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {112},
pages = {102936},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102936},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001339},
author = {Pengyuan Liu and Filip Biljecki},
keywords = {Urban studies, Deep learning, Socio-economics, Location encoder, Graph neural network},
abstract = {Urban Geography studies forms, social fabrics, and economic structures of cities from a geographic perspective. Catalysed by the increasingly abundant spatial big data, Urban Geography seeks new models and research paradigms to explain urban phenomena and address urban issues. Recent years have witnessed significant advances in spatially-explicit geospatial artificial intelligence (GeoAI), which integrates spatial studies and AI, primarily focusing on incorporating spatial thinking and concept into deep learning models for urban studies. This paper provides an overview of techniques and applications of spatially-explicit GeoAI in Urban Geography based on 581 papers identified using a systematic review approach. We examined and screened papers in three scopes of Urban Geography (Urban Dynamics, Social Differentiation of Urban Areas, and Social Sensing) and found that although GeoAI is a trending topic in geography and the applications of deep neural network-based methods are proliferating, the development of spatially-explicit GeoAI models is still at their early phase. We identified three challenges of existing models and advised future research direction towards developing multi-scale explainable spatially-explicit GeoAI. This review paper acquaints beginners with the basics of GeoAI and state-of-the-art and serve as an inspiration to attract more research in exploring the potential of spatially-explicit GeoAI in studying the socio-economic dimension of the city and urban life.}
}
@article{KEMPF2023103747,
title = {Point pattern and spatial analyses using archaeological and environmental data – A case study from the Neolithic Carpathian Basin},
journal = {Journal of Archaeological Science: Reports},
volume = {47},
pages = {103747},
year = {2023},
issn = {2352-409X},
doi = {https://doi.org/10.1016/j.jasrep.2022.103747},
url = {https://www.sciencedirect.com/science/article/pii/S2352409X22004102},
author = {Michael Kempf and Gerrit Günther},
keywords = {Environmental archaeology, Quantitative archaeology, Computational methods, Spatial analysis, R, Point pattern analysis (PPA)},
abstract = {Computational methods recently gained momentum in archaeological science, particularly affecting large site distribution samples and environmental explanatory parameters. However, quantitative and environmental archaeology are still considered to be limited to a small number of experts and thus less ready to use in general research. Here, we present a case study that integrates computational methods and environmental data into archaeological spatial analyses using Point Pattern Analysis (PPA). We introduce a basic approach to model, visualise, and interpret archaeological site distributions as functions of explanatory covariates in a regional setting of the Neolithic period in the Carpathian Basin. The integration of environmental and socio-cultural variables in a multicomponent analysis allows to distinguish site location parameters and preferences across different chronological periods. Using the code to this article and open-access spatial data, the workflow can be adapted to different regional contexts and chronological periods, making it particularly suitable for spatial pattern comparison.}
}
@article{GAULD2024116255,
title = {Exploring the interplay of clinical reasoning and artificial intelligence in psychiatry: Current insights and future directions},
journal = {Psychiatry Research},
volume = {342},
pages = {116255},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.116255},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124005407},
author = {Christophe Gauld and Vincent P. Martin and Hugo Bottemanne and Pierre Fourneret and Jean-Arthur Micoulaud-Franchi and Guillaume Dumas},
keywords = {Artificial intelligence, Statistical prediction, Psychiatry, Computational sciences, Explainability, Deep learning},
abstract = {For many years, it has been widely accepted in the psychiatric field that clinical practice cannot be reduced to finely tuned statistical prediction systems utilizing diverse clinical data. Clinicians are recognized for their unique and irreplaceable roles. In this brief historical overview, viewed through the lens of artificial intelligence (AI), we propose that comprehending the reasoning behind AI can enhance our understanding of clinical reasoning. Our objective is to systematically identify the factors that shape clinical reasoning in medicine, based on six factors that were historically considered beyond the reach of statistical methods: open-endedness, unanalyzed stimulus-equivalences, empty cells, theory mediation, insufficient time, and highly configured functions. Nevertheless, a pertinent consideration in the age of AI is whether these once-considered insurmountable specific factors of clinicians are now subject to scrutiny or not. Through example in AI, we demonstrate that a deeper understanding of these factors not only sheds light on clinical decision-making and its heuristic processes but also underscores the significance of collaboration between AI experts and healthcare professionals. This comparison between AI and clinical reasoning contributes to a better grasp of the current challenges AI faces in the realm of clinical medicine.}
}
@article{SAMSONOVICH2022824,
title = {Key Advanced Research Initiative: A Manifesto for the New-Generation Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {213},
pages = {824-831},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.140},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922018397},
author = {Alexei V. Samsonovich and Sergey A. Shumsky and Valery E. Karpov and Artemy A. Kotov and Anton G. Kolonin},
keywords = {AGI, humanlike AI, strong AI, virtual evolution, machine learning, evolutionary computation, artificial creativity, anthropocentric AI},
abstract = {The goal here is to identify key directions for the future advanced research initiatives in Artificial Intelligence (AI) and beyond. The following areas are identified as having particular importance: (1) socially emotional, ethical, and moral AI, (2) self-developing and self-sustainable AI, and (3) human-analogous AI, inspired by the human psychology. As a result, a general concept is formulated with the intent to clarify and unify the currently popular slogans, including Artificial General Intelligence (AGI), Strong AI, Human-Level or Humanlike AI (HLAI), Brain-Inspired or Biologically Inspired Cognitive Architectures (BICA), and more. The key idea of the proposed concept is that future AI must open a new angle of view and new perspectives to humans, thereby enriching and transforming the society, helping it to solve its problems and taking the civilization to a new level. While being created by humans, for humans, and fully compatible with humans at the social level, it will not be “a human in silicon”, but rather an “alien”: intelligent, friendly, and welcome. Its principles will combine preprogrammed basic functions and its own natural ontogeny in a virtual social environment. Forms of implementation will range from virtual entities to wearable electronics and autonomous robots. The expected impact on the society will be immense and crucial for its survival.}
}
@article{WANG20221,
title = {The past and future of mapping the biomarkers of psychosis},
journal = {Current Opinion in Behavioral Sciences},
volume = {43},
pages = {1-5},
year = {2022},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2021.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352154621001261},
author = {Ling-Ling Wang and Simon SY Lui and Raymond CK Chan},
abstract = {Biomarker research has investigated the neurobiological basis for individual differences in liability to psychosis. However, few biomarkers for psychosis have been consistently found to be useful. This paper reviews several previous approaches to identify putative biomarkers of liability to psychosis, and then highlights the lessons that we have learned. We argue that limiting our research to clinical patients at the extreme of the psychosis continuum would likely obscure our knowledge as to how a minority of the general population would develop psychosis. Research on putative neurobiological origins of inter-individual differences in personality traits may be useful in mapping the biomarkers of psychosis. To identify biomarkers applicable to the general population, we advocate the transdiagnostic and psychosis continuum approach. We also advocate the use of multivariate analyses and computational modelling to tackle complex multi-modal datasets. More research should be conducted to study intra-individual variations over different ranges of timescale.}
}
@article{BRANASGARZA2012254,
title = {Cognitive effort in the Beauty Contest Game},
journal = {Journal of Economic Behavior & Organization},
volume = {83},
number = {2},
pages = {254-260},
year = {2012},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2012.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0167268112001278},
author = {Pablo Brañas-Garza and Teresa García-Muñoz and Roberto Hernán González},
keywords = {Beauty Contest Game, Raven, Cognitive Reflection Test},
abstract = {This paper analyzes cognitive effort in 6 different oneshot p-beauty games. We use both Raven and Cognitive Reflection tests to identify subjects’ abilities. We find that the Raven test does not provide any insight on Beauty Contest Game playing but CRT does: subjects with higher scores on this test are more prone to play dominant strategies. The results are confirmed when levels of reasoning instead of entries in the BCG are used.}
}
@article{BEDOGNI2025107855,
title = {Fluid Computing & Digital Twins for intelligent interoperability in the IoT ecosystem},
journal = {Future Generation Computer Systems},
volume = {171},
pages = {107855},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107855},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25001505},
author = {Luca Bedogni and Marco Mamei and Marco Picone and Marcello Pietri and Franco Zambonelli},
keywords = {Digital twins, Intelligence, Fluid Computing, Interoperability},
abstract = {The integration of physical and digital systems is fundamental to enabling intelligent, adaptive, and scalable solutions in modern IoT environments. This paper explores Fluid Digital Twins (FDTs), a novel framework combining Fluid Computing (FC) principles with Digital Twin (DT) technology, to address challenges related to interoperability, dynamic functionality, and adaptability in IoT ecosystems. FC introduces a paradigm shift, enabling seamless data and computational task flow across heterogeneous environments, dynamically adjusting to resource availability and system needs. This paper focuses on embedding intelligence within FDTs to enhance interoperability and enable IoT applications to adapt to changes across both physical and digital domains. By integrating intelligent interoperability mechanisms, FDTs ensure smooth data alignment and compatibility across platforms, adapting to both physical and digital changes. The proposed framework has been implemented, prototyped, and evaluated in the Modena Automotive Smart Area (MASA), a smart city testbed. The evaluation demonstrates FDTs’ ability to enhance smart mobility, optimize transportation systems, and provide actionable insights, highlighting their transformative potential in dynamic, data-rich environments. The results emphasize the practical applicability of FDTs in addressing real-world challenges and advancing the capabilities of IoT-driven smart cities.}
}
@article{KNIGHT20158,
title = {Making grammars: From computing with shapes to computing with things},
journal = {Design Studies},
volume = {41},
pages = {8-28},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000605},
author = {Terry Knight and George Stiny},
keywords = {computational model(s), design theory, perception, reflective practice, shape grammar},
abstract = {Recent interest in making and materiality spans from the humanities and social sciences to engineering, science, and design. Here, we consider making through the lens of a unique computational theory of design: shape grammars. We propose a computational theory of making based on the improvisational, perception and action approach of shape grammars and the shape algebras that support them. We modify algebras for the materials (basic elements) of shapes to define algebras for the materials of objects, or things. Then we adapt shape grammars for computing shapes to making grammars for computing things. We give examples of making grammars and their algebras. We conclude by reframing designing and making in light of our computational theory of making.}
}
@incollection{TIN1994299,
title = {Baby-Sit: Towards a situation-theoretic computational environment},
editor = {Carlos Martín-Vide},
series = {North-Holland Linguistic Series: Linguistic Variations},
publisher = {Elsevier},
volume = {56},
pages = {299-308},
year = {1994},
booktitle = {Current Issues in Mathematical Linguistics},
issn = {0078-1592},
doi = {https://doi.org/10.1016/B978-0-444-81693-1.50034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444816931500348},
author = {Erkan Tin and Varol Akman},
abstract = {Publisher Summary
This chapter provides an overview of a situation-theoretic computational environment. Situation theory was first formulated in detail by Jon Barwise and John Perry in 1983. Various versions of the theory have been applied to a number of linguistic issues, resulting in what is commonly known as situation semantics. Individuals, properties, relations, spatio-temporal locations, and situations are the basic constructs of situation theory. The world is viewed as a collection of objects, sets of objects, properties, and relations. Infons are discrete items of information and situations are first-class objects that describe parts of the real world. Information flow is made possible by a network of abstract links among high-order uniformities, viz. situation types. The chapter presents a computational approach to situation theory and its associated environment (called BABY-SIT). The environment is dubbed BABY-SIT because it is believed that presently it includes far too many provisional, make-shift design decisions. The chapter highlights that compared to existing approaches, BABY-SIT enhances the basic features of situation theory.}
}
@article{HORWICH201323622,
title = {Chaperonin-mediated Protein Folding},
journal = {Journal of Biological Chemistry},
volume = {288},
number = {33},
pages = {23622-23632},
year = {2013},
issn = {0021-9258},
doi = {https://doi.org/10.1074/jbc.X113.497321},
url = {https://www.sciencedirect.com/science/article/pii/S0021925820452524},
author = {Arthur L. Horwich},
keywords = {Protein Folding, Chaperone Chaperonin, Molecular Chaperone, Yeast, Protein Misfolding, Polypeptide},
abstract = {We have been studying chaperonins these past twenty years through an initial discovery of an action in protein folding, analysis of structure, and elucidation of mechanism. Some of the highlights of these studies were presented recently upon sharing the honor of the 2013 Herbert Tabor Award with my early collaborator, Ulrich Hartl, at the annual meeting of the American Society for Biochemistry and Molecular Biology in Boston. Here, some of the major findings are recounted, particularly recognizing my collaborators, describing how I met them and how our great times together propelled our thinking and experiments.}
}
@article{FESTA2024,
title = {Incidence of circular refurbishment measures on indoor air quality and comfort conditions in two real buildings: Experimental and numerical analysis},
journal = {Energy and Built Environment},
year = {2024},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666123324000394},
author = {Valentino Festa and Silvia Ruggiero and Sara Riccardi and Margarita- Niki Assimakopoulos and Dimitra Papadaki},
keywords = {Energy building refurbishment, Experimental campaign, Indoor air quality, Thermal comfort, Computational fluid dynamics analysis},
abstract = {The application of Circular Economy to construction sector is a key to attain carbon neutrality, since it is responsible of 40 % of natural resource consumption. In this frame the importance of an efficient building refurbishment process throughout recycled material and renewable energy is fundamental. From an overview about building refurbishment emerges the need to investigate aspects related to Indoor Environmental Quality and the comparison between in-field measurements with output of dynamic simulation models. The present study aims to fill these two gaps by means an energy renovation of two real buildings in Greece. The work develops within the European project “Drive 0″, born to promote deep environmentally friendly retrofitting by means of circular renovation concepts. The methodological approach involves on-site monitoring of a series of parameters describing the energy, microclimate environmental and air quality, before and after the energy requalification. In addition, a numerical model developed in Building Energy Simulation program is calibrated and a Computational Fluid Dynamics is developed. From the in-field measurements emerges that, on one hand, the refurbishment of heating system shows a great improvement of indoor thermal conditions, with Total Volatile Organic Compounds concentration that sometimes exceed 3.0 mg/m3; on the other hand an integrated thermal insulation reduces infiltrations and changes the envelope behaviour, with a global energy saving of 30 % during winter and autumn periods. Another result of the study shows that a numerical model developed in Building Energy Simulation program and calibrated on energy consumption can greatly fit the local thermal comfort distribution of the occupant zone and predict the indoor air quality, if it outputs are used as input data in a Computational Fluid Dynamics study. These results can be beneficial to decision makers and designers for evaluating emitters positioning, opening design and mechanical ventilation strategies, aimed at reducing energy costs.}
}
@article{ZHANG2024101412,
title = {Predicting the Mathematics Literacy of Resilient Students from High‐performing Economies: A Machine Learning Approach},
journal = {Studies in Educational Evaluation},
volume = {83},
pages = {101412},
year = {2024},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2024.101412},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X24000919},
author = {Yimei Zhang and Maria Cutumisu},
keywords = {Academic resilience, Machine learning, Mathematics literacy, Cultural differences},
abstract = {Mathematics is a crucial yet challenging subject for all students. Therefore, it is important to understand the role of academic resilience in mathematics, which enables students to overcome academic challenges. This study applied two machine learning algorithms, Lasso Regression (LR) and Random Forest (RF), to predict the mathematics literacy of resilient students from high-performing economies across cultures in PISA 2022. The findings indicated both RF and LR performed better in Western cultures than in Eastern cultures. Furthermore, in Eastern cultures, mathematics self-efficacy for 21st-century skills played an important role in predicting resilient students’ mathematics literacy, followed by self-efficacy towards mathematics, and mathematics anxiety. In Western cultures, self-efficacy towards mathematics was the predominant predictor, followed by mathematics self-efficacy for 21st-century skills. Theoretically, this study identifies key factors in predicting resilient students’ mathematics literacy across cultures. Methodologically, it is the first to apply ML in exploring resilient students’ mathematics literacy. Practically, it guides educators interested in developing interventions to improve resilient students’ mathematics literacy.}
}
@article{YANG2022107728,
title = {Mixed data-driven sequential three-way decision via subjective–objective dynamic fusion},
journal = {Knowledge-Based Systems},
volume = {237},
pages = {107728},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107728},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009692},
author = {Xin Yang and Yang Chen and Hamido Fujita and Dun Liu and Tianrui Li},
keywords = {Three-way decision, Sequential three-way decision, Mixed data, subjective–objective, Dynamic fusion},
abstract = {In the context of granular computing, sequential three-way decision is a useful tool to triadic thinking, triadic computing and triadic processing from coarser to finer under multilevel and multiview granularity space. In this paper, we mainly explore a novel framework of sequential three-way decision for the fusion of mixed data from the subjective and objective dynamic perspectives. The former focuses on the decision maker’s dynamic behavior without considering the time-evolving data, and the latter emphasizes on dealing with dynamic mixed data over time by multi-stage decision-making. We firstly utilize four T-norm operators and kernel-based similarity relations to integrate different types of dynamic data. Then the subjective and objective models of sequential three-way decision are investigated based on decision thresholds, attribute importance and cost reduction. Finally, the comparative experiments are reported to verify that our proposed models can achieve the lower decision cost and the acceptable accuracy.}
}
@article{KISELEV2022e09664,
title = {Predicting verbal reasoning from virtual community membership in a sample of Russian young adults},
journal = {Heliyon},
volume = {8},
number = {6},
pages = {e09664},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09664},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022009525},
author = {Pavel Kiselev and Valeriya Matsuta and Artem Feshchenko and Irina Bogdanovskaya and Boris Kiselev},
keywords = {Verbal reasoning, Social networking site, Virtual community, Machine learning},
abstract = {Predicting personality traits from social networking site profiles can help to assess individual differences in verbal reasoning without using long questionnaires. Inspired by earlier studies, which investigated whether abstract-thinking ability are predictable by social networking sites data, we used supervised machine learning to predict verbal-reasoning ability based on a proposed set of features extracted from virtual community membership. A large sample (N = 3,646) of Russian young adults aged 18–22 years approved access to the data from their social networking accounts and completed an online test on verbal reasoning. We experimented with binary classification machine-learning models for verbal-reasoning prediction. Prediction performance was tested on isolated control subsamples for men and women. The results of prediction on AUC-ROC metrics for control subsamples over 0.7 indicated reasonably good performance on predicting verbal-reasoning level. We also investigated the contribution of virtual community's genres to verbal reasoning level prediction for male and female participants. Theoretical interpretations of results stemming from both Vygotsky's sociocultural theory and behavioural genomics are discussed, including the implication that virtual communities make up a non-shared environment that can cause variance in verbal reasoning. We intend to conduct studies to explore the implications of the results further.}
}
@article{ELIAZ2010304,
title = {Paying for confidence: An experimental study of the demand for non-instrumental information},
journal = {Games and Economic Behavior},
volume = {70},
number = {2},
pages = {304-324},
year = {2010},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2010.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
author = {Kfir Eliaz and Andrew Schotter},
abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.}
}
@article{ROSSI2011820,
title = {MAPIT: a pedagogical-relational ITS},
journal = {Procedia Computer Science},
volume = {3},
pages = {820-826},
year = {2011},
note = {World Conference on Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.12.135},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910005107},
author = {Pier Giuseppe Rossi and Simone Carletti},
keywords = {Teachers’ thinking, Intelligent tutoring system, Multi agent system, Learning management system, Tracking data, Chat-bot},
abstract = {The majority of Intelligent Tutoring System architectures are focused on supporting learners through content retrieval or in one or more given subject matters; examples of this can be found in Baghera [1], MyClass, Andes [2], Gramy, Advanced Geometry Tutor [7]. The implementation of such architectures are time-consuming and are generally not interoperable with other domains [3]. The presented research describes the experimentation of a Open Source, LMS enhanced with elements of AI aiming at supporting online teachers’ and tutors’ work by using a KB specific to relational and pedagogical aspects, not connected to a specific subject matter. Such implementation needs to be provided of an authoring tool easily and readily usable by tutors and teachers of different subjects and with medium level IT training. Starting point of our investigation has been a preliminary analysis of machine-mediated, human-human interactions (MM-HHI) and communications by using the Teachers’ thinking approach [4], [5], [6]. We considered messages exchanged between teachers/tutors and online students in three post-graduate, online courses running at the University of Macerata during 2008–2010 by the Faculty of Education. The study showed that about 30% of messages concerned structured information that could be straightforwardly retrieved by an artificial agent; almost all remaining messages were instead deeply bound to student’s learning path or required a significant input by the teacher/tutor, while the residual part of messages could — to some extents — be delegated to an intelligent agent having access to students’ tracking data in order to display visual information to users or trigger alarms to tutors. The investigation carried out prompted us for the deployment of an Open Source chat-bot system that would retrieve information already coded into the courses or originated by students through the analysis of their activity logs; the chat-bot agent uses this structured information in order to answer students’ most common questions hence relieving teachers and tutors from doing this repetitive task. The system is being implemented on a OLAT ver. 6.3 LMS loosely coupled to a JADE-based Multi Agent System in charge of processing user tracking data and running the ALICE chat-bot integrated with the platform messaging system.}
}
@article{SCHEFFLER201575,
title = {NeurOS™ and NeuroBlocks™ a neural/cognitive operating system and building blocks},
journal = {Biologically Inspired Cognitive Architectures},
volume = {11},
pages = {75-105},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2014.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X14000747},
author = {Lee Scheffler},
keywords = {Cognition, Perception, Pattern recognition, Memory, Learning, Behavior},
abstract = {NeurOS is an open platform for accelerating research, development and hosting execution of intelligent applications. A NeurOS application is a directed “neural graph” of modular components connected by signal paths, similar to biological brain connectivity and functional block diagrams of neural pathways. Built-in reusable modules (NeuroBlocks) provide a wide range of general- and special-purpose capabilities: inputs/senses, outputs/effectors, processing, memory, pattern learning and recognition, visualization/instrumentation, custom module development, integrating external intelligence capabilities, and sub-graph reuse. NeurOS sub-graph assemblies address neural/cognitive functions including perception, pattern learning and recognition, working memory, imagination, prediction, context priming, attention, abstraction, classification, associational thinking and behavior. NeurOS applications are inherently portable, scalable, networkable, extensible and embeddable. NeurOS development tools provide simple intuitive graphical drag and drop application assembly from components without programming, along with testing, debugging, monitoring and visualization. Prototype NeurOS applications have begun to explore a wide range of intelligent functions in diverse areas, including aspects of pattern recognition, vision, music, reading, puzzle solving, reasoning, behavior. Building working intelligent systems using NeurOS and NeuroBlocks lets researchers and developers focus on their core functions and rapidly iterate and instrument working models, fostering both analytical and biological insight as well as usable systems.}
}
@article{WANG2025104139,
title = {Can attention detect AI-generated text? A novel Benford's law-based approach},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104139},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104139},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000767},
author = {Zhenhua Wang and Guang Xu and Ming Ren},
keywords = {AI-generated text detection, Benford's law, Attention distribution, Adherence pattern},
abstract = {AI technologies, such as the GPT-series, have garnered worldwide attention and raised concerns regarding their potential for misuse, owing to their groundbreaking text-generating capabilities, particularly in AI-generated text (AIGT). In response to the urgent need for effective detection, this study proposes BENATTEN, a novel approach that exploits the attention between human-generated text (HGT) and AIGT. We reveal that the way humans think and the probabilistic nature of AI algorithms lead to discrepancies in how they pay attention to tokens within the text they produce, with AIGT exhibiting a higher adherence to Benford's law in attention distribution compared to HGT. Extensive experiments on three general-domain datasets demonstrate the advantage of BENATTEN compared with existing methods. For instance, on the HC3 dataset, BENATTEN achieved an impressive 99.24 % accuracy, 99.69 % F1 and 99.47 % AUC, surpassing the OpenAI detector by 3.05 %, 3.48 % and 2.39 %, respectively. Also, comprehensive evaluations on seven specialized-application domain datasets have confirmed BENATTEN's robustness and its cross-platform applicability, proving its ongoing efficacy even as AI technology evolves. Further, the experiments have shown that BENATTEN exhibits remarkable resilience, effectively handling adversarial attacks and interference from other AI systems.}
}
@article{FALOMIR201931,
title = {Special issue on problem-solving, creativity and spatial reasoning},
journal = {Cognitive Systems Research},
volume = {58},
pages = {31-34},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S138904171930261X},
author = {Zoe Falomir and Ana-Maria Olteţeanu},
keywords = {Cognitive systems, Problem-solving, Creativity, Computational creativity, Spatial reasoning, Cognition, General artificial intelligence, Spatial cognition},
abstract = {Problem-solving, creativity and spatial reasoning are high level abilities of cognitive systems with high potential for synergies. However, they have been treated separately by different fields. This special issue presents research work on these topics, aiming to observe their interrelations in order to create theoretical approaches, methodologies and computational tools to advance work on creativity and spatial problem-solving in cognitive systems.}
}
@incollection{KAMPIS1991345,
title = {Chapter Seven - SELF-REPRODUCTION AND COMPUTATION},
editor = {GEORGE KAMPIS},
booktitle = {Self-Modifying Systems in Biology and Cognitive Science},
publisher = {Pergamon},
address = {Amsterdam},
pages = {345-403},
year = {1991},
volume = {6},
series = {IFSR International Series on Systems Science and Engineering},
isbn = {978-0-08-036979-2},
doi = {https://doi.org/10.1016/B978-0-08-036979-2.50012-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080369792500124},
author = {GEORGE KAMPIS}
}
@article{CHERNYSHOV20151345,
title = {Information Support and Skill Evaluation of Human-Operators},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {3},
pages = {1345-1350},
year = {2015},
note = {15th IFAC Symposium onInformation Control Problems inManufacturing},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.06.273},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315005121},
author = {K.R. Chernyshov and E.Ph Jharko},
keywords = {Human-operator, Information support, Flexible simulation, Evaluation of skills, Random processes, Measures of dependence},
abstract = {The paper presents an approach to design an intelligent information support system to be used as a human-operator assistant to control large complex industrial plants. Tasks and structure of such an intelligent information support system (IISS), IISS design stages, methodology of IISS design, toolkits for IISS design are considered. A flexible simulation complex (FSC) as such an intelligent toolkit has been presented. The complex is used as a “kernel” of IISS for human-operators of a nuclear power plant. A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human- operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is used based on involving the notion of consistency of measures of dependence of random variables.}
}
@article{WOZNIAK2023489,
title = {BiLSTM deep neural network model for imbalanced medical data of IoT systems},
journal = {Future Generation Computer Systems},
volume = {141},
pages = {489-499},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22004095},
author = {Marcin Woźniak and Michał Wieczorek and Jakub Siłka},
keywords = {Medical informatics, Deep learning, Multi-optimization learning, BiLSTM, IoT},
abstract = {Health informatics is one of the most developed field in recent time. Computational Intelligence is among the most influential factors that may help to improve patient oriented and secure decision support model. In this article we present a model of IoT system, which combines BiLSTM deep learning with Decision Tree model and data balancing strategy used to help in automated diagnosis support. Presented solution include experimental series of data preprocessing using well established balancing algorithms with custom parameters and modifications in order to best prepare the data for the network training. Such algorithms are ADASYN, SMOTE-Tomek, etc. The system helps to evaluate questionnaires and securely exchange documents between patient and corresponding medical team. From the level of system patient and doctors are able to see automated diagnosis provided by deep learning model. The model gives an important advance to help patients faster. Results show that proposed BiLSTM deep learning with decision tree mode detects diseases from questionnaires with accuracy above 96%, precision above 88% and recall above 96% which proves efficiency of our proposed model.}
}
@article{FAYEZ2023105905,
title = {Moringa extract reverses pilocarpine-induced hippocampal sclerosis in rats with temporal lobe epilepsy},
journal = {Journal of Functional Foods},
volume = {111},
pages = {105905},
year = {2023},
issn = {1756-4646},
doi = {https://doi.org/10.1016/j.jff.2023.105905},
url = {https://www.sciencedirect.com/science/article/pii/S1756464623005054},
author = {Shaimaa Fayez and Nourhan {Hisham Shady} and Iten M. Fawzy and Sherif A. Maher and Entesar {Ali saber} and Mahmoud Elrehany and Alaa M. Alqahtani and Esam S. Allehyani and Ahmed M. Shawky and Usama {Ramadan Abdelmohsen} and Nada M. Mostafa},
keywords = {, Moringinine A, Computational studies, Epilepsy},
abstract = {The horseradish tree “Moringa oleifera” is the most nutritious terrestrial plant around the globe. Although native to India, its fast growth and drought resistance ability enabled the plant to be cultivated worldwide. In the current study, we report on the isolation of a new phenolic methyl ester namely moringinine A (1) along with four other known compounds viz. caffeic acid (2), ferulic acid (3), 4-hydroxybenzonitrile (4), and 4-hydroxyphenyl acetic acid (5) from Moringa seeds. The later compound was first to be isolated from family Moringaceae. Compounds identification was guided by interplay of NMR and HR-ESI-MS analysis. Anti-epileptic studies conducted in vivo showed that the extract attenuates convulsions by suppressing stress–induced pro-inflammatory markers TNF-α, IL-1β, IL-6, and IFN-ɣ whereas upregulating the anti-inflammatory markers TGF-β and IL-10 in the hippocampal tissues of epileptic rats. The isolated compounds were subjected to computational studies through docking on lactate dehydrogenase A(LDH) and interleukin-6 (IL-6), where all showed binding modes and interaction energies comparable to those of the reference drug diazepam. ADME investigation revealed good pharmacokinetic and drug-likeness properties. These results show that Moringa oleifera seeds could potentially be used as adjuvant in the management of epilepsy.}
}
@article{DELIMA2024107089,
title = {Integrating artificial intelligence and wing geometric morphometry to automate mosquito classification},
journal = {Acta Tropica},
volume = {249},
pages = {107089},
year = {2024},
issn = {0001-706X},
doi = {https://doi.org/10.1016/j.actatropica.2023.107089},
url = {https://www.sciencedirect.com/science/article/pii/S0001706X23002760},
author = {Vinicio Rodrigues {de Lima} and Mauro César Cafundó {de Morais} and Karin Kirchgatter},
keywords = {Mosquito-borne diseases, Species identification, Integrative approach},
abstract = {Mosquitoes (Diptera: Culicidae) comprise over 3500 global species, primarily in tropical regions, where the females act as disease vectors. Thus, identifying medically significant species is vital. In this context, Wing Geometric Morphometry (WGM) emerges as a precise and accessible method, excelling in species differentiation through mathematical approaches. Computational technologies and Artificial Intelligence (AI) promise to overcome WGM challenges, supporting mosquito identification. AI explores computers' thinking capacity, originating in the 1950s. Machine Learning (ML) arose in the 1980s as a subfield of AI, and deep Learning (DL) characterizes ML's subcategory, featuring hierarchical data processing layers. DL relies on data volume and layer adjustments. Over the past decade, AI demonstrated potential in mosquito identification. Various studies employed optical sensors, and Convolutional Neural Networks (CNNs) for mosquito identification, achieving average accuracy rates between 84 % and 93 %. Furthermore, larval Aedes identification reached accuracy rates of 92 % to 94 % using CNNs. DL models such as ResNet50 and VGG16 achieved up to 95 % accuracy in mosquito identification. Applying CNNs to georeference mosquito photos showed promising results. AI algorithms automated landmark detection in various insects' wings with repeatability rates exceeding 90 %. Companies have developed wing landmark detection algorithms, marking significant advancements in the field. In this review, we discuss how AI and WGM are being combined to identify mosquito species, offering benefits in monitoring and controlling mosquito populations.}
}
@article{FARHAT199435,
title = {Simulation of compressible viscous flows on a variety of MPPs: computational algorithms for unstructured dynamic meshes and performance results},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {119},
number = {1},
pages = {35-60},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/0045782594000751},
author = {Charbel Farhat and Stéphane Lanteri},
abstract = {We report here on our effort in simulating unsteady viscous flows on the iPSC-860, the CM-5 and the KSR-1 MPPs (Massively Parallel Processors), using a Monotonic Upwind Scheme for Conservation Laws finite volume/finite element method on fully unstructured fixed and moving grids. We advocate mesh partitioning with message passing as a portable paradigm for parallel processing. We present and discuss several performance results obtained on all three MPP systems in terms of interprocessor communication costs, I/O, scability and sheer performance.}
}
@article{BYLANDER1994165,
title = {The computational complexity of propositional STRIPS planning},
journal = {Artificial Intelligence},
volume = {69},
number = {1},
pages = {165-204},
year = {1994},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)90081-7},
url = {https://www.sciencedirect.com/science/article/pii/0004370294900817},
author = {Tom Bylander},
abstract = {I present several computational complexity results for propositional STRIPS planning, i.e., STRIPS planning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.}
}
@article{WEI2025104318,
title = {Probability evaluation of blade flutter in a transonic compressor with inlet distortion using SSA-DBEN model},
journal = {Journal of Fluids and Structures},
volume = {135},
pages = {104318},
year = {2025},
issn = {0889-9746},
doi = {https://doi.org/10.1016/j.jfluidstructs.2025.104318},
url = {https://www.sciencedirect.com/science/article/pii/S0889974625000532},
author = {Jingshan Wei and Zhidong Chi and Shimin Wang and Qun Zheng and Wei Yan and Bin Jiang},
keywords = {Axial compressor, Total pressure distortion, Deep belief network, Sparrow search algorithm, Flutter probability assessment},
abstract = {Inlet distortion significantly impacts the aeroelastic stability of aircraft engines, posing potential risks to their reliability and performance. Evaluating the probability of flutter in compressor blades is an effective approach to quantifying uncertain vibration characteristics and assessing blade aeroelastic stability. To improve modeling accuracy and computational efficiency in this analysis, a prediction method based on the sparrow search algorithm -deep extreme belief network (SSA-DEBN) model is proposed. The proposed method is evaluated through a case study involving the flutter probability assessment of a typical compressor rotor under inlet total pressure distortion. The results demonstrate that the aerodynamic modal damping ratio initially decreases and then increases as the wavelength of the inlet distortion decreases, reaching a minimum when the sinusoidal wave number of the distortion is two. Under inlet distortion conditions, the aerodynamic modal damping ratio of the compressor blade follows an approximate normal distribution, with a flutter reliability of 98.48 %. The primary factors influencing compressor blade flutter are rotational speed, inlet total temperature, vibration frequency, inlet total pressure, outlet static pressure, and distortion amplitude. The SSA-DEBN method has high accuracy and efficiency in the evaluation of compressor blade flutter failure mode by comparative analysis.}
}
@article{BORDY201329,
title = {Radiotherapy out-of-field dosimetry: Experimental and computational results for photons in a water tank},
journal = {Radiation Measurements},
volume = {57},
pages = {29-34},
year = {2013},
note = {Proceedings of the Workshop: Dosimetry for Second Cancer Risk Estimation EURADOS Annual Meeting Vienna 2012},
issn = {1350-4487},
doi = {https://doi.org/10.1016/j.radmeas.2013.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1350448713002710},
author = {J.M. Bordy and I. Bessieres and E. d'Agostino and C. Domingo and F. d'Errico and A. {di Fulvio} and Ž. Knežević and S. Miljanić and P. Olko and A. Ostrowsky and B. Poumarede and S. Sorel and L. Stolarczyk and D. Vermesse},
keywords = {Radiotherapy, Photon dosimetry, Out of field doses, Scatter radiation, Leakage},
abstract = {The first objective of this work was to check and select a set of four kinds of passive photon, dosimeters (two thermo-luminescence dosimeter (TLD) types, one radiophotoluminescence (RPL) dosimeter and one optically stimulated luminescence (OSL) dosimeter) together with a common measurement protocol. Dosimeters were calibrated in a reference clinical linear acccelerator beam in a water tank at a reference facility at the Laboratoire National Henri Becquerel (CEA LIST/LNE LNHB, Saclay. Radiation qualities of 6, 12 and 20 MV were used with standard calibration conditions described in IAEA TRS 398 and non-standard conditions. Profile and depth dose ion chamber measurements were also made to provide reference values. Measurements were made in a water tank into which pipes could be inserted which held dosimeters in pre-determined and reproducible positions. The water tank was built to enable investigation of doses up to 60 cm from the beam axis. A first set of experiments was carried out with the beam passing through the tank. From this first experiment, penumbra and out-of-field dose profiles including water and collimator scatter and leakage were found over three orders of magnitude. Two further sets of experiments using the same experimental arrangement with the beam outside the tank, to avoid water scatter, were designed to measure collimator scatter and leakage by closing the jaws of the collimator. Depending on the energy, typical leakage and collimator scatter represents 10–40% and 30–50% of the total out-of-field doses respectively. It was concluded that all dosimeters can be used for out-of-field photon dosimetry. All show good uniformity, good reproducibility, and can be used down to low doses expected at distances remote from the subsequent radiotherapy target volume.}
}
@incollection{KOCH2009125,
title = {Consciousness: Theoretical and Computational Neuroscience},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {125-130},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.00407-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469004071},
author = {C. Koch and G. Tononi},
abstract = {Consciousness is a puzzling, state-dependent property of certain types of complex, adaptive, and highly interconnected systems. The best example is a healthy and attentive human brain. If the brain is anesthetized, consciousness ceases. Small lesions in the midbrain and thalamus of patients can lead to a complete loss of consciousness, while destruction of circumscribed parts of the cerebral cortex of patients can eliminate very specific aspects of consciousness, such as the ability to be aware of motion or to recognize objects (e.g., faces), without a concomitant loss of consciousness in general. Given the similarity in brain structure and behavior, biologists commonly assume that at least some animals, in particular nonhuman primates, share certain aspects of consciousness with humans. Brain scientists are exploiting a number of empirical approaches that shed light on the neural basis of consciousness. At present, it is not known to what extent artificial systems, such as computers, robots, or the World Wide Web as a whole, are or can become ‘conscious.’ What is needed is a theory of consciousness that explains in quantitative terms what types of systems, with what architecture, can possess conscious states.}
}
@article{BROWN19921,
title = {Some conceptual issues in the modeling and computational analysis of the Canada-U.S. Free Trade Agreement},
journal = {The North American Journal of Economics and Finance},
volume = {3},
number = {1},
pages = {1-20},
year = {1992},
issn = {1062-9408},
doi = {https://doi.org/10.1016/1062-9408(92)90009-G},
url = {https://www.sciencedirect.com/science/article/pii/106294089290009G},
author = {Drusilla K. Brown and Robert M. Stern},
abstract = {We present an interpretive history of the development of the computational analysis of the Canada-U.S. FTA. Several important conceptual issues are identified, including: perfect competition and national product differentiation; imperfect competition and increasing returns to scale; tariff liberalization and monopolistic competition; adjustment and dynamic effects; macroeconomic effects; and other pertinent aspects of market structure and firm behavior.}
}
@article{PEZZULO2013270,
title = {Action simulation in the human brain: Twelve questions},
journal = {New Ideas in Psychology},
volume = {31},
number = {3},
pages = {270-290},
year = {2013},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2013.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X13000263},
author = {Giovanni Pezzulo and Matteo Candidi and Haris Dindo and Laura Barca},
keywords = {Action simulation, Internal model, Forward model, Motor control, Action understanding},
abstract = {Although the idea of action simulation is nowadays popular in cognitive science, neuroscience and robotics, many aspects of the simulative processes remain unclear from empirical, computational, and neural perspectives. In the first part of the article, we provide a critical review and assessment of action simulation theories advanced so far in the wider literature of embodied and motor cognition. We focus our analysis on twelve key questions, and discuss them in the context of human and (occasionally) primate studies. In the second part of the article, we describe an integrative neuro-computational account of action simulation, which links the neural substrate (as revealed in neuroimaging studies of action simulation) to the components of a computational architecture that includes internal modeling, action monitoring and inhibition mechanisms.}
}
@article{JOHNSON1989319,
title = {Exploiting parallelism in computational science},
journal = {Future Generation Computer Systems},
volume = {5},
number = {2},
pages = {319-337},
year = {1989},
note = {Grand Challenges to Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/0167-739X(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0167739X89900502},
author = {Gary M. Johnson},
abstract = {The full exploitation of numerical simulation as an independent approach to the solution of engineering and scientific problems requires computing capability far exceeding that which is presently available. In this paper, the computing requirements posed by challenging problems in several disciplines are examined and contrasted with contemporary supercomputer resources. Of the means available to help fill the gap between the demands of computational science and the performance level of present-generation supercomputer systems, parallel processing appears to have the greatest potential for near-term success. Parallel computer architectures are reviewed and categorized according to processing units, memory, and interconnection scheme. Philosophies of parallel processing are discussed. They are distinguished by the number and size of the parallel tasks which they employ. Scientific problems are examined for parallelism inherent at the physical level. Typical algorithms and their mappings onto parallel architectures are discussed. Computational examples are presented to document the performance of scientific applications on present-generation parallel processors. Projections are made concerning software developments and machine architectures.}
}
@article{ARORA1990131,
title = {Computational design optimization: A review and future directions},
journal = {Structural Safety},
volume = {7},
number = {2},
pages = {131-148},
year = {1990},
issn = {0167-4730},
doi = {https://doi.org/10.1016/0167-4730(90)90063-U},
url = {https://www.sciencedirect.com/science/article/pii/016747309090063U},
author = {Jasbir S. Arora},
keywords = {optimization methods, nonlinear problems, review, computational aspects, engineering design},
abstract = {A mathematical model for design optimization of engineering systems is defined. Computational algorithms to treat the model are reviewed and their features are discussed. The attributes of a good algorithm are given. Sequential quadratic programming algorithms that generate and use the approximate Hessian of the Lagrange function to calculate the search direction are the most recent methods. They are the most reliable methods among the available ones. Several other computational aspects, such as robust implementation of algorithms, use of a knowledge base, interactive use of optimization, and use of a database and database management system, are discussed. Recent developments in the field and future directions are presented.}
}
@article{GARG2024101391,
title = {Molecular Mechanics Demonstrate S-COMT as promising therapeutic receptor when analyzed with secondary plant metabolites},
journal = {Journal of the Indian Chemical Society},
volume = {101},
number = {11},
pages = {101391},
year = {2024},
issn = {0019-4522},
doi = {https://doi.org/10.1016/j.jics.2024.101391},
url = {https://www.sciencedirect.com/science/article/pii/S0019452224002711},
author = {Deepanshu Garg and Aarya Vashishth and Maharsh Jayadeep Jayawant and Virupaksha A. Bastikar},
keywords = {S-COMT receptor, Depression, Plant secondary metabolites, Molecular docking, Molecular dynamic simulation},
abstract = {Major depressive disorder (MDD) and other psychiatric conditions are debilitating illnesses affecting millions globally. Catechol-O-methyltransferase (COMT), an enzyme that regulates dopamine and norepinephrine breakdown in the brain, has emerged as a potential therapeutic target for these disorders. This study explores the inhibitory potential of plant secondary metabolites against S-COMT using computational techniques. COMT exists in two isoforms: membrane-bound COMT (MB-COMT), primarily found in brain neurons, and soluble COMT (S-COMT), present in peripheral tissues. S-COMT, particularly in the prefrontal cortex, is crucial for regulating neurotransmitters and maintaining cognitive function. Studies suggest S-COMT variants might be linked to the development of depression, schizophrenia, and other psychiatric disorders. Current COMT inhibitors often suffer from limitations, necessitating the exploration of novel therapeutic strategies. This study employed in-silico methods to investigate plant secondary metabolites as potential S-COMT inhibitors. Here, we describe the S-COMT protein structure retrieval and validation, followed by molecular docking simulations to identify plant compounds with the strongest binding affinity to the receptor's active site. Key amino acid residues involved in these interactions were also analyzed. Furthermore, molecular dynamics simulations were conducted to assess the stability of the top-scoring protein-ligand complexes over a 100-ns timeframe. The results explored the stability of ligand binding within the active site and its impact on the overall conformation of the S-COMT receptor. Our findings highlight promising therapeutic potential for these plant-derived compounds. Further in vitro and in vivo studies are warranted to validate their efficacy and safety for potential clinical applications in treating S-COMT-related disorders.
Subjects
Bioinformatics and Computational Biology, Proteomics, Neurogenerative Diseases.}
}
@article{MU2025109748,
title = {Adaptive model-agnostic meta-learning network for cross-machine fault diagnosis with limited samples},
journal = {Engineering Applications of Artificial Intelligence},
volume = {141},
pages = {109748},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109748},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624019079},
author = {Mingzhe Mu and Hongkai Jiang and Xin Wang and Yutong Dong},
keywords = {Fault diagnosis, Rotating machine, Adaptive model-agnostic meta-learning network, Cross-machine, Limited samples},
abstract = {Deep learning-based methods have been extensively studied in rotating machinery defect diagnosis. However, training an accurate and robust diagnostic model is still a challenge under severe domain bias and limited samples. For this reason, a new adaptive model-agnostic meta-learning (AMAML) is proposed for cross-machine fault diagnosis with limited samples. First, a novel adaptive feature encode network is built, incorporating lightweight spatial-bilateral channel attention. This enables the network to extract critical fault information in multiple dimensions adaptively within limited samples, which improves the learning efficiency of generalized diagnostic knowledge. Then, an adaptive loss computation (ALC) method is devised, which inventively realizes the interaction between loss computation and model performance. The underfitting and overfitting dilemmas under few-shot conditions are tackled by ALC. Finally, an adaptive meta-optimization strategy is proposed for dynamically adapting the update strategy of the base learner, so that the model is always optimized in the direction of strong generalizability while obtaining high performance. Six cross-machine diagnosis tasks are conducted to verify the effectiveness of AMAML. The average diagnostic accuracy of the AMAML under the 5-shot setting reached 97.42%. Experiments confirm that AMAML is superior to other prevailing methods and is potentially promising for engineering applications.}
}
@incollection{MILLER2020181,
title = {Chapter eight - Data science and the exposome},
editor = {Gary W. Miller},
booktitle = {The Exposome (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {181-209},
year = {2020},
isbn = {978-0-12-814079-6},
doi = {https://doi.org/10.1016/B978-0-12-814079-6.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128140796000080},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, models, computational biology, machine learning, Bayesian methods, artificial intelligence, causal inference},
abstract = {Data science is focused on extracting meaningful value from complex datasets. Exposome-related data are certainly complex with information coming from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. It is unlikely that unsupervised approaches will allow for causal associations to be made, but with proper study design and appropriate statistical and computational models, it should be possible to derive meaningful connections between complex exposures and specific health outcomes. The complex types of data will undoubtedly require sophistical mathematical approaches, including bioinformatics, computational, machine learning, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive datasets that will result from exposome research.}
}
@article{PITTAPANTAZI2007301,
title = {Secondary school students’ levels of understanding in computing exponents},
journal = {The Journal of Mathematical Behavior},
volume = {26},
number = {4},
pages = {301-311},
year = {2007},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000508},
author = {Demetra Pitta-Pantazi and Constantinos Christou and Theodossios Zachariades},
keywords = {Exponents, Prototype, Conceptual change},
abstract = {The aim of this study is to describe and analyze students’ levels of understanding of exponents within the context of procedural and conceptual learning via the conceptual change and prototypes’ theory. The study was conducted with 202 secondary school students with the use of a questionnaire and semi-structured interviews. The results suggest that three levels of understanding can be identified. At the first level students’ interpretation of exponents is based upon exponents that symbolize natural numbers. At Level 2, students’ knowledge acquisition process is a process of enrichment of the existing conceptual structures. Students at this level are able to compute exponents with negative numbers by extending the application of prototype examples. Finally, at Level 3 students not only extend the prototype examples but also reorganize their thinking in order to compute and compare exponents with roots, a concept which is quite different from the concept of exponents with natural numbers.}
}
@article{LIEVENS2021128,
title = {A service design perspective on the stakeholder engagement journey during B2B innovation: Challenges and future research agenda},
journal = {Industrial Marketing Management},
volume = {95},
pages = {128-141},
year = {2021},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0019850121000791},
author = {Annouk Lievens and Vera Blažević},
keywords = {Stakeholder engagement, B2B innovation process, Stakeholder engagement journey, Innovation networks, Service design},
abstract = {Innovation in business-to-business (B2B) contexts deals with highly dynamic, complex, and heterogeneous constellations of stakeholders with a diversity of goals, motives, and capabilities that further challenge successful management of B2B innovation processes and outcomes. Complex challenges, such as sustainability and digitization trends, push these B2B firms to embrace new innovation methods that help them manage disruptive change. Service design thinking has emerged as an innovation management practice emphasizing a human-centered innovation process of user interactions, creativity, and learning mindsets. In this article, we aim to evaluate the challenges and develop a research agenda on how service design can effectively enable stakeholders' engagement during the B2B innovation process. We argue that to advance service design opportunities for stakeholder engagement, we need to address the unique complexities and challenges of stakeholder engagement during innovation from a systemic and dynamic process perspective. From a systemic perspective, we zoom in on the building blocks of stakeholder engagement and address multi-level stakeholder engagement platforms (i.e., innovation networks). From a dynamic process perspective, we treat stakeholder engagement as an emerging process and zoom in on the temporal and relational connections and hybrid orchestration to allow for both structural and emerging stakeholder engagement during innovation. We develop a stakeholder engagement journey in which we integrate service and innovation stages and propose how service design activities can support and facilitate the aforementioned challenges and complexities. Finally, we identify concrete research questions and, accordingly, develop a research agenda for future research on stakeholder engagement in B2B innovation trajectories.}
}
@article{CRILLY2021333,
title = {The Evolution of “Co-evolution” (Part II): The Biological Analogy, Different Kinds of Co-evolution, and Proposals for Conceptual Expansion},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {333-355},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000927},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Biological analogy, Interdisciplinarity},
abstract = {Descriptions of problem-solution “co-evolution” either explicitly or implicitly draw an analogy between processes of design and processes of biological evolution. Analogies of this kind are common in research because of their potential to assist in explanation and discovery. However, reviewing the design literature reveals that the discussion of design co-evolution has become disconnected from the biological analogy on which it is founded, and from which other disciplines draw. Here, I explore the function of the co-evolution analogy, provide an illustrative example from biology, and explore the varieties of co-evolution to which design might be compared. By doing so, I propose two possible directions for expanding the design co-evolution concept: (i) examining what co-evolves in addition to, or instead of, problems and solutions, and (ii) examining the different levels at which co-evolution occurs. Both of these proposals are illustrated with a variant of the design co-evolution diagram.}
}
@article{HOIFODT2015,
title = {Predictors of Response to Web-Based Cognitive Behavioral Therapy With High-Intensity Face-to-Face Therapist Guidance for Depression: A Bayesian Analysis},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {9},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4351},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115002137},
author = {Ragnhild Sørensen Høifødt and Matthias Mittner and Kjersti Lillevoll and Susanne Kvam Katla and Nils Kolstrup and Martin Eisemann and Oddgeir Friborg and Knut Waterloo},
keywords = {treatment outcome, computer-assisted therapy, cognitive behavior therapy, depression, primary health care, Bayesian analysis},
abstract = {Background
Several studies have demonstrated the effect of guided Internet-based cognitive behavioral therapy (ICBT) for depression. However, ICBT is not suitable for all depressed patients and there is a considerable level of nonresponse. Research on predictors and moderators of outcome in ICBT is inconclusive.
Objective
This paper explored predictors of response to an intervention combining the Web-based program MoodGYM and face-to-face therapist guidance in a sample of primary care patients with mild to moderate depressive symptoms.
Methods
Participants (N=106) aged between 18 and 65 years were recruited from primary care and randomly allocated to a treatment condition or to a delayed treatment condition. The intervention included the Norwegian version of the MoodGYM program, face-to-face guidance from a psychologist, and reminder emails. In this paper, data from the treatment phase of the 2 groups was merged to increase the sample size (n=82). Outcome was improvement in depressive symptoms during treatment as assessed with the Beck Depression Inventory-II (BDI-II). Predictors included demographic variables, severity variables (eg, number of depressive episodes and pretreatment depression and anxiety severity), cognitive variables (eg, dysfunctional thinking), module completion, and treatment expectancy and motivation. Using Bayesian analysis, predictors of response were explored with a latent-class approach and by analyzing whether predictors affected the slope of response.
Results
A 2-class model distinguished well between responders (74%, 61/82) and nonresponders (26%, 21/82). Our results indicate that having had more depressive episodes, being married or cohabiting, and scoring higher on a measure of life satisfaction had high odds for positively affecting the probability of response. Higher levels of dysfunctional thinking had high odds for a negative effect on the probability of responding. Prediction of the slope of response yielded largely similar results. Bayes factors indicated substantial evidence that being married or cohabiting predicted a more positive treatment response. The effects of life satisfaction and number of depressive episodes were more uncertain. There was substantial evidence that several variables were unrelated to treatment response, including gender, age, and pretreatment symptoms of depression and anxiety.
Conclusions
Treatment response to ICBT with face-to-face guidance may be comparable across varying levels of depressive severity and irrespective of the presence and severity of comorbid anxiety. Being married or cohabiting, reporting higher life satisfaction, and having had more depressive episodes may predict a more favorable response, whereas higher levels of dysfunctional thinking may be a predictor of poorer response. More studies exploring predictors and moderators of Internet-based treatments are needed to inform for whom this treatment is most effective.
Trial Registration
Australian New Zealand Clinical Trials Registry number: ACTRN12610000257066; https://www.anzctr.org.au/trial_view.aspx?id=335255 (Archived by WebCite at http://www.webcitation.org/6GR48iZH4).}
}
@article{PAILLARD2025101182,
title = {GREEN: A lightweight architecture using learnable wavelets and Riemannian geometry for biomarker exploration with EEG signals},
journal = {Patterns},
volume = {6},
number = {3},
pages = {101182},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101182},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000303},
author = {Joseph Paillard and Jörg F. Hipp and Denis A. Engemann},
keywords = {electroencephalography, EEG, biomarkers, deep learning, wavelets, Riemannian geometry, brain-computer interface, BCI},
abstract = {Summary
Spectral analysis using wavelets is widely used for identifying biomarkers in EEG signals. Recently, Riemannian geometry has provided an effective mathematical framework for predicting biomedical outcomes from multichannel electroencephalography (EEG) recordings while showing concord with neuroscientific domain knowledge. However, these methods rely on handcrafted rules and sequential optimization. In contrast, deep learning (DL) offers end-to-end trainable models achieving state-of-the-art performance on various prediction tasks but lacks interpretability and interoperability with established neuroscience concepts. We introduce Gabor Riemann EEGNet (GREEN), a lightweight neural network that integrates wavelet transforms and Riemannian geometry for processing raw EEG data. Benchmarking on six prediction tasks across four datasets with over 5,000 participants, GREEN outperformed non-deep state-of-the-art models and performed favorably against large DL models while using orders-of-magnitude fewer parameters. Computational experiments showed that GREEN facilitates learning sparse representations without compromising performance. By integrating domain knowledge, GREEN combines a desirable complexity-performance trade-off with interpretable representations.}
}
@article{RANGANATHAN201958,
title = {Emotion Mining in Social Media Data},
journal = {Procedia Computer Science},
volume = {159},
pages = {58-66},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.160},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919313389},
author = {Jaishree Ranganathan and Angelina Tzacheva},
keywords = {Data Mining, Emotion, Microblog, Sentiment Analysis, Twitter},
abstract = {Emotions are known to influence the perception of human beings along with their memory, thinking and imagination. Human perception is important in today’s world in a wide range of factors including but not limited to business, education, art, and music. Microblogging and Social networking sites like Twitter, Facebook are challenging sources of information that allow people to share their feelings and thoughts on a daily basis. In this paper we propose an approach to automatically detect emotions on Twitter messages that explores characteristics of the tweets and the writer’s emotion using Support Vector Machine LibLinear model and achieve 98% accuracy. Emotion mining gained attraction in the field of computer science due to the vast variety of systems that can be developed and promising applications like remote health care system, customer care services, smart phones that react based on users’s emotion, vehicles that sense emotion of the driver. These emotions help understand the current state of user. In order to perform suitable actions or provide suggestions on how user’s can enhance their feeling for a better healthy life-style we use actionable recommendations. In this work we extract action rules with respect to the user emotions that help provide suggestions for user’s.}
}
@article{DIGIACOMO2025115393,
title = {Perspectives on the role of “-Omics” in predicting response to immunotherapy},
journal = {European Journal of Cancer},
volume = {220},
pages = {115393},
year = {2025},
issn = {0959-8049},
doi = {https://doi.org/10.1016/j.ejca.2025.115393},
url = {https://www.sciencedirect.com/science/article/pii/S0959804925001741},
author = {Anna Maria {Di Giacomo} and Sumit Subudhi and Wim Vos and Massimo Andreatta and Santiago Carmona and Will McTavish and Barbara Seliger and Ramy Ibrahim and Michael Lahn and Michael Smith and Alexander Eggermont and Bernard A. Fox and Michele Maio},
keywords = {Immunotherapy, Systems biology, “omics”-based biology, Epigenetics, Tumor microenvironment, Dark matter},
abstract = {The annual Immuno-Oncology “Think Tank” held in October 2023 in Siena reviewed the rapidly evolving systems-biological approaches which are now providing a deeper understanding of tumor and tumor microenvironment heterogeneity. Based on this understanding opportunities for novel therapies may be identified to overcome resistance to immunotherapy. There is increasing evidence that malignant disease processes are not limited to purely intracellular or genetic events but constitute a dynamic interaction between the host and disease. Tumor responses are influenced by many host tissue determinants across different cellular compartments, which can now be investigated by high-throughput molecular profiling technologies, often labelled with a suffix “-omics”. “Omics” together with ever increasing computational power, fast developments in machine learning, and high-resolution detection tools offer an unrivalled opportunity to connect high-dimensional data and create a holistic view of disease processes in cancer. This review describes advances in several state-of-the-art “-omics” approaches with perspectives on how these can be applied to the clinical development of new immunotherapeutic strategies and ultimately adopted in clinical practice.}
}
@article{XIAO1996292,
title = {On the effects of ampoule tilting during vertical Bridgman growth: three-dimensional computations via a massively parallel, finite element method},
journal = {Journal of Crystal Growth},
volume = {167},
number = {1},
pages = {292-304},
year = {1996},
issn = {0022-0248},
doi = {https://doi.org/10.1016/0022-0248(96)00231-X},
url = {https://www.sciencedirect.com/science/article/pii/002202489600231X},
author = {Qiang Xiao and Satheesh Kuppurao and Andrew Yeckel and Jeffrey J. Derby},
abstract = {Three-dimensional convection and asymmetric radial segregation, caused by ampoule tilting during the vertical Bridgman growth, are analyzed using a novel, massively parallel, finite element model. The growth of cadmium telluride with a dilute dopant is considered and found to be surprisingly sensitive to the amount of tilt - as little as one degree of misalignment of the ampoule axis from the gravitational vector produces a significant three-dimensional flow and a concomitant skewing of the dopant distribution along the surface of the growing solid. This indicates the need for precise ampoule axis alignment to ensure process reproducibility. Analysis of the dopant distribution along the solid-liquid interface of the tilted system reveals a surface region more uniform in dopant concentration than any corresponding region of the interface of the perfectly aligned system. For systems in which low radial segregation is very important, growth with an intentional axis offset may be beneficial.}
}
@article{CORPONI2021,
title = {Frontal lobes dysfunction across clinical clusters of acute schizophrenia},
journal = {Revista de Psiquiatría y Salud Mental},
year = {2021},
issn = {1888-9891},
doi = {https://doi.org/10.1016/j.rpsm.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1888989121001324},
author = {Filippo Corponi and Yana Zorkina and Daniel Stahl and Andrea Murru and Eduard Vieta and Alessandro Serretti and Аnna Morozova and Alexander Reznik and Georgiy Kostyuk and Vladimir Pavlovich Chekhonin},
keywords = {Schizophrenia, Frontal lobe, Precision medicine, Cluster analysis, Machine learning},
abstract = {Introduction
Schizophrenia is a clinical construct comprising manifold phenotypes underlying heterogeneous biological underpinnings. The Positive and Negative Syndrome Scale (PANSS) represents the standard tool in the clinical characterization of patients affected by schizophrenia, allowing to detect different clinical profiles within the disorder. Frontal lobes are a key area of brain dysfunction in schizophrenia. We investigated whether different clinical profiles in acute schizophrenia show differences in frontal lobes dysfunction or not.
Methods
We defined PANSS-derived principal components in a sample of 516 acute patients. These components were used as clustering variables in a finite-mixture model. Frontal lobe impairment, measured with the frontal assessment battery (FAB) score, was adjusted for disease duration and compared across the clinical clusters with ANCOVA. A supervised-learning approach was then implemented to reveal most informative PANSS items.
Results
A three-cluster solution emerged: a first profile with high-moderate expression for the positive and excitability/hostility component; a second profile scoring high on depression/anxiety and low on other components; a third profile, comprising the majority of the study population (74%), with a heavy affection on the negative-disorganization dimensions. After controlling for disease duration, frontal lobe impairment significantly differed across the aforementioned clusters, with the third cluster being the most affected. Two PANSS items presented the highest predictive value for FAB total score.
Conclusions
Among negative and disorganization symptoms, “difficulty in abstract thinking” and “lack of spontaneity/flow in conversation” are specifically mapped to higher levels of frontal lobes dysfunction, hinting at similar features with other neurological disorders involving frontal lobes.}
}
@article{MAHMUD20233933,
title = {Detection of Different Stages of Alzheimer’s Disease Using CNN Classifier},
journal = {Computers, Materials and Continua},
volume = {76},
number = {3},
pages = {3933-3948},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.039020},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823000450},
author = {S M Hasan Mahmud and Md Mamun Ali and Mohammad Fahim Shahriar and Fahad Ahmed Al-Zahrani and Kawsar Ahmed and Dip Nandi and Francis M. Bui},
keywords = {Alzheimer’s disease, early detection, convolutional neural network, data augmentation, random oversampling, machine learning},
abstract = {Alzheimer’s disease (AD) is a neurodevelopmental impairment that results in a person’s behavior, thinking, and memory loss. The most common symptoms of AD are losing memory and early aging. In addition to these, there are several serious impacts of AD. However, the impact of AD can be mitigated by early-stage detection though it cannot be cured permanently. Early-stage detection is the most challenging task for controlling and mitigating the impact of AD. The study proposes a predictive model to detect AD in the initial phase based on machine learning and a deep learning approach to address the issue. To build a predictive model, open-source data was collected where five stages of images of AD were available as Cognitive Normal (CN), Early Mild Cognitive Impairment (EMCI), Mild Cognitive Impairment (MCI), Late Mild Cognitive Impairment (LMCI), and AD. Every stage of AD is considered as a class, and then the dataset was divided into three parts binary class, three class, and five class. In this research, we applied different preprocessing steps with augmentation techniques to efficiently identify AD. It integrates a random oversampling technique to handle the imbalance problem from target classes, mitigating the model overfitting and biases. Then three machine learning classifiers, such as random forest (RF), K-Nearest neighbor (KNN), and support vector machine (SVM), and two deep learning methods, such as convolutional neuronal network (CNN) and artificial neural network (ANN) were applied on these datasets. After analyzing the performance of the used models and the datasets, it is found that CNN with binary class outperformed 88.20% accuracy. The result of the study indicates that the model is highly potential to detect AD in the initial phase.}
}
@incollection{KRISHNAN2025,
title = {Oro-pharyngeal mucosal microbiome alternations causing immune system dysregulation in schizophrenia},
series = {International Review of Neurobiology},
publisher = {Academic Press},
year = {2025},
issn = {0074-7742},
doi = {https://doi.org/10.1016/bs.irn.2025.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S007477422500008X},
author = {Deena Krishnan and Puja Ghosh and Nathish Lakshman and Antony Justin and Sivasamy Ramasamy},
keywords = {Oropharyngeal microbiome, Schizophrenia, Immune dysregulation, Oral microbiome},
abstract = {Schizophrenia is a chronic and thoughtful psychological disorder that affects a person’s thinking, feelings, and behaviours. Multi-factorial genetic, environmental, and neurological variables cause it. Recently, more research focused on the human microbiome, which alters the immune system and develops adverse health effects on the human body. The study discusses a possible relationship between the oropharyngeal microbiome and schizophrenia. According to recent studies, the oropharyngeal microbiome may alter the immune system in the human body and cause various psychiatric disorders, including schizophrenia. The oropharyngeal microbiome can cause schizophrenia either by affecting the genes, chromosomes, and immune system in the human body. Additionally, it examines the combined mechanism of how the oropharyngeal microbiome’s alterations lead to genetic abnormalities and immune dysregulation in schizophrenia. By combining the various approaches, this chapter offers a comprehensive view of the oropharyngeal microbiome’s role in schizophrenia and suggests that microbial alterations could serve as biomarkers or therapeutic targets for the disorder.}
}
@article{KISAALITA201658,
title = {Perspectives on context, design teams and diffusion of technological innovations in low-resource settings: A practical approach based on sub-Saharan African projects},
journal = {Technology in Society},
volume = {46},
pages = {58-62},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300495},
author = {William S. Kisaalita},
keywords = {Technological innovations, Sustainable development, Developing countries, Design teams, Poverty alleviation, Food and energy security},
abstract = {A human-centered design approach for creating science/engineering-driven solutions or innovations, referred to as “connect-the-dots,” is presented. Dots symbolize the best questions and the connections reveal the best order in which these questions should be answered. In this approach, the number of customer or user behavioral changes are critically analyzed, revealing the overall context in which the solution or innovation will operate; especially to undergraduate students creating solutions to problems from settings that are less familiar, from cultural, economic, and geopolitical viewpoints. Solutions or innovations that result in minimal user behavior changes are preferred. Additional benefits include better incorporation of systems theory thinking, ease with which team multidisciplinarity and diversity can be identified, and seamlessly integrating design and research.}
}
@article{CAI2024118870,
title = {An efficient Meta-VSW method for ship behaviors recognition and application},
journal = {Ocean Engineering},
volume = {311},
pages = {118870},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.118870},
url = {https://www.sciencedirect.com/science/article/pii/S002980182402208X},
author = {Zhiyuan Cai and Qidong Fan and Lecheng Li and Long Yu and Congbo Li},
keywords = {Ship behavior recognition, Unsupervised algorithm, Massive unknown data, Meta-trajectory, Operational efficiency, Fuel consumption},
abstract = {Ship behaviors refer to the operational process such as sailing, entering into port/departure, etc., which indicate by their position, speed, and so on. The collected big data normally have been treated by unsupervised Machine Learning methods. However, the process is time consuming and lacks consideration of time continuity. From the unknown data to recognize and recur the ship behaviors is still a complex problem. Hence, this study proposes a universal Meta-trajectory Variable Sliding Window (Meta-VSW) method to provide an efficient and high-fidelity solution. In this method, the ship data were connected into the smallest units by the meta-trajectory coding, and combines with variable sliding windows to achieve fast, continuous and accurate recognition of ship behaviors. Taking an inland-water ship and a marine transport ship as examples, the validity of the method was fulfilled and compared with two commonly used algorithms, Affinity Propagation (AP) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). It has the fastest computational speed and can effectively classify the behaviors of massive unknown data from different ships. And it has good performance in capturing behavior boundaries, with the recognition accuracy up to 0.9. Then, the method was applied to analyze the operational effectively and fuel consumption.}
}
@article{GAN2021101212,
title = {Translating novel HPC techniques into efficient geoscience solutions},
journal = {Journal of Computational Science},
volume = {52},
pages = {101212},
year = {2021},
note = {Case Studies in Translational Computer Science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101212},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320305135},
author = {Lin Gan and Haohuan Fu and Guangwen Yang},
keywords = {Computational geoscience application, Numerical simulation, High performance computing, Translational computer science},
abstract = {Computational geoscience is an established field for better understanding and protecting our planet. It covers a wide range of different fields that are closely related to Earth systems. As a popular research area that largely relies on high performance computing, the efficient translation of novel techniques from computer science to practical geoscience solutions has emerged as an important and challenging problem. Based on a series of efforts in conducting interdisciplinary research in computer science and geoscience, this paper summarizes the measures we have taken and the lessons we have learned to successfully translate selected computational laboratory innovations into practical solutions.}
}
@article{TEIXEIRADUARTE2022112513,
title = {Review on layout optimization strategies of offshore parks for wave energy converters},
journal = {Renewable and Sustainable Energy Reviews},
volume = {163},
pages = {112513},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112513},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122004178},
author = {Felipe Teixeira-Duarte and Daniel Clemente and Gianmaria Giannini and Paulo Rosa-Santos and Francisco Taveira-Pinto},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Layout optimization, Offshore parks, Energy parks, WEC arrays},
abstract = {Layout optimization of wave energy offshore parks is a challenging task, as it encompasses various design objectives and constraints attributed to the complex hydrodynamic interactions. The wave energy converter (WEC) park performance is affected by local environment and device characteristics. To solve this challenge, advanced numerical algorithms, including artificial intelligence, have been applied to a wide range of case studies. Nevertheless, this process remains incomplete, which keeps it as a pertinent research topic in the field of WEC development. The present paper provides an overview of the current state and research trends of offshore WEC park layout optimization. To analyze the state-of-the-art, the paper targets the last decades’ research on this topic, summarizing the studies, addressing the optimization objective and the employed methods and separating them according to the corresponding technique. The review showed that the results strongly depend on the methodologies applied. Furthermore, a preferential use of computational intelligence techniques has been observed in recent years.}
}
@article{OMRAN2022114806,
title = {Valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment: Approaching green chemistry and circular economy principles},
journal = {Journal of Environmental Management},
volume = {311},
pages = {114806},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.114806},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722003796},
author = {Basma A. Omran and Kwang-Hyun Baek},
keywords = {Green synthesis, Zero-cost, Nanomaterials, Wastewater treatment, Sustainability},
abstract = {Water pollution is one of the most critical issues worldwide and is a priority in all scientific agendas. Green nanotechnology presents a plethora of promising avenues for wastewater treatment. This review discusses the current trends in the valorization of zero-cost, biodegradable, and readily available agro-industrial biowaste to produce green bio-nanocatalysts and bio-nanosorbents for wastewater treatment. The promising roles of green bio-nanocatalysts and bio-nanosorbents in removing organic and inorganic water contaminants are discussed. The potent antimicrobial activity of bio-derived nanodisinfectants against water-borne pathogenic microbes is reviewed. The bioactive molecules involved in the chelation and tailoring of green synthesized nanomaterials are highlighted along with the mechanisms involved. Furthermore, this review emphasizes how the valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment adheres to the fundamental principles of green chemistry, circular economy, nexus thinking, and zero-waste manufacturing. The potential economic, environmental, and health impacts of valorizing agro-industrial biowaste to green nanomaterials are highlighted. The challenges and future outlooks for the management of agro-industrial biowaste and safe application of green nanomaterials for wastewater treatment are summarized.}
}
@article{KAKOOEE20241466,
title = {Impact of Pavlovian Approach Bias on Bidirectional Planning in Spatial Navigation Tasks},
journal = {Procedia Computer Science},
volume = {246},
pages = {1466-1478},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.593},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026449},
author = {Reza Kakooee and Mohammad TH Beheshti and Mehdi Keramati},
keywords = {Reinforcement Learning, Computational Modeling, Bidirectional Planning, Decision-Making, Pavlovian Bias},
abstract = {Bidirectional planning refers to a form of goal-directed decision-making process that combines forward and backward planning. Forward planning expands decision trees from the current state towards simulated futures, while backward planning starts the tree expansion from specific goal points in the opposite direction. Previous research has highlighted the impact of Pavlovian approach bias on behavior, showing that animals move towards appetitive outcomes regardless of the appropriateness of such behavior for achieving those outcomes. However, it remains unexplored whether the Pavlovian approach influences behavior by biasing backward planning. This research introduces a spatial navigation task to investigate the involvement of backward planning in humans’ action-selection process and to determine whether the Pavlovian approach biases behavior through backward planning. The results reveal the behavioral signature of backward planning in humans and show that Pavlovian approach bias can influence both forward and backward planning, leading to decisions that are not necessarily instrumentally more efficient. Additionally, we developed a bidirectional planning algorithm based on reinforcement learning to simulate the participants’ decisions. The simulation results suggest that the observed behavioral patterns can be parsimoniously explained by assuming that the Pavlovian approach bias acts as a pruning mechanism when expanding decision trees in both forward and backward directions.}
}
@article{SHIBATA2021436,
title = {Sensitivity – Local index to control chaoticity or gradient globally –},
journal = {Neural Networks},
volume = {143},
pages = {436-451},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002471},
author = {Katsunari Shibata and Takuya Ejima and Yuki Tokumaru and Toshitaka Matsuki},
keywords = {Sensitivity, Sensitivity adjustment learning (SAL), Edge of chaos, Recurrent neural network (RNN), Deep feedforward neural network (DFNN), Vanishing gradient problem},
abstract = {Here, we introduce a fully local index named “sensitivity” for each neuron to control chaoticity or gradient globally in a neural network (NN). We also propose a learning method to adjust it named “sensitivity adjustment learning (SAL)”. The index is the gradient magnitude of its output with respect to its inputs. By adjusting its time average to 1.0 in each neuron, information transmission in the neuron changes to be moderate without shrinking or expanding for both forward and backward computations. That results in moderate information transmission through a layer of neurons when the weights and inputs are random. Therefore, SAL can control the chaoticity of the network dynamics in a recurrent NN (RNN). It can also solve the vanishing gradient problem in error backpropagation (BP) learning in a deep feedforward NN or an RNN. We demonstrate that when applying SAL to an RNN with small and random initial weights, log-sensitivity, which is the logarithm of RMS (root mean square) sensitivity over all the neurons, is equivalent to the maximum Lyapunov exponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP through time) to avoid the vanishing gradient problem in a 300-layer NN or an RNN that learns a problem with a lag of 300 steps between the first input and the output. Compared with manually fine-tuning the spectral radius of the weight matrix before learning, SAL’s continuous nonlinear learning nature prevents loss of sensitivities during learning, resulting in a significant improvement in learning performance.}
}
@article{BENTON2023105626,
title = {Associative learning or Bayesian inference? Revisiting backwards blocking reasoning in adults},
journal = {Cognition},
volume = {241},
pages = {105626},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105626},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002603},
author = {Deon T. Benton and David H. Rakison},
keywords = {Causal reasoning, Causal mechanisms, Computational models, Analytical models, Associative learning, Bayesian inference},
abstract = {Causal reasoning is a fundamental cognitive ability that enables humans to learn about the complex interactions in the world around them. However, the cognitive mechanisms that underpin causal reasoning are not well understood. For instance, there is debate over whether Bayesian inference or associative learning best captures causal reasoning in human adults. The two experiments and computational models reported here were designed to examine whether adults engage in one form of causal inference called backwards blocking reasoning, whether the presence of potential distractors affects performance, and how adults' ratings align with the predictions of different computational models. The results revealed that adults engaged in backwards blocking reasoning regardless of whether distractor objects are present and that their causal judgements supported the predictions of a Bayesian model but not the predictions of two different associative learning models. Implications of these results are discussed.}
}
@incollection{ROCAVERT202065,
title = {Arts Bias},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {65-68},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23612-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236122},
author = {Carla Rocavert},
keywords = {Algorithm, Arts, Bias, Creativity, Capitalism, Elite, Neoliberalism, Permanence, Technology, Utility},
abstract = {This entry posits that current debates around ‘arts bias’ are indicative of evolving definitions of creativity. It discusses themes of utility and permanence to illuminate tensions between historical conceptions of artistic creativity and newer fields, especially those which are driving the global economy toward an increasingly technologically-oriented paradigm under neoliberal capitalism. The arrival of computational creativity and the practice of applying algorithmic data technologies to artmaking are discussed.}
}
@article{RUBIOFERNANDEZ2025269,
title = {Tracking minds in communication},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {3},
pages = {269-281},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324003127},
author = {Paula Rubio-Fernandez and Marlene D. Berke and Julian Jara-Ettinger},
keywords = {social cognition, Theory of Mind, language, communication},
abstract = {How does social cognition help us communicate through language? At what levels does this interaction occur? In classical views, social cognition is independent of language, and integrating the two can be slow, effortful, and error-prone. But new research into word level processes reveals that communication is brimming with social micro-processes that happen in real time, guiding even the simplest choices like how we use adjectives, articles, and demonstratives. We interpret these findings in the context of advances in theoretical models of social cognition and propose a communicative mind-tracking framework, where social micro-processes are not a secondary process in how we use language – they are fundamental to how communication works.}
}
@article{ROBINSON2021,
title = {Development of the Organonitrogen Biodegradation Database: Teaching Bioinformatics and Collaborative Skills to Undergraduates during a Pandemic},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2351},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000745},
author = {Serina L. Robinson and Troy Biernath and Caleb Rosenthal and Dean Young and Lawrence P. Wackett and Betsy M. Martinez-Vaz},
abstract = {Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology.
ABSTRACT
Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology. The work presented here describes a fully online, collaborative research experience created to allow undergraduate students to learn those skills. The research experience was focused on the development and implementation of the Organonitrogen Biodegradation Database (ONDB, z.umn.edu/ondb). The ONDB was developed to catalog information about the cost, chemical properties, and biodegradation potential of commonly used organonitrogen compounds. A cross-institutional team of undergraduate researchers worked in collaboration with two faculty members and a postdoctoral fellow to develop the database. Students carried out extensive online literature searches and used a biodegradation prediction website to research and represent the microbial catabolism of different organonitrogen compounds. Participants employed computational tools such as R, Shiny, and flexdashboard to construct the database pages and interactive web interface for the ONDB. Worksheets and forms were created to encourage other students and researchers to gather information about organonitrogen compounds and expand the database. Student progress was evaluated through biweekly project meetings, presentations, and a final reflection. The ONDB undergraduate research experience provided a platform for students to learn bioinformatics skills while simultaneously developing a teaching and research tool for others.}
}
@article{KWON2019109608,
title = {Towards codification of thunderstorm/downburst using gust front factor: Model-based and data-driven perspectives},
journal = {Engineering Structures},
volume = {199},
pages = {109608},
year = {2019},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2019.109608},
url = {https://www.sciencedirect.com/science/article/pii/S0141029619306315},
author = {Dae Kun Kwon and Ahsan Kareem},
keywords = {Wind loads, Nonstationary process, Gust front, Gust front factor, Downburst, Thunderstorm, Codes and standards},
abstract = {Winds associated with gust fronts originating from a thunderstorm/downburst exhibit rapid changes during a short time period which may be accompanied by changes in direction. For several decades, a number of studies have been focused on identifying the characteristics of such nonstationary gust front winds in a variety of manners such as experimental/numerical methods and full-scale measurements. Yet, beginning the dialogue on any guidelines for design practice has thus far not evolved, in part due to a limited consensus on such characteristics among studies in conjunction with paucity of available data needed for vetting and corroborating, which is further impacted by the presence of nonstationarity. In an effort to establishing a new design procedure for this type of wind load effect on structures, the gust front factor (GFF) framework has been proposed by authors that encapsulates both the kinematic and dynamic features of gust front induced wind effects on structures, which distinguish themselves from those experienced in conventional boundary layer flows. This study revisits the gust front factor framework seeking to take the next step toward a possible initial framework for codification of gust front winds from model-based and data-driven perspectives. A modular and extensible web-enabled framework to estimate gust front related wind load effects is envisaged to rationally and holistically quantify design loads. This would promote design practice to enhance disaster resilience of the built environment. In this context, a closed-form expression concerning nonstationary fluctuations for a case of a long pulse duration is derived to facilitate rapid evaluation of nonstationary turbulence effects. A preliminary uncertainty analysis is also carried out to assess the influence of uncertainties associated with the load effects of gust front winds and the reliability of GFF. In addition, a comparison of the model-based gust front factor with a recently introduced thunderstorm response spectrum technique to assess their relative performance is carried out. In view of the lessons learned from the history of the gust loading factor on codes and standards, a possible living codification concept through a learning and updating invoking the emerging “Design Thinking” approach is discussed.}
}
@article{LI2025102888,
title = {From assistance to reliance: Development and validation of the large language model dependence scale},
journal = {International Journal of Information Management},
volume = {83},
pages = {102888},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102888},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000209},
author = {Zewei Li and Zheng Zhang and Mingwei Wang and Qi Wu},
keywords = {Factor model of LLMs dependence, Large language models, Functional dependence, Existential dependence, Alleviating interventions},
abstract = {With the rapid advancement of large language models (LLMs), the phenomenon of LLMs dependence has emerged and garnered significant attention. However, previous scales have been insufficient to measure the extent of individuals' dependence on LLMs. The current study aims to utilize the human-computer trust model and addiction theory to develop and validate the LLMs dependence scale (LDS) and to report its psychometric properties. An exploratory structural investigation of LLMs dependence was conducted with a sample of 421 LLMs users (Sample 1), which included items analysis, exploratory factor analysis, and network analysis. Additionally, a formal test was performed with a separate sample of 1030 LLMs users (Sample 2), with the data undergoing structural validation through confirmatory factor analysis, validity testing, and reliability testing. To mitigate the potential negative impacts of LLMs dependence, we employed the NodeIdentifyR algorithm for computational simulation interventions to identify critical intervention nodes within the LLMs dependence network. The results indicated that the LDS (18 items) exhibited a bifactor structure of functional dependence and existential dependence. The confirmatory factor model demonstrated a good fit and the LDS also showed good criterion-related validity. Subsequent simulated results of alleviating interventions suggested that users' existential dependence was primarily driven by their dependence on LLMs to handle tedious and boring tasks, while functional dependence was more influenced by users' belief in the omnipotence of LLMs. In summary, the factor structure of the LDS is clear, and its reliability and validity indices meet psychometric standards, making it an effective tool for measuring LLMs dependence.}
}
@article{VALLVERDU20146,
title = {What are Simulations? An Epistemological Approach},
journal = {Procedia Technology},
volume = {13},
pages = {6-15},
year = {2014},
note = {SLACTIONS 2013: Research conference on virtual worlds – Learning with simulations},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314000139},
author = {Jordi Vallverdú},
keywords = {model, computer, simulation, epistemology, representation},
abstract = {Contemporary sciences use a wide and diverse range of computational simulations, including in the areas of aeronautics, chemistry, bioinformatics, social sciences, AI, the physics of elementary particles and most other scientific fields. A simulation is a mathematical model that describes or creates computationally a system process. Simulations are our best cognitive representation of complex reality, that is, our deepest conception of what reality is. In this paper we defend that a simulation is equivalent epistemologically and ontologically with all other types of cognitive models of elements of reality. Therefore, simulations cannot be considered secondary nor weak instruments to approach to the reality analysis.}
}
@article{WANG2024111131,
title = {Three-way clustering: Foundations, survey and challenges},
journal = {Applied Soft Computing},
volume = {151},
pages = {111131},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111131},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011493},
author = {Pingxin Wang and Xibei Yang and Weiping Ding and Jianming Zhan and Yiyu Yao},
keywords = {Cluster analysis, Two-way clustering, Three-way decision, Three-way clustering},
abstract = {Clustering, as an unsupervised data mining technique, allows us to classify similar objects into the same cluster according to certain criteria. It helps us identify patterns between objects, reveal the associations between objects, and discover hidden structures. Traditional two-way clustering (2W clustering) algorithms represent one cluster by one set and only two types of relationships are considered between a sample and a cluster, namely, belonging to and not belonging to. Two-way decision is not always feasible especially in situations that are characterized by uncertainty and lack of information. Guided by the principle of three-way decision (3WD) as thinking in threes, three-way clustering (3W clustering) addresses the information uncertainty problem using core and the fringe regions to character a cluster. The universe is split into three sections by these two sets, which capture three kinds of relationships between objects and a cluster, namely, belonging to, partially belonging to, and not belonging-to. Compared with 2W clustering methods, 3W clustering incorporates the fringe region to describe the uncertain relationship between objects and clusters, which provides more information about the clustering structure. This survey points out the historical developments of three-way clustering and makes an overview of the achievements in the field of three-way clustering. In addition, to reap a clearer grasp of the development and research significance of three-way clustering, we divide the existing three-way clustering approaches into two categories and present the bibliometric analysis of related approaches. Finally, we point out some challenges and future research topics in three-way clustering. It is hoped that this review can serve as a reference and provide convenience for scholars and practitioners in the field of three-way clustering.}
}
@article{RITCHIE2012649,
title = {Styles for philosophers of science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {43},
number = {4},
pages = {649-656},
year = {2012},
note = {Part Special Issue: Styles of Thinking},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2012.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368112000490},
author = {Jack Ritchie},
keywords = {Ian Hacking, Styles of Thinking, Realism, Self-authentication},
abstract = {In this paper I discuss the bearing of Hacking’s ideas about Scientific Styles on traditional debates in the philosophy of science concerning rationality and realism. I argue that a kind of deflationary position with regard to realism debates is a natural consequence of Hacking’s claim that styles are self-authenticating. I then go on to argue, using an example of van Fraassen’s, that Hacking should allow a methodological role for realism debates and hence they are not idle, as he has claimed, although their resolution may not be important.}
}
@incollection{KRAWCZYK2018101,
title = {Chapter 5 - Reasoning Origins: Human Development During Childhood},
editor = {Daniel C. Krawczyk},
booktitle = {Reasoning},
publisher = {Academic Press},
pages = {101-129},
year = {2018},
isbn = {978-0-12-809285-9},
doi = {https://doi.org/10.1016/B978-0-12-809285-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092859000053},
author = {Daniel C. Krawczyk},
keywords = {Analogies, Causal reasoning, Decision making, Development, Developmental stages, Moral reasoning, Relational reasoning},
abstract = {The developmental process is remarkably dynamic. The process is both a biological one and an environmental one with both factors frequently contributing to the output of increasingly sophisticated and abstract reasoning behavior. Children begin with a process of cortical thickening as large numbers of synaptic connections are formed. From age three onward, the cortex undergoes a tuning process as some synaptic connections strengthen and others weaken. The net result of this process is a decrease in cortical volume from age 5 through 20. Children's thinking is guided by a variety of factors. The context of a problem becomes a significant factor in determining how children will reason and developmental reasoning studies require sensitivity toward making the experimental stimuli understandable and interesting to the child. Children exhibit some competencies in causal reasoning and learning from a very young age. Children show increasing reasoning abilities as they develop. Skills such as relational and analogical reasoning grow during the elementary school years and are supported by increases in cognitive control and decreases in impulsivity. The child becomes less concrete in how he or she views and interacts with the world. This increasing abstraction ability encompasses semantic knowledge, deduction, and moral thinking.}
}
@incollection{WILLIAMS2020341,
title = {Chapter 17 - Begin with the human: Designing for safety and trustworthiness in cyber-physical systems},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {341-357},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000171},
author = {Elizabeth T. Williams and Ehsan Nabavi and Genevieve Bell and Caitlin M. Bentley and Katherine A. Daniell and Noel Derwort and Zac Hatfield-Dodds and Kobi Leins and Amy K. McLennan},
keywords = {Trust, Safety, Autonomy, Agency, Assurance, Metrics, Interfaces, Human-machine interaction, Cyber-physical systems},
abstract = {Control systems are designed and built to manage and regulate the behavior of other systems. The use of artificial intelligence (AI) in control systems has simultaneously created new opportunities and new challenges in how we create, manage, and govern cyber-physical systems. In this paper, we discuss the challenge of defining and developing a model for contemplating how these systems will potentially learn, evolve, and act without human intervention. We present an analytical framework for thinking about trust and safety in these systems—both key factors for shared context in human-machine teams—and demonstrate its application using an example from history.}
}
@article{CHANDRA2018306,
title = {New narratives of development work? Making sense of social entrepreneurs’ development narratives across time and economies},
journal = {World Development},
volume = {107},
pages = {306-326},
year = {2018},
issn = {0305-750X},
doi = {https://doi.org/10.1016/j.worlddev.2018.02.033},
url = {https://www.sciencedirect.com/science/article/pii/S0305750X18300780},
author = {Yanto Chandra},
keywords = {Development narrative, Development, Social enterprise, Social entrepreneur, Computational linguistics},
abstract = {This article views social entrepreneurship as a relatively new model for achieving sustainable development. It also identifies development narratives that social entrepreneurs (SEs) construct to represent and promote their work as an important research gap in development studies. Drawing on the development and narratology literature, and employing computational linguistics (CL) techniques, this article compares the development narratives of 1076 Ashoka SEs across two periods (2009–2013 and 1994–1998) and two economies (developing and developed). CL analyses reveal important themes that characterize the identity, framing and orientations of development SEs across time and economies. The findings demonstrate how SE development narratives i) tend to be more pragmatic and solution-centric, and contain less political ideology than conventional development narratives, ii) combine extant development ideas and models but reframe them in new ways to address contemporary, complex development challenges, and iii) reflect a ‘bottom-up’ approach that encourages local ownership and collaborations with various social and economic sectors to achieve development goals. Overall, this study identifies the increasing importance of SEs in the development industry and reveals new aspects of SEs—their latent political framing, collective-utilitarian identities, and topical areas—that require further research via development narratives.}
}
@article{GALLISTEL199243,
title = {Preverbal and verbal counting and computation},
journal = {Cognition},
volume = {44},
number = {1},
pages = {43-74},
year = {1992},
note = {Numerical Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(92)90050-R},
url = {https://www.sciencedirect.com/science/article/pii/001002779290050R},
author = {C.R. Gallistel and Rochel Gelman},
abstract = {We describe the preverbal system of counting and arithmetic reasoning revealed by experiments on numerical representations in animals. In this system, numerosities are represented by magnitudes, which are rapidly by inaccurately generated by the Meck and Church (1983) preverbal counting mechanism. We suggest the following. (1) The preverbal counting mechanisms is the source of the implicit principles that guide the acquisition of verbal counting. (2) The preverbal system of arithmetic computation provides the framework for the assimilation of the verbal system. (3) Learning to count involves, in part, learning a mapping from the preverbal numerical magnitudes to the verbal and written number symbols and the inverse mappings from these symbols to the preverbal magnitudes. (4) Subitizings is the use of the preverbal counting process and the mapping from the resulting magnitudes to number words in order to generate rapidly the number words for small numerosities. (5) The retrieval of the number facts, which plays a central role in verbal computation, is mediated via the inverse mappings from verbal and written numbers to the preverbal magnitudes and the use of these magnitudes to find the appropriate cells in tabular arrangements of the answers. (6) This model of the fact retrieval process accounts for the salient features of the reaction time differences and error patterns revealed by expriments on mental arithmetic. (7) The application of verbal and written computational algorithms goes on in parallel with, and is to some extent guided by, preverbal computations, both in the child and in the adult.}
}
@article{MEHRYAR2024109812,
title = {AI and climate resilience governance},
journal = {iScience},
volume = {27},
number = {6},
pages = {109812},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109812},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224010344},
author = {Sara Mehryar and Vahid Yazdanpanah and Jeffrey Tong},
keywords = {Natural sciences, Earth sciences, Environmental science, Environmental policy, Social sciences},
abstract = {Summary
While artificial intelligence (AI) offers promising solutions to address climate change impacts, it also raises many application limitations and challenges. A risk governance perspective is used to analyze the role of AI in supporting decision-making for climate adaptation, spanning risk assessment, policy analysis, and implementation. This comprehensive review combines expert insights and systematic literature review. The study’s findings indicate a large emphasis on applying AI to climate “risk assessments,” particularly regarding hazard and exposure assessment, but a lack of innovative approaches and tools to evaluate resilience and vulnerability as well as prioritization and implementation process, all of which involve subjective, qualitative, and context-specific elements. Additionally, the study points out challenges such as difficulty of simulating complex long-term changes, and evolving policies and human behavior, reliance on data quality and computational resources, and the need for improved interpretability of results as areas requiring further development.}
}
@incollection{VARGHESE202275,
title = {Chapter 4 - Principles in action},
editor = {George Varghese and Jun Xu},
booktitle = {Network Algorithmics (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {75-107},
year = {2022},
isbn = {978-0-12-809927-8},
doi = {https://doi.org/10.1016/B978-0-12-809927-8.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128099278000099},
author = {George Varghese and Jun Xu},
keywords = {Buffer validation, Dijkstra's algorithm, virtual circuit, transport protocols},
abstract = {Part 2 of the book begins a detailed look at specific network bottlenecks such as data copying and control transfer. While the principles are used in these later chapters, the focus of these later chapters is on the specific bottleneck being examined. Given that network algorithmics is as much a way of thinking as it is a set of techniques, it seems useful to round out Part 1 by seeing the principles in action on small, self contained, but nontrivial network problems. Thus this chapter provides examples of applying the principles in solving specific networking problems. The examples are drawn from real problems, and some of the solutions are used in real products. Unlike subsequent chapters, this chapter is not a collection of new material followed by a set of exercises. Instead, this chapter can be thought of as an extended set of exercises. In Section 4.1 to Section 4.15, 15 problems are motivated and described. Each problem is followed by a hint that suggests specific principles, which is then followed by a solution sketch. There are also a few exercises after each solution. In classes and seminars on the topic of this chapter, the audience enjoyed inventing solutions by themselves (after a few hints were provided), rather than directly seeing the final solutions.}
}
@article{LIN2022104649,
title = {Towards a cross-level understanding of Bayesian inference in the brain},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104649},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104649},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001385},
author = {Chin-Hsuan Sophie Lin and Marta I. Garrido},
keywords = {Probabilistic inference, Bayesian decision theory, Uncertainty, Sampling, Variational approximation, Neural codes, Marr’s level of analysis},
abstract = {Perception emerges from unconscious probabilistic inference, which guides behaviour in our ubiquitously uncertain environment. Bayesian decision theory is a prominent computational model that describes how people make rational decisions using noisy and ambiguous sensory observations. However, critical questions have been raised about the validity of the Bayesian framework in explaining the mental process of inference. Firstly, some natural behaviours deviate from Bayesian optimum. Secondly, the neural mechanisms that support Bayesian computations in the brain are yet to be understood. Taking Marr’s cross level approach, we review the recent progress made in addressing these challenges. We first review studies that combined behavioural paradigms and modelling approaches to explain both optimal and suboptimal behaviours. Next, we evaluate the theoretical advances and the current evidence for ecologically feasible algorithms and neural implementations in the brain, which may enable probabilistic inference. We argue that this cross-level approach is necessary for the worthwhile pursuit to uncover mechanistic accounts of human behaviour.}
}
@article{THIEDE201536,
title = {Can teachers accurately predict student performance?},
journal = {Teaching and Teacher Education},
volume = {49},
pages = {36-44},
year = {2015},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2015.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X1500013X},
author = {Keith W. Thiede and Jonathan L. Brendefur and Richard D. Osguthorpe and Michele B. Carney and Amanda Bremner and Sam Strother and Steven Oswalt and Jennifer L. Snow and John Sutton and Dan Jesse},
keywords = {Teacher judgment, Judgment accuracy, Mathematics achievement},
abstract = {In two studies, we examined the effect of professional development to improve mathematics instruction on the accuracy of teachers' monitoring of student learning. Study 1 was conducted with 36 teachers participating in three years of professional development. Judgment accuracy was influenced by the fidelity with which what was learned in the professional development. Study 2 was conducted with 64 teachers from 8 schools, which were randomly assigned to receive professional development or serve as a control. Judgment accuracy was greater for teachers receiving professional development than for teachers who did not and teachers were better to predict students' computational skills.}
}
@article{GAO2023106199,
title = {Letter to the Editor on a shallow water wave equation in Results Phys. 43, 106048 (2022) and its generalization},
journal = {Results in Physics},
volume = {44},
pages = {106199},
year = {2023},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2022.106199},
url = {https://www.sciencedirect.com/science/article/pii/S2211379722008208},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Generalized shallow water wave equation, Similarity reductions, Symbolic computation},
abstract = {Results Phys. 43, 106048 (2022) has amusingly retrieved some solitonic and other analytic solutions for a shallow water wave equation presented there. In this Letter, we suggest that such an equation be moreover studied in line with Results Phys. 43, 106048 (2022). Employing symbolic computation, for a generalization of that equation, with respect to the displacement and velocity of the water, we construct a family of the similarity reductions, to a known ordinary differential equation. Our results depend on the gravitational force and wave height.}
}
@incollection{GOMILA201219,
title = {3 - The Relevance of Language for Thought: A Continuum of Possibilities},
editor = {Antoni Gomila},
booktitle = {Verbal Minds},
publisher = {Elsevier},
address = {London},
pages = {19-33},
year = {2012},
isbn = {978-0-12-385200-7},
doi = {https://doi.org/10.1016/B978-0-12-385200-7.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852007000035},
author = {Antoni Gomila},
keywords = {Cognitive restructuring, linguistic relativism, Whorf, Vygotsky, thinking for speaking, modular interphase, social scaffolding, categorical effect, perceptual similarity},
abstract = {Publisher Summary
This chapter directs the influence and relevance of language on thoughts. Though there has been no outlined domain on how exactly language effects cognitive architecture, the chapter critically studies five most relevant positions that have attracted defenders, critics since twentieth century to contemporary proposals. It discuses relativism, cognitive restructuring, thinking for speaking, language as modular interface, and language as social scaffolding. Linguistic relativism finds its roots in Romanticism as a reaction to the supremacist attitudes of the “Enlightment thinkers,” who were in the business of establishing hierarchies of languages. Cognitive system, being linguistic, acquires a supplementary system of cognitive representation and processing, which transforms the basic capabilities of system and gives rise to new possibilities. Since language is an interface between the modules it attempts to concede to some cognitive impact without challenging the general cognitive architecture of modules of thought as a successful representational vehicle. Lastly, human minds are socially and culturally constituted minds and therefore linguistic symbols (like other kinds of symbols and other social tools in general) allow the individual to externally discharge cognitive processes through language.}
}
@article{FEIZIZADEH2024103764,
title = {Spatiotemporal mapping of urban trade and shopping patterns: A geospatial big data approach},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {128},
pages = {103764},
year = {2024},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.103764},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224001183},
author = {Bakhtiar Feizizadeh and Davoud Omarzadeh and Thomas Blaschke},
keywords = {Shopping pattern mapping, GIS, Geospatial big data, Data-driven approaches, Spatially explicit, GIScience, Novel methodology},
abstract = {The economic viability of an urban area in terms of trade and shopping significantly impacts its residents’ quality of life and is crucial for any sustainable development initiative. Geographic information systems (GIS) are well established, but the use of GIS technology within finance and trade analysis is still in its infancy. In this article, we highlighted the potential of GIS technology and big data analytics and demonstrated the importance of thinking in spatial terms for analysing patterns within the trade and finance industries. We studied spatiotemporal trade and shopping patterns in the city of Tabriz using data generated by customer purchase transactions obtained from 5200 stores, shopping, business and service centres. We employed time series transaction data collected from the points of sale in stores, shopping, service and business centres located in different areas of the city. We applied four well known geospatial big data driven approaches including machine learning nearest neighbour, kernel density estimation, space–time pattern mining and spatiotemporal coupling tele-coupling for detecting and mapping of spatial trade hotspot patterns. The results of this study indicated the potential of GIScience methods for the explicit spatial mapping of trade and shopping patterns. The results revealed that the city centre, particularly the Bazaar of Tabriz, acts as the city’s heart of trade, and we identify additional major business hotspots. Furthermore, the results allow for studying the impacts of unbalanced urban development in Tabriz, where the wealthy suburbs with high quality of life, such as Valiasr and Elguli, host the major shopping hotspots. The spatial patterns obtained enable local stakeholders, decision makers and authorities to develop strategic plans for urban sustainable development in Tabriz. The geospatial big data approach used can stimulate novel and progressive research. Results of this study demonstrate methodological advancements in GIScience by ’spatializing’ individual purchase data and therefor proposing an explicit geospatial big data analysis approach.}
}
@article{BIBI2025115199,
title = {Dopant-free hole transport materials for perovskite solar cells and donor molecules for organic solar cells},
journal = {Computational and Theoretical Chemistry},
volume = {1248},
pages = {115199},
year = {2025},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2025.115199},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X25001355},
author = {Zeeshana Bibi and Javed Iqbal and Ali Raza Ayub and Amna Ayub and Sehrish Gul},
keywords = {DFT, Perovskite solar cell, Hole transporting material, Organic solar cells},
abstract = {This work aimed to create new Ullazine derivatives as hole-transporting materials (HTMs) for perovskite solar cells (PSCs) and donor materials for organic solar cells (OSCs). The newly devised compounds (UM1-UM6) exhibit much smaller energy band gaps and a broader λmax than the UMR because of their strong electron-attracting groups. While UMR has a bandgap of 3.37 eV, the produced molecules ranged from 1.45 to 2.08 eV. The λmax of UM1-UM6 in DCM are 376–460 nm, while the λmax value of UMR is 408 nm. The reference UMR has a λh value of 0.008164 eV, whereas the computationally computed λh values of the UM1-UM6 created molecules range from 0.003777 to 0.008791 eV. Reason being, the acceptor moieties of these compounds make hole transit easier. Furthermore, after all of the newly created molecules were scaled with a PC61BM acceptor, the Voc values were comparable to or higher than the reference, suggesting that these molecules are in a good position to increase efficiency. In terms of PCE (6.27 to 12.33 %), the newly created compounds (UM1-UM6) perform better than the reference compound (PCE = 7.80 %). The newly designed compounds (UM1-UM6) have the potential to be used as noble HTMs in the development of more advanced perovskite solar cells (PSCs) and donor molecules for organic solar cells (OSCs) in the future.}
}
@article{OSORIOMORA2025837,
title = {A risk-averse latency location-routing problem with stochastic travel times},
journal = {European Journal of Operational Research},
volume = {321},
number = {3},
pages = {837-850},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.10.041},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724008440},
author = {Alan Osorio-Mora and Francisco Saldanha-da-Gama and Paolo Toth},
keywords = {Routing, Cumulative routing, Sampling, Variable neighborhood search},
abstract = {In this paper, a latency location-routing problem with stochastic travel times is investigated. The problem is cast as a two-stage stochastic program. The ex-ante decision comprises the location of the depots. The ex-post decision regards the routing, which adapts to the observed travel times. A risk-averse decision-maker is assumed, which is conveyed by adopting the latency CVaRα as the objective function. The problem is formulated mathematically. An efficient multi-start variable neighborhood search algorithm is proposed for tackling the problem when uncertainty is captured by a finite set of scenarios. This procedure is then embedded into a sampling mechanism so that realistic instances of the problem can be tackled, namely when the travel times are represented by random vectors with an infinite support. An extensive computational analysis is conducted to assess the methodological developments proposed and the relevance of capturing uncertainty in the problem. Additional insights include the impact of the risk level in the solutions.}
}
@article{XUE2024108224,
title = {Interaction dynamics of social support expressions predict future support-seeking behaviors in online support groups},
journal = {Computers in Human Behavior},
volume = {156},
pages = {108224},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108224},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400092X},
author = {Haoning Xue and Wang Liao and Jingwen Zhang},
keywords = {Compensation, Computational methods, Interaction dynamics, Online support groups, Reciprocity, Support-seeking},
abstract = {Maintaining the sustainability of online support groups (OSGs) presents a significant challenge. Integrating the literature on interaction dynamics and supportive communication, this study investigated how interaction dynamics in supportive communication foster long-term support-seeking behaviors that are crucial to sustaining continuous support exchanges in OSGs. Using a large-scale dataset of 48,868 posts and 468,243 comments over ten years from an OSG, this study examined how reciprocity and compensation of emotional and informational support, signaled by emotional expressions and analytical expressions, predicted a poster's future support-seeking behaviors in the OSG. Results showed that a poster's future support-seeking behaviors were positively associated with receiving (a) reciprocity of analytical expressions and (b) compensation of negative emotional expressions with positive emotional expressions in their past posts. However, reciprocity of negative emotional expressions was negatively associated with a poster's future support-seeking behaviors. This study emphasizes social support as an ongoing interactive process and its importance in motivating support-seeking behaviors and fostering a thriving OSG.}
}
@article{JAGER2021133,
title = {Using agent-based modelling to explore behavioural dynamics affecting our climate},
journal = {Current Opinion in Psychology},
volume = {42},
pages = {133-139},
year = {2021},
note = {Psychology of Climate Change (2021)},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000968},
author = {Wander Jager},
keywords = {Agent based modelling, Social complexity, Computational social science, Social simulation, Artificial societies, Environmental behaviour, Climate, Psychology},
abstract = {This article introduces the methodology of agent-based modelling (ABM), explains how it contributes to understanding the dynamics of climate-relevant behaviour and discusses the challenges to implementing behavioural theory in ABMs. Next, an overview will be given on recent advances in environmentally relevant ABMs. The conclusions address the future of the ABM tool in the context of environmentally relevant behaviour in research and education.}
}
@article{XIE2015262,
title = {Evolutionary sampling: A novel way of machine learning within a probabilistic framework},
journal = {Information Sciences},
volume = {299},
pages = {262-282},
year = {2015},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2014.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0020025514011384},
author = {Zhenping Xie and Jun Sun and Vasile Palade and Shitong Wang and Yuan Liu},
keywords = {Evolutionary sampling, Support sample model, Monte Carlo Markov chain, Rejection sampling, Online learning, Particle swarm optimization},
abstract = {In many traditional machine learning methods, sampling is only a process of acquiring training data. However, some studies (on sequential Markov chains and particle filters) have demonstrated that sampling can be used for solving some intractable optimization problems in classical learning methods. Along this line of thinking, the relationships between sampling and learning are theoretically exploited in this paper, wherein the key feature of the sampling process is selecting representative samples from original data that can be modeled by a probability distribution. In theory, acquiring reliable samples is not an easy task for an arbitrary probability distribution. Motivated by approaches in evolutionary computation, rejection sampling and function approximation, a novel sampling strategy, called the evolutionary sampling, is proposed in this paper, and a machine learning method, called the evolutionary sampling approach (ESA), is put forward afterwards. Within ESA, a computing model, called the support sample model (SSM), is presented as well and is used to approximate an original density function. Accordingly, a concrete implementation of an evolutionary sampling approach (ESA) is proposed to seek the optimal model parameters of the SSM. Benefiting from the combination of rejection sampling and evolutionary searching, the ESA can theoretically converge to the optimal solution by minimizing the total variation distance, and can do this with high computational efficiency. Moreover, the normalized factor of a density function can be automatically estimated with high precision within the ESA. As a result, the ESA may be suitable for machine learning problems that could be transformed into density function approximation problems within a probabilistic framework. In addition, derived from the rejection sampling strategy, the ESA can also have online learning abilities required by large-scale data stream processing tasks. Theoretical analyses and application studies are carried out in this paper, and the results demonstrate that the ESA, as a novel way of machine learning, has several prominent merits aspired by past researches in machine learning.}
}
@article{WEISSLER19991061,
title = {A Perspective on Standardizing the Predictive Power of Noninvasive Cardiovascular Tests by Likelihood Ratio Computation: 1. Mathematical Principles},
journal = {Mayo Clinic Proceedings},
volume = {74},
number = {11},
pages = {1061-1071},
year = {1999},
issn = {0025-6196},
doi = {https://doi.org/10.4065/74.11.1061},
url = {https://www.sciencedirect.com/science/article/pii/S0025619611650933},
author = {Arnold M. Weissler},
abstract = {The current practice of reporting positive and negative predictive value (PV), sensitivity (Se), and specificity (Sp) as measures of the power of noninvasive cardiovascular tests has significant limitations. A test result's PV and its comparison with other test results are highly dependent on the pretest disease prevalence at which it is determined; the citation of sensitivity and specificity provides no succinct or explicit quantitation of the rule-in and rule-out power of a test. This article presents a rationale for the use of an alternative standard for expressing predictive power in the form of positive and negative likelihood ratios, (+)LR and (-)LR. The likelihood ratios are composite expressions of test power, which incorporate the Se and Sp and their respective complements [(1 - Se) and (1 - Sp)], thus yielding single unambiguous measures of positive and negative predictive power. The likelihood ratios are calculated as follows: (+)LR = Se(l- Sp) and (-)LR = Sp/(I- Se). On analysis of the predictive value equations, the likelihood ratios equal the quotients of the posttest predictive value odds to the pretest prevalence odds for disease and no disease, respectively, as follows: (+)LR = (+)PVOd/POD and (-)LR = (-)PVOn/PON, where (+)PVO d is positive predictive value odds for disease, POD is prevalence odds for disease, (-)PVOn is negative predictive value odds for no disease, and PON is prevalence odds for no disease. Thus, the likelihood ratios are measures of the odds advantage in posttest probability of disease or no disease relative to pretest probability, independent of disease prevalence in the tested population. The quotients of the (+)LR or the (-)LR among test results studied in a common population are direct expressions of their relative predictive power in that population, The likelihood ratio principle is applicable to the evaluation of the predictive power of multiple tests performed in a common population and to estimating predictive power at multiple test thresholds.}
}
@article{BERZ1990473,
title = {Computational aspects of optics design and simulation: COSY INFINITY},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {298},
number = {1},
pages = {473-479},
year = {1990},
issn = {0168-9002},
doi = {https://doi.org/10.1016/0168-9002(90)90649-Q},
url = {https://www.sciencedirect.com/science/article/pii/016890029090649Q},
author = {Martin Berz},
abstract = {The new differential algebraic (DA) techniques allow very efficient treatment and understanding of nonlinear motion in optical systems as well as circular accelerators. To utilize these techniques in their most general way, a powerful software environment is essential. A language with structure elements similar to Pascal was developed. It has object oriented features to allow for a direct utilization of the elementary operations of the DA package. The compiler of the language is written in Fortran 77 to guarantee wide portability. The language was used to write a very general beam optics code, COSY INFINITY. At its lowest level, it allows the computation of the maps of standard beam line elements including fringe fields and system parameters to arbitrary order. The power of the DA approach coupled with an adequate language environment reveals itself in the very limited length of COSY INFINITY of only a few hundred lines. Grouping of elements as well as structures for optimization and study are readily available through the features of the language. Because of the openness of the approach, it offers a lot of power for more advanced purposes. For example, it is very easy to construct new particle optical elements. There are also many ways to efficiently manipulate and analyze the maps.}
}
@incollection{CUMMINS20171,
title = {Chapter 1 - The Agile Enterprise},
editor = {Fred A. Cummins},
booktitle = {Building the Agile Enterprise (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {1-34},
year = {2017},
series = {The MK/OMG Press},
isbn = {978-0-12-805160-3},
doi = {https://doi.org/10.1016/B978-0-12-805160-3.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051603000016},
author = {Fred A. Cummins},
keywords = {Agile enterprise, Business impact of technology, Capability-based architecture, Business collaboration management, Value delivery management, Value delivery modeling language},
abstract = {This chapter begins with an introduction to the agile enterprise concept and provides a somewhat historical perspective on the evolution of information technology and its impact on business operations and management. It then introduces three new ways of thinking that are key to today's agile enterprise and are referenced in the subtitle of this book: (1) capability-based architecture, (2) business collaboration management (BCM), and (3) value delivery management (VDM). Finally, the impact of VDM is discussed related to the management of major business changes, along with some critical success factors for the journey to agility.}
}
@article{CHERRIER2023104497,
title = {Household heterogeneity in macroeconomic models: A historical perspective},
journal = {European Economic Review},
volume = {158},
pages = {104497},
year = {2023},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2023.104497},
url = {https://www.sciencedirect.com/science/article/pii/S0014292123001265},
author = {Beatrice Cherrier and Pedro Garcia Duarte and Aurélien Saïdi},
keywords = {History of macroeconomics, Heterogeneous agents, Bewley models, Permanent income hypothesis, Aggregation, Equity premium puzzle, Precautionary savings},
abstract = {In this paper, we trace the rise of heterogeneous household models in mainstream macroeconomics from the turn of the 1980s to the early 2000s, when these models evolved into an identifiable and consistent literature. We show that different communities across the US and Europe considered heterogeneous agents for various reasons and developed models that differed in their theoretical and empirical strategies. Minnesota economists primarily focused on incorporating stochastic heterogeneity into general equilibrium models. Other researchers refined growth models or tried to find alternatives to the permanent income hypothesis, leading them to explore more structural heterogeneity. We also document the computational challenges that some of these communities faced, how they gradually became aware of each other's work, and how they faced criticisms from macro- and microeconomists, many of them trained in European countries and dissatisfied with the theoretical and empirical aggregation strategies underlying these models.}
}
@article{HICKS2007233,
title = {Lean information management: Understanding and eliminating waste},
journal = {International Journal of Information Management},
volume = {27},
number = {4},
pages = {233-249},
year = {2007},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0268401206001435},
author = {B.J. Hicks},
keywords = {Information management, SMEs, Waste, Information systems infrastructure, Strategy, Process improvement},
abstract = {This paper deals with the development of a new approach for supporting the improvement of information management and the overall information systems infrastructure. In particular, the paper discusses the application of lean thinking to information management; where information management can be considered to involve adding value to information by virtue of how it is organised, visualised and represented; and enabling information (value) to flow to the end-user (customer) through the processes of exchange, sharing and collaboration. The potential benefits of lean thinking are discussed and the fundamental barriers for its application to information management are highlighted. These include the need to characterise the nature of waste and establish the five principles of; value, value streams, flow, pull and continuous improvement in the context of information management. It follows that the core contribution of this paper is the development of an understanding of these critical elements and the creation of a conceptual framework for a set of lean principles within the context of information management. This framework offers a unique and arguably generic approach for supporting the retrospective improvement of information management systems and the overall information systems infrastructure.}
}
@article{ADAMS201731,
title = {Patternlets — A teaching tool for introducing students to parallel design patterns},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {31-41},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S074373151730014X},
author = {Joel C. Adams},
keywords = {Design patterns, Education, MPI, Multiprocessing, Multithreading, OpenMP, Parallel, Patternlets, Teaching, Threads},
abstract = {Thanks to the ubiquity of multicore processors, today’s CS students must be introduced to parallel computing or they will be ill prepared as modern software developers. Professional developers of parallel software think in terms of parallel design patterns, which are markedly different from traditional (sequential) design patterns. It follows that the more we can teach students to think in terms of parallel patterns, the more their thinking will resemble that of parallel software professionals. In this paper, we present patternlets—minimalist, scalable, syntactically correct programs, each designed to introduce students to a particular parallel design pattern. The collection currently includes 44 patternlets (16 MPI, 17 OpenMP, 9 Pthreads, and 2 heterogeneous), of which we present a representative sample. We also present data that indicate the use of patternlets to introduce parallelism in CS2 produced a modest improvement in student understanding of parallel concepts.}
}
@article{TAKAMA20151263,
title = {NFC-based Tangible User Interface for Information Curation and Its Application to Analogy Game},
journal = {Procedia Computer Science},
volume = {60},
pages = {1263-1270},
year = {2015},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.192},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915023194},
author = {Yasufumi Takama and Tomohiro Ito and Hiroshi Ishikawa},
keywords = {Tangible user interface (TUI), Near field communication (NFC), Smartphone, Information curation, Analogy game},
abstract = {This paper applies a Tangible User Interface (TUI) for information curation using Near Field Communication (NFC) to an analogy game. The increase in text data is more remarkable in current IT society. Although those are usually accessed with using Graphical User Interface (GUI), users except experienced computer users have difficulty in reading and organizing data with GUI. In particular, information curation such as grouping related data / information and finding relationship among them is difficult. In order to solve this problem, an interface that can access text data intuitively is expected. We are developing a TUI based on NFC, by which a user can move and group text data in a similar manner when handling paper documents. As one of the promising applications of the proposed TUI, this paper focuses on creative thinking support, for which touching externalized thought by hand is expected to be effective. An experiment is conducted, in which test participants did an analogy game with using the proposed TUI. The experimental result shows experience of using the TUI affects the participants’ self-evaluation about idea creation.}
}