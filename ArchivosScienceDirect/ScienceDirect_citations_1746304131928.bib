@article{JOLY2017133,
title = {Corruption: The shortcut to disaster},
journal = {Sustainable Production and Consumption},
volume = {10},
pages = {133-156},
year = {2017},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2016.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2352550916300288},
author = {Marcel Joly},
keywords = {Climate, Complex systems, Ethics, Petroleum, Politics, Zika virus},
abstract = {I invite readers to briefly explore the utility of mathematical modeling and systems thinking to properly address the impact of causal relationships associated with the higher levels of scattered corruption in the public administration on the constrained-based analysis of high-profile concerns for a sustainable economy. A recent and disastrous, but very educational, Brazilian experience is taken as the motivating example: the unequaled governmental corruption scandal hitherto known, which its epicenter has publicly being associated with the Brazilian state-owned energy company, Petrobras. Few, but remarkable, socio-environmental consequences thought to have been triggered by (or related to) the resulting political crisis, currently devastating the socioeconomic scenario in Brazil, are didactically selected for the in silico analysis proposed. Major findings show that: (a) a reductionist perspective may be illusive when comparing the distinct real-life production and consumption scenarios under corruption, and (b) nonlinear dynamics can efficiently provide theoretical plausibility for the emergent behaviors of the system, which are typically scenario-dependent and can drastically be altered when corruption evolves from a circumscribed into a scattered condition. In conclusion, these results corroborate the need for far greater attention to the issue of corruption–or more generally ethics–to aptly cope with a new array of complex global sustainability challenges that would have been unthinkable just a few decades, or years, ago.}
}
@article{ZHANG2025107610,
title = {AdaptFL: Adaptive Federated Learning Framework for Heterogeneous Devices},
journal = {Future Generation Computer Systems},
volume = {165},
pages = {107610},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107610},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005740},
author = {Yingqi Zhang and Hui Xia and Shuo Xu and Xiangxiang Wang and Lijuan Xu},
keywords = {Federated learning, Heterogeneous device, Neural architecture search, Knowledge distillation},
abstract = {With the development of the Internet of Things (IoT), Federated Learning (FL) is extensively employed in smart cities and industrial IoT, involving numerous heterogeneous devices with varying computational and storage capabilities. Traditional FL assumes that clients have enough resources to train a unified global model from the beginning to the end of training. However, it ignores the problem of uneven and real-time changes in client resources. Additionally, there are aggregation difficulties between heterogeneous client models and global model. To address these challenges, we propose an Adaptive Federated Learning Framework for Heterogeneous Devices (AdaptFL). In AdaptFL, we employ a resource-aware neural architecture search method, which searches for models based on each client’s resource conditions. It enables AdaptFL to automatically assign customized models tailored to each client’s specific resource conditions in the current round. Additionally, we employ a staged knowledge distillation strategy to facilitate efficient distribution and aggregation between the heterogeneous global model and the client models. Experimental results demonstrate that, compared to state-of-the-art model-level heterogeneous ablation methods, AdaptFL improves global test accuracy by 4% to 15% on the SVHN dataset and enhances accuracy by 5% to 14% in scenarios with heterogeneous data. Additionally, AdaptFL effectively reduces communication overhead by over 50% across all datasets. Furthermore, it offers a degree of resilience against model poisoning attacks.}
}
@article{SHAH2025104842,
title = {Deep learning multilayer architecture for analysis of three-dimensional Eyring-Powell nanofluid flow subject to viscous dissipation and joule heating},
journal = {Results in Engineering},
volume = {26},
pages = {104842},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.104842},
url = {https://www.sciencedirect.com/science/article/pii/S259012302500917X},
author = {Zahoor Shah and Muflih Alhazmi and Maryam Jawaid and Nafisa A. Albasheir and Mohammed M.A. Alma Zah and Nashwan Adnan Othman and Waqar Azeem Khan},
keywords = {Artificial intelligence, Deep learning, Neural network, Eyring-powell nanofluid, Soft computing paradigm},
abstract = {Artificial intelligence has enhanced complex systems modeling by achieving exceptional precision and effectiveness. The purpose of this paper is to use the Deep Learning Multi-Layer Soft Computing paradigm (DLML-SCP) to evaluate the model 3D flow dynamics of Eyring-Powell nanofluids subject to viscous dissipation and joule heating (EPNF-3D-VJ). It can capture the complex behavior of a specialized fluid flow system with the changing of different physical parameters like Prandtl number, magnetic field parameter, radiation parameter, and Brownian motion parameter and the controlling parameters of non-Newtonian nature of the fluid, ε, δ1, and δ2, make up the source parameters of Eyring-Powell fluid. Similarity transformation in the governing partial differential equations (PDEs) ultimately leads to a reduced set of ordinary differential equations (ODEs) along with boundary conditions. Not only does it simplify the computational process, but it also boosts the model's predictive abilities. The Adam numerical technique is employed to generate a comprehensive dataset across the fluid-dynamic spectrum that covers diverse EPNF-3D-VJ cases, offering critical insights into the system's behavior. The dataset is utilized to test, train, and validate the DLML-SCP, proving its accuracy in predicting fluid system behavior. Results show the effectiveness and reliability of the model and are well aligned to the dataset. Validation results demonstrate that the DLML-SCP framework accurately predicts fluid system behavior, achieving mean square error (MSE) values between E-09 to E-10. Important findings from the performance evaluations, it can be noted that the increase in both the Prandtl number and magnetic field coefficient has led to a decrease in the temperature and velocity profiles. With an increase in the Eyring-Powell fluid parameter, the velocity profile is likely to increase. present study utilized an advanced machine learning framework that has been proven to outperform the state-of-the-art models in predicting complex dynamics of EPNF-3D-VJ. Providing strong support for a new class of physics-informed deep neural networks designed for solving fluid mechanics problems.}
}
@article{HANSEN2022101637,
title = {From newspaper supplement to data company: Tracking rhetorical change in the Times Higher Education’s rankings coverage},
journal = {Poetics},
volume = {92},
pages = {101637},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2021.101637},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X21001352},
author = {Morten Hansen and Astrid {Van den Bossche}},
keywords = {Computational hermeneutics, Rhetoric, Ratio, University rankings, Times Higher Education},
abstract = {Despite their importance, little is known about the companies behind global university rankings and how they have legitimized the use of league tables as structuring devices in the higher education sector. Taking a computational approach to Burke's dramatistic pentad, we analyse a corpus of 3,296 articles printed between 1994 and 2020 in the Times Higher Education magazine, publisher of the World University Rankings. We show how coverage of the rankings is subject to shifts in rhetorical strategy as Times Higher Education has developed into a ranking powerhouse. Over time, the magazine has spectacularized higher education by making changes in the rankings newsworthy, and has thereby cemented the company's position as an arbiter, reporter, and consultant in the sector.}
}
@article{KOWALCZUK2019206,
title = {The impact of the temperament model on the behavior of an autonomous driver},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {8},
pages = {206-210},
year = {2019},
note = {10th IFAC Symposium on Intelligent Autonomous Vehicles IAV 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.072},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319304033},
author = {Z. Kowalczuk and O. Piechowski and M. Czubenko},
keywords = {Learning, adaptation, autonomous vehicles, artificial intelligence, cognitive aspects},
abstract = {Because it is generally believed that the personality and temperament of a human driver influence his/her behavior on the road, the article presents a computational model of the temperament of an autonomous agent - a driver. First, a short review of the four ideas of Galen’s temperament in psychology is presented. Temperament traits are grouped into four other sets, one of which is chosen for implementation in the project of integration of the temperament model with the target autonomous agent. On the basis of this selection, it is proposed to modify, by introducing additional useful mechanisms of temperament, the existing model (ISD) of an autonomous robot and/or driver. In addition, other ways of extending the ISD model are indicated, as well as possible applications of the proposed system. The developed model may also be interesting for other research purposes in which the description of the human personality is important.}
}
@article{FIRMIN2024128483,
title = {Parallel hyperparameter optimization of spiking neural networks},
journal = {Neurocomputing},
volume = {609},
pages = {128483},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128483},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224012542},
author = {Thomas Firmin and Pierre Boulet and El-Ghazali Talbi},
keywords = {Spiking neural networks, Hyperparameter optimization, Parallel asynchronous optimization, Bayesian optimization, STDP, SLAYER},
abstract = {Hyperparameter optimization of spiking neural networks (SNNs) is a difficult task which has not yet been deeply investigated in the literature. In this work, we designed a scalable constrained Bayesian based optimization algorithm that prevents sampling in non-spiking areas of an efficient high dimensional search space. These search spaces contain infeasible solutions that output no or only a few spikes during the training or testing phases, we call such a mode a “silent network”. Finding them is difficult, as many hyperparameters are highly correlated to the architecture and to the dataset. We leverage silent networks by designing a spike-based early stopping criterion to accelerate the optimization process of SNNs trained by spike timing dependent plasticity and surrogate gradient. We parallelized the optimization algorithm asynchronously, and ran large-scale experiments on heterogeneous multi-GPU Petascale architecture. Results show that by considering silent networks, we can design more flexible high-dimensional search spaces while maintaining a good efficacy. The optimization algorithm was able to focus on networks with high performances by preventing costly and worthless computation of silent networks.}
}
@article{BERKE2017222,
title = {Optimizing trauma-informed intervention for intimate partner violence in veterans: The role of alexithymia},
journal = {Behaviour Research and Therapy},
volume = {97},
pages = {222-229},
year = {2017},
issn = {0005-7967},
doi = {https://doi.org/10.1016/j.brat.2017.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0005796717301651},
author = {Danielle S. Berke and Alexandra Macdonald and Gina M. Poole and Galina A. Portnoy and Savannah McSheffrey and Suzannah K. Creech and Casey T. Taft},
keywords = {Veteran, Trauma, Alexithymia, Randomized control trial, Intimate partner violence},
abstract = {Recent research supports the efficacy of Strength at Home-Men's Program (SAH-M), a trauma-informed group intervention designed to reduce use of intimate partner violence (IPV) in veterans (Taft, Macdonald, Creech, Monson, & Murphy, 2016). However, change-processes facilitating the effectiveness of SAH-M have yet to be specified. Alexithymia, a deficit in the cognitive processing of emotional experience characterized by difficulty identifying and distinguishing between feelings, difficulty describing feelings, and use of an externally oriented thinking style, has been shown to predict PTSD severity and impulsive aggression; however, no studies have investigated the relationship between alexithymia and IPV. As such, the current study examined the role of improvements in alexithymia as a potential facilitator of treatment efficacy among 135 male veterans/service members, in a randomized control trial SAH-M. After an initial assessment including measures of IPV and alexithymia, participants were randomized to an Enhanced Treatment as Usual (ETAU) condition or SAH-M. Participants were assessed three and six months after baseline. Results demonstrated a statistically significant association between alexithymia and use of psychological IPV at baseline. Moreover, participants in the SAH-M condition self-reported significantly greater reductions in alexithymia over time relative to ETAU participants. Findings suggest that a trauma-informed intervention may optimize outcomes, helping men who use IPV both limit their use of violence and improve deficits in emotion processing.}
}
@article{OZTOP201343,
title = {Mirror neurons: Functions, mechanisms and models},
journal = {Neuroscience Letters},
volume = {540},
pages = {43-55},
year = {2013},
note = {The Mirror Neuron System},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2012.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0304394012013183},
author = {Erhan Oztop and Mitsuo Kawato and Michael A. Arbib},
keywords = {Mirror neuron, Computational model, Action recognition, imitation, language evolution, Mirror neuron development, Direct matching},
abstract = {Mirror neurons for manipulation fire both when the animal manipulates an object in a specific way and when it sees another animal (or the experimenter) perform an action that is more or less similar. Such neurons were originally found in macaque monkeys, in the ventral premotor cortex, area F5 and later also in the inferior parietal lobule. Recent neuroimaging data indicate that the adult human brain is endowed with a “mirror neuron system,” putatively containing mirror neurons and other neurons, for matching the observation and execution of actions. Mirror neurons may serve action recognition in monkeys as well as humans, whereas their putative role in imitation and language may be realized in human but not in monkey. This article shows the important role of computational models in providing sufficient and causal explanations for the observed phenomena involving mirror systems and the learning processes which form them, and underlines the need for additional circuitry to lift up the monkey mirror neuron circuit to sustain the posited cognitive functions attributed to the human mirror neuron system.}
}
@article{YANG2024102469,
title = {Prosumer data center system construction and synergistic optimization of computing power, electricity and heat from a global perspective},
journal = {Thermal Science and Engineering Progress},
volume = {49},
pages = {102469},
year = {2024},
issn = {2451-9049},
doi = {https://doi.org/10.1016/j.tsep.2024.102469},
url = {https://www.sciencedirect.com/science/article/pii/S2451904924000878},
author = {Dongfang Yang and Xiaoyuan Wang and Rendong Shen and Yang Li and Lei Gu and Ruifan Zheng and Jun Zhao},
keywords = {Data center, Prosumer, Global optimization, Waste heat, Computing power},
abstract = {In the context of achieving carbon neutrality, the imperative to save energy and reduce emissions in data centers (DCs) has become paramount. Current research predominantly concentrates on internal systems of DCs, lacking the perspective of treating DCs as prosumers and subsequent global optimization, resulting in limited results. In this paper, a novel prosumer DC integrated energy system is constructed and a globally coordinated optimization strategy for the synergy of computing power, electricity, and heat is proposed. This is achieved through meticulous adjustments to the battery charge–discharge processes on the supply side, computational workloads within the DC's internal systems, and the heating temperature for waste heat utilization on the load side. The optimization objectives are centered around minimizing the renewable energy waste and operation cost. Compared to the non-optimized system, the optimized system exhibits reductions of 11.39 % in renewable energy waste, 6.96 % in operation cost, 8.89 % in grid electricity consumption, and 4.18 % in total electricity consumption. Furthermore, the strategy effectively reduces renewable energy waste and operation cost at different occupancy rates by 8.02 %–12.21 % and 6.61 %–10.44 %, respectively. Under varying battery capacities, the system demonstrates reductions in renewable energy waste and operation cost by 9.42 %–26.57 % and 6.89 %–10.70 %, confirming the effectiveness of the proposed strategy across different occupancy rates and battery capacities. The research findings further highlight the potential of globally coordinated optimization in the synergy of computing power, electricity, and heat, providing valuable insights for the sustainable development of DCs.}
}
@incollection{HOLLAN199733,
title = {Chapter 2 - Information Visualization},
editor = {Marting G. Helander and Thomas K. Landauer and Prasad V. Prabhu},
booktitle = {Handbook of Human-Computer Interaction (Second Edition)},
publisher = {North-Holland},
edition = {Second Edition},
address = {Amsterdam},
pages = {33-48},
year = {1997},
isbn = {978-0-444-81862-1},
doi = {https://doi.org/10.1016/B978-044481862-1.50068-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444818621500686},
author = {James D. Hollan and Benjamin B. Bederson and Jonathan I. Helfman},
abstract = {Publisher Summary
Computation provides the most plastic representational medium and for that it can be employed to mimic successful mechanisms of earlier media and also enables novel techniques that were not previously possible. Computation-based information presentations promise to dramatically enrich the understandings as well as assist in navigating and effectively exploiting rapidly growing and increasingly complex information collections. This chapter surveys a sample of recent information visualization research. Information visualization has a long history, dating to the earliest forms of symbolic representation, and can be approached from multiple perspectives, ranging across psychology, epistemology, graphic design, linguistics, and semiology to newer perspectives emerging from cognitive science. The goal of this chapter is to provide a glimpse of current research as it attempts to communicate the exciting potential of new dynamic representations. To accomplish this, profiling is done for selected recent work from the research group. This chapter further discusses the beginnings of a paradigm shift for thinking about information, one that starts viewing information as being much more dynamic and reactive to the nature of people's tasks, activities, and even relationships with others.}
}
@article{ADABALA2005896,
title = {From virtualized resources to virtual computing grids: the In-VIGO system},
journal = {Future Generation Computer Systems},
volume = {21},
number = {6},
pages = {896-909},
year = {2005},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2003.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03002899},
author = {Sumalatha Adabala and Vineet Chadha and Puneet Chawla and Renato Figueiredo and José Fortes and Ivan Krsul and Andrea Matsunaga and Mauricio Tsugawa and Jian Zhang and Ming Zhao and Liping Zhu and Xiaomin Zhu},
keywords = {Virtual machines, Grid-computing, Middleware, Virtual data, Network computing},
abstract = {This paper describes the architecture of the first implementation of the In-VIGO grid-computing system. The architecture is designed to support computational tools for engineering and science research In Virtual Information Grid Organizations (as opposed to in vivo or in vitro experimental research). A novel aspect of In-VIGO is the extensive use of virtualization technology, emerging standards for grid-computing and other Internet middleware. In the context of In-VIGO, virtualization denotes the ability of resources to support multiplexing, manifolding and polymorphism (i.e. to simultaneously appear as multiple resources with possibly different functionalities). Virtualization technologies are available or emerging for all the resources needed to construct virtual grids which would ideally inherit the above mentioned properties. In particular, these technologies enable the creation of dynamic pools of virtual resources that can be aggregated on-demand for application-specific user-specific grid-computing. This change in paradigm from building grids out of physical resources to constructing virtual grids has many advantages but also requires new thinking on how to architect, manage and optimize the necessary middleware. This paper reviews the motivation for In-VIGO approach, discusses the technologies used, describes an early architecture for In-VIGO that represents a first step towards the end goal of building virtual information grids, and reports on first experiences with the In-VIGO software under development.}
}
@article{CANCHIG2025100445,
title = {Enhanced selectivity of carbon quantum dots for metal ion detection through surface modification by heteroatom doping: A study on optical properties and theoretical approach},
journal = {Carbon Trends},
volume = {18},
pages = {100445},
year = {2025},
issn = {2667-0569},
doi = {https://doi.org/10.1016/j.cartre.2024.100445},
url = {https://www.sciencedirect.com/science/article/pii/S266705692400124X},
author = {María Belén Cánchig and Floralba López and Zaillmar Morales-Navarro and Alexis Debut and Karla Vizuete and Thibault Terencio and Manuel Caetano and Juan Pablo Saucedo-Vázquez},
keywords = {Carbon quantum dots, Heteroatom-doped, Ion detection, Heavy metals},
abstract = {Water contamination by toxic metal ions has become a significant issue, requiring the development of effective ion detection methods. Traditional analytical techniques often involve toxic elements or complex devices. Carbon quantum dots (CQDs) have emerged as a promising alternative for optic ion detection due to their unique properties and compatibility with living organisms. This study focuses on synthesizing and functionalizing CQDs with various heteroatoms (N, S) to enhance their optical properties and ion selectivity. CQDs were synthesized using citric acid as the carbon source and modified with l-cysteine, ethylenediamine, and diethylenetriamine. The structural and optical properties of the CQDs were determined using several techniques, including FT-IR, TEM, UV–Vis, and Fluorescence Spectroscopy. The results indicate that doping with heteroatoms significantly alters the absorption and emission properties of CQDs. Particularly, nitrogen-doped CQDs (NCQDs) exhibited the highest absorption and emission intensities, making them ideal for sensor applications. The study also demonstrated that functionalization with sulfur could modulate emission frequencies, enhancing the detection capabilities for specific ions. Fluorescence quenching studies revealed that NCQDs and S-CQDs have a high selectivity for Hg²⁺ ions, attributed both electrostatic and covalent interactions formed between the CQDs and Hg²⁺. Computational studies supported these findings, showing that the interaction with Hg²⁺ significantly affects the energy gap of the CQDs, enhancing their sensitivity. This research contributes to the field of environmental monitoring by providing a practical solution for the detection of free metal ions in water through the development of advanced CQD-based sensors.}
}
@article{WESTERBERG2004447,
title = {A retrospective on design and process synthesis},
journal = {Computers & Chemical Engineering},
volume = {28},
number = {4},
pages = {447-458},
year = {2004},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2003.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0098135403002564},
author = {Arthur W Westerberg},
keywords = {Design, Process, Synthesis},
abstract = {We discuss the impact over the past 40 years of process systems thinking on the design of chemical processes. We first explore the rich set of issues related to process design, only some of which are technical. We then briefly examine simulation, optimization and more extensively process synthesis ideas as they relate to design. Throughout we note that this progress is inextricably linked with the development of computer technology.}
}
@article{MUSTAPHA2025103066,
title = {A survey of emerging applications of large language models for problems in mechanics, product design, and manufacturing},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103066},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103066},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007171},
author = {K.B. Mustapha},
keywords = {Pre-trained language models, Large language models, Generative AI, Generative pre-trained transformer, Mechanical engineering, Engineering design, Manufacturing, Mechanics, Intelligent digital twins, Intelligent maintenance, Creativity},
abstract = {In the span of three years, the application of large language models (LLMs) has accelerated across a multitude of professional sectors. Amid this development, a new collection of studies has manifested around leveraging LLMs for segments of the mechanical engineering (ME) field. Concurrently, it has become clear that general-purpose LLMs faced hurdles when deployed in this domain, partly due to their training on discipline-agnostic data. Accordingly, there is a recent uptick of derivative ME-specific LLMs being reported. As the research community shifts towards these new LLM-centric solutions for ME-related problems, the shift compels a deeper look at the diffusion of LLMs in this emerging landscape. Consequently, this review consolidates the diversity of ME-tailored LLMs use cases and identifies the supportive technical stacks associated with these implementations. Broadly, the review demonstrates how various categories of LLMs are re-shaping concrete aspects of engineering design, manufacturing and applied mechanics. At a more specific level, it uncovered emerging LLMs’ role in boosting the intelligence of digital twins, enriching bidirectional communication within the human-cyber-physical infrastructure, advancing the development of intelligent process planning in manufacturing and facilitating inverse mechanics. It further spotlights the coupling of LLMs with other generative models for promoting efficient computer-aided conceptual design, prototyping, knowledge discovery and creativity. Finally, it revealed training modalities/infrastructures necessary for developing ME-specific language models, discussed LLMs' features that are incongruent with typical engineering workflows, and concluded with prescriptive approaches to mitigate impediments to the progressive adoption of LLMs as part of advanced intelligent solutions.}
}
@article{QIAN2023110898,
title = {A novel granular ball computing-based fuzzy rough set for feature selection in label distribution learning},
journal = {Knowledge-Based Systems},
volume = {278},
pages = {110898},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110898},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123006482},
author = {Wenbin Qian and Fankang Xu and Jintao Huang and Jin Qian},
keywords = {Feature selection, Label distribution learning, Granular ball, Fuzzy rough set, Granular computing},
abstract = {Label distribution learning is a widely studied supervised learning diagram that can handle the problem of label ambiguity. The increasing size of datasets is accompanied by the disaster of dimensionality, which implies that the arrival of redundant and noisy features undermines the effect of label distribution learning. As a crucial data-preprocessing technique, feature selection is capable of choosing discriminative features. However, due to the complex issue of label ambiguity, traditional feature selection approaches for datasets with logical labels cannot be applied to label distribution data. In this paper, a novel granular ball computing-based fuzzy rough set (GBFRS) is proposed for label distribution feature selection. Specifically, the proposed method is first introduced at the finest granularity, i.e., calculating similarity relations between single data points. Considering that the label ambiguity issue is exacerbated by the label imbalance phenomenon, the relative similarity in label distribution space among samples is computed for better generalization of the model. Then, a robust approximation strategy is devised for the target sample by using its true different and partially different class samples. Finally, with the concept of granular balls, the method explores the similarity relations between balls and samples, and the granular ball computing-based fuzzy rough set method is developed , which is endowed with the ability to simulate the characteristics of large-scale priorities in human thinking and considers local consistency. Extensive experiments conducted on twenty-two datasets show that GBFRS can effectively select more significant features than seven state-of-the-art feature selection algorithms.}
}
@article{WANG2025101743,
title = {Peeking at low versus high achievers’ problem-solving processes in interactive tasks with multiple items},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101743},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101743},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124002839},
author = {Maohua Wang and Shuai Wang and Yingbin Zhang and Siqi Shen and Shuo Feng},
keywords = {Problem-solving processes, Interactive tasks, Multiple items, Exploration strategies, Navigation strategies},
abstract = {Problem-solving is now emerging as a crucial thinking skill among students. To reflect students’ problem-solving levels, researchers designed a series of interactive tasks, especially tasks with multiple items. Researchers have examined the relationship between achievements and the use of exploration and navigation strategies in such contexts. However, the potential impact of analytical levels (macro versus micro) on problem-solving processes remains unexplored, constraining a comprehensive understanding of their processes. Especially, the difference in how the use of both exploration and navigation strategies evolve between low and high achievers at different analytical levels still needs to be uncovered. As such, our study analyzed log data (i.e., activities and related attributes) of 233 low achievers and 343 high achievers in a task consisting of six successive items at both macro (entire task) and micro (individual item) levels. We harnessed raw log data to generate meaningful insights into students’ problem-solving strategies at both the macro and micro levels, including initial goal-directed, initial non-targeted, and repeated exploration, as well as navigation behavior. The metrics of these behaviors, including behavioral frequencies and patterns, were then examined using independent t-tests and first-order Markov models. Results showed that metrics differentiating achievement levels varied by analytical levels. However, the frequency of initial goal-directed exploration and the pattern of continuous forward behavior appeared to be somewhat context-free, showing differences at both the macro and micro levels. Moreover, problem-solving processes in interactive tasks at the micro level may be linked to differences in item formats, complexity, and nuanced contexts. Our study provides deeper insights into problem-solving processes in more complex contexts, contributing to the development of more targeted tasks, more intelligent assessment and learning systems, and potential support for students’ problem-solving skills.}
}
@article{GAFFLEY2024477,
title = {Survey on the Perceptions of Pregnancy and Parenthood in Trainees: Advances, Obstacles, and Growth Opportunities},
journal = {Journal of Surgical Research},
volume = {295},
pages = {477-486},
year = {2024},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2023.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0022480423005528},
author = {Michaela Gaffley and Sean Hernandez and Katherine M. Riera and Saskia Anzola},
keywords = {Graduate medical education, Parenting, Pregnancy, Residency},
abstract = {Introduction
Despite national policy changes, perspective changes on pregnancy and parenting in training are often lacking. We evaluated current viewpoints regarding pregnancy, parenthood, leave needs, and perceptions of support across trainees at our institution.
Methods
A cross-sectional survey was sent to all residents and fellows at a tertiary care academic center with >700 trainees. Demographic information, opinions on maternity and paternity leave, and opinions on institutional support and career goals were collected. The survey was sent via the Graduate Medical Education Office listserv -- 66 Accreditation Council for Graduate Medical Education (ACGME) programs and 40 non-ACGME programs.
Results
Seven hundred and forty-seven house officers received the survey with a response rate of 21.9% (n = 164). Of respondents, 81% were residents and 99 respondents were female (representing 31% of female trainees at our institution). Thirty-seven point two percent of respondents reported being parents. Twenty-five point three percent of respondents had been pregnant while a trainee with no statistical difference by specialty type (P = 0.0817). Statistically significant difference was noted in having children based on sex with men becoming parents at twice the rate of women (56% vs 26%, P < 0.001). No difference was noted between specialties on perceived support while pregnant and peripartum. Thirty percent of parent respondents reported thinking about leaving medical training after having children given family stressors. Statistical difference in thoughts of leaving medicine overall between females (46%) and males (17.6%; P = 0.0238).
Conclusions
Men and women need support as they navigate becoming parents at a naturally stressful transition period. Females consider leaving medicine at twice the rate of males after becoming parents. Our institution and other ACGME programs need greater transparency and consistent leave practices that reflect changing times.}
}
@article{WHITACRE2019148,
title = {Exploring unfamiliar paths through familiar mathematical territory: Constraints and affordances in a preservice teacher’s reasoning about fraction comparisons},
journal = {The Journal of Mathematical Behavior},
volume = {53},
pages = {148-163},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2018.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0732312317301608},
author = {Ian Whitacre and Şebnem Atabaş and Kelly Findley},
keywords = {Preservice teachers, Fractions, Environment metaphor, Beliefs, Productive disposition},
abstract = {Preservice elementary teachers (PSTs) have been described as having difficulties with fractions, relying on standard procedures, and experiencing math anxiety. We are interested in productive ways in which PSTs can and do use their prior knowledge when exploring unfamiliar paths through familiar mathematical territory. We conducted interviews with PSTs in which we challenged them with various fraction comparison tasks and encouraged them to develop new strategies. In this paper, we present a case study focused on one PST who made considerable progress in her reasoning about fraction comparisons during such an interview. We use Greeno’s (1991) environment metaphor to conceptualize number sense as situated knowing in a conceptual domain. This perspective helps us account for both cognitive and affective factors. We highlight 4 themes concerning features of the mathematical environment that Jennifer (pseudonym) appeared to inhabit during the interview: (a) the interview context created a safe space that emphasized the interviewer’s interest in Jennifer’s ideas, as opposed to correct answers; (b) Jennifer used her prior knowledge of parts and wholes to ground her arguments meaningfully and as building blocks to invent new strategies; (c) she used her prior knowledge of cross multiplication as an established path that provided reassurance and facilitated her exploration of unfamiliar paths; (d) it was beliefs and affective factors, not deficiencies in knowledge, that constrained Jennifer’s exploration of unfamiliar paths through familiar mathematical territory. We discuss the implications of these findings for research concerning PSTs’ mathematical thinking and learning and for mathematics teacher education.}
}
@incollection{CORICELLI2009427,
title = {Chapter 20 - Reward-based emotions: affective evaluation of outcomes and regret learning},
editor = {Jean-Claude Dreher and Léon Tremblay},
booktitle = {Handbook of Reward and Decision Making},
publisher = {Academic Press},
address = {New York},
pages = {427-439},
year = {2009},
isbn = {978-0-12-374620-7},
doi = {https://doi.org/10.1016/B978-0-12-374620-7.00020-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123746207000200},
author = {Giorgio Coricelli and Aldo Rustichini},
abstract = {Publisher Summary
The emotions related to experiencing rewards or punishers are not independent from the outcomes that have not occurred. Indeed, it is the counterfactual reasoning between the obtained and unobtained outcomes that determines the quality and intensity of the emotional response. This chapter concerns the behavioral effects and the neural substrates of a class of reward-based emotions, which are emotions elicited by rewards and punishers. It describes how outcome evaluation is influenced by the level of responsibility in the process of choice (agency) and by the available information regarding alternative outcomes. The data reported in the chapter suggests that cognitive context, exemplified by counterfactual thinking exerts a modulatory influence on the orbitofrontal cortex activation to rewards and punishers. The orbitofrontal cortex is also critically involved in learning in environments where the information about the rewards of the alternative foregone actions is available. These processes are addressed in humans, both in the context of normal and altered brain functions.}
}
@article{SIMONE2021103070,
title = {Rome was not built in a day. Resilience and the eternal city: Insights for urban management},
journal = {Cities},
volume = {110},
pages = {103070},
year = {2021},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2020.103070},
url = {https://www.sciencedirect.com/science/article/pii/S0264275120314189},
author = {Cristina Simone and Francesca Iandolo and Irene Fulco and Francesca Loia},
keywords = {Rome, Urban resilience, Urban management, Aspect-based sentiment analysis (ABSA), Collective perception},
abstract = {Resilience has been intensely investigated as the viable quality of individuals, groups, organizations, and systems to respond productively to notable change without engaging in an extended period of regressive behaviour. Recently, there has been growing attention to the relationship between resilience and cities. To contribute to this stimulating debate, this paper first provides the theoretical framework and links the concept of resilience to urban studies. Subsequently, it enlightens, through a systems perspective and the aspect-based sentiment analysis (ABSA) methodology, the possibility to enrich the information variety endowment of urban policymakers, generated by new information units, to foster resilience capabilities in the urban context. Specifically, a large-scale text analysis study was conducted on the city of Rome to understand the sentiments expressed within the text generated online by citizens and visitors. The positive or negative sentiments linked to the hidden problems of the urban context were organized within collective perception-based maps for each of the analysed points of interest (POIs). Since cities represent complex decision-making contexts, this study aimed to outline a methodology and a tool that would help foster resilient thinking in urban policies by enriching the diversity of the information variety endowment of urban decision-makers.}
}
@article{FLORES201825,
title = {Problem-based science, a constructionist approach to science literacy in middle school},
journal = {International Journal of Child-Computer Interaction},
volume = {16},
pages = {25-30},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300417},
author = {Christa Flores},
keywords = {Curriculum design, Design science, Learning spaces design, Science literacy, Maker education, Mindsets, Problem-based science, Constructionism, Constructivism, Inclusivity},
abstract = {This paper describes a four-year observation using a model designed and tested in a middle school maker space, called problem-based science (PbS). PbS was used as the primary model for a middle school science curriculum adapted by the tools and mindsets of the maker movement. PbS is learning through inventing and problem solving — while using the latest in fabrication technology, like 3D printers and laser cutters, as well as more traditional making skills, like electronics, robotics, sewing and carpentry. PbS is based on Seymour Papert’s constructionism, set to a science curriculum taught full time in a makerspace or fablab. Bridging ideas in design thinking, maker education, and applied math and science, the term problem-based science was used to describe how learning would look, sound, and feel different in a makerspace, when a focus was on learner-centered curriculum. The design and testing of this curriculum took place as part of the 5th and 6th grade science courses offered at a private (non-public) school in California (USA) the fall of 2012, through the spring of 2016. Through daily formative assessment, as well as exit surveys, the patterns and benefits of learning in a self-directed learning space, designed for constructionism, were observed. This paper shares the highlights of those years. Video taped exit surveys conducted by the author, show that self-direction is both challenging and rewarding, students often felt trusted and respected, even if they did not always feel supported in a manner common in a more teacher directed classroom setting. Daily informal classroom observations revealed that using student driven, open-ended problem solving, rather than a 100% teacher led, step by step lab, lends to a more diverse pool of leadership practice in students and higher engagement in hard problems. Students typically seen as struggling in traditional classrooms, identified as experts and successful learners in this setting. Lastly, using PbS as a model for science literacy allows the youngest of learners to practice mindsets and habits typical of real scientists and inventors, fostering early identify formation in STEM fields.}
}
@article{GUAN2022256,
title = {AFE-CNN: 3D Skeleton-based Action Recognition with Action Feature Enhancement},
journal = {Neurocomputing},
volume = {514},
pages = {256-267},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222012784},
author = {Shannan Guan and Haiyan Lu and Linchao Zhu and Gengfa Fang},
keywords = {3D Skeleton, Action Recognition, Feature Enhance, Attention},
abstract = {Existing 3D skeleton-based action recognition approaches reach impressive performance by encoding handcrafted action features to image format and decoding by CNNs. However, such methods are limited in two ways: a) the handcrafted action features are difficult to handle challenging actions, and b) they generally require complex CNN models to improve action recognition accuracy, which usually occur heavy computational burden. To overcome these limitations, we introduce a novel AFE-CNN, which devotes to enhance the features of 3D skeleton-based actions to adapt to challenging actions. We propose feature enhance modules from key joint, bone vector, key frame and temporal perspectives, thus the AFE-CNN is more robust to camera views and body sizes variation, and significantly improve the recognition accuracy on challenging actions. Moreover, our AFE-CNN adopts a light-weight CNN model to decode images with action feature enhanced, which ensures a much lower computational burden than the state-of-the-art methods. We evaluate the AFE-CNN on three benchmark skeleton-based action datasets: NTU RGB + D, NTU RGB + D 120, and UTKinect-Action3D, with extensive experimental results demonstrate our outstanding performance of AFE-CNN.}
}
@article{LI2025101851,
title = {The effects of school climate on students' creativity:The mediating role of growth mindset and self-efficacy},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101851},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101851},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125001002},
author = {Zhenyu Li and Qiong Li},
keywords = {school climate, creativity, growth mindset, self-efficacy},
abstract = {The influence of school climate on students' creativity has garnered significant attention, yet the underlying mechanisms remain underexplored. This study investigates the mediating roles of growth mindset and self-efficacy in the relationship between school climate and creativity among 10- and 15-year-old Chinese students. Data were collected from 7,246 students across 150 schools in Suzhou, China, as part of the Survey on Social and Emotional Skills (SSES). The findings revealed that peer support significantly enhanced students' self-reported creativity, whereas teacher support did not directly influence it. However, teacher support positively affected teachers' and parents' evaluations of students' creativity. Furthermore, growth mindset and self-efficacy served as significant mediators, forming a chain mediation pathway that links school climate to creativity. These results underscore the importance of fostering a supportive educational environment that promotes both psychological growth and creative expression. The study provides valuable insights for educators and policymakers aiming to enhance students' creative capabilities through targeted interventions that improve school climate and develop growth mindset and self-efficacy.}
}
@incollection{ELYAS202357,
title = {Chapter 3 - Physical property estimation and phase behavior for process simulation∗},
editor = {Dominic C.Y. Foo},
booktitle = {Chemical Engineering Process Simulation (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {57-86},
year = {2023},
isbn = {978-0-323-90168-0},
doi = {https://doi.org/10.1016/B978-0-323-90168-0.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323901680000056},
author = {Rafil Elyas},
keywords = {Enthalpy, Entropy, Equations of state, Property estimation methods, Separator, Work},
abstract = {Like the foundation of a building, the methods used for physical property estimation determine the integrity of a chemical engineering computation. These days, most engineers rely on commercial simulators to perform their computations, and all commercial simulators these days come with a myriad of property packages, where various property estimation methods have been combined into property packages such as Peng–Robinson, Soave–Redlich–Kwong, BWRS, Grayson–Streed, Braun-K10, nonrandom two liquid, UNIQUAC, and the list goes on. It is critical to know which property package would be applicable for one's computation. The objective of this chapter is to provide some insight into the workings of those property packages and enable the reader to make the correct selection.}
}
@article{WOLFENGAGEN2016347,
title = {Evolutionary Domains for Varying Individuals},
journal = {Procedia Computer Science},
volume = {88},
pages = {347-352},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.447},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317033},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov and Viacheslav V. Navrotskiy and Sergey I. Kukalev and Alexander A. Zuev and Polina V. Belyatskaya},
keywords = {computational model, variable domains, individual migration, tangled individuals},
abstract = {The domains ranged by the variables using Web-resources can vary with a time. This is possible even in a runtime of Web-application giving rise to various vulnerabilities and bugs. This paper focuses at the problem mentioned as the individual migration in a problem domain. There is a lack of computational models which operate in an environment of variable domains and the contribution is to develop such a model. The advance is in establishing the mechanism for driving the dynamics of the sets and individuals. As a consequence, the behavior of the variables in query logical expression becomes predictable suppressing the possible semantic instability.}
}
@incollection{HARITASHYA20221,
title = {4.01 - The Development, History and Future of Cryospheric Geomorphology},
editor = {John (Jack) F. Shroder},
booktitle = {Treatise on Geomorphology (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {1-19},
year = {2022},
isbn = {978-0-12-818235-2},
doi = {https://doi.org/10.1016/B978-0-12-818234-5.00181-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128182345001814},
author = {Umesh K. Haritashya and Jon Harbor and Hugh French},
keywords = {Cold regions geomorphology, Cryosphere, Geocryology, Glacial geomorphology, Glaciology, Permafrost, Process geomorphology, Quaternary science},
abstract = {The cryosphere is a broadly defined term associated with areas where water is in solid form. Thus, cryospheric geomorphology, in theory, should include polar and mountain regions, the arctic, ice, sea ice, glaciers, rock glaciers, snow, permafrost, ice shelves and icebergs, karst-glacial interactions, and even planetary cryosphere. No book can completely justify including all these areas/topics. In this treatise on geomorphology, the focus is primarily on conventional and applied glacial geomorphology and periglacial geomorphology with a rich history and promising future. Glacial geomorphology, for example, rose to prominence in debate surrounding the theory of Ice Ages. Detailed descriptions and novel measurements of processes and landforms and now high-end computing facilities led to sophisticated process-form modeling. Current emphases include interactions between glacial and other processes in development of mountain belts, natural hazards, hydrological interplay, and responses to climate change. Periglacial geomorphology begins with Walery von Lozinski and the IGS Spitzbergen excursion, 1910–11, followed by it becoming a descriptive branch of European-dominated climatic geomorphology with a growing emphasis on quantitative studies by the 1960s. More recently, the emergence of geocryology, cold-regions engineering, and sophisticated Quaternary studies is dominating many aspects of basic and applied periglacial geomorphology. The advent of high-resolution satellite and drone images, digital elevation models, and machine learning and large-scale data computational techniques are now leading the discovery process for cryospheric geomorphology.}
}
@article{KLATZMANN2025115372,
title = {A dynamic bifurcation mechanism explains cortex-wide neural correlates of conscious access},
journal = {Cell Reports},
volume = {44},
number = {3},
pages = {115372},
year = {2025},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2025.115372},
url = {https://www.sciencedirect.com/science/article/pii/S2211124725001433},
author = {Ulysse Klatzmann and Sean Froudist-Walsh and Daniel P. Bliss and Panagiota Theodoni and Jorge Mejías and Meiqi Niu and Lucija Rapan and Nicola Palomero-Gallagher and Claire Sergent and Stanislas Dehaene and Xiao-Jing Wang},
keywords = {consciousness, large-scale brain model, connectome, NMDA, AMPA, feedforward, feedback, computational model, ignition, global neuronal workspace, access consciousness},
abstract = {Summary
Conscious access is suggested to involve “ignition,” an all-or-none activation across cortical areas. To elucidate this phenomenon, we carry out computer simulations of a detection task using a mesoscale connectome-based model for the multiregional macaque cortex. The model uncovers a dynamic bifurcation mechanism that gives rise to ignition in a network of associative regions. A hierarchical N-methyl-D-aspartate (NMDA)/α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) receptor gradient plays a critical role: fast AMPA receptors drive feedforward signal propagation, while slow NMDA receptors in feedback pathways shape and sustain the ignited network. Intriguingly, the model suggests higher NMDA-to-AMPA receptor ratios in sensory areas compared to association areas, a prediction supported by in vitro autoradiography data. Furthermore, the model accounts for diverse behavioral and physiological phenomena linked to consciousness. This work sheds light on how receptor gradients along the cortical hierarchy enable distributed cognitive functions and provides a biologically constrained computational framework for investigating the neurophysiological basis of conscious access.}
}
@article{MILLET2023107707,
title = {Defending humankind: Anthropocentric bias in the appreciation of AI art},
journal = {Computers in Human Behavior},
volume = {143},
pages = {107707},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107707},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223000584},
author = {Kobe Millet and Florian Buehler and Guanzhong Du and Michail D. Kokkoris},
keywords = {Anthropocentrism, Speciesism, Artificial intelligence (AI), Computational creativity, Computer-generated art, Awe},
abstract = {We argue that recent advances of artificial intelligence (AI) in the domain of art (e.g., music, painting) pose a profound ontological threat to anthropocentric worldviews because they challenge one of the last frontiers of the human uniqueness narrative: artistic creativity. Four experiments (N = 1708), including a high-powered preregistered experiment, consistently reveal a pervasive bias against AI-made artworks and shed light on its psychological underpinnings. The same artwork is preferred less when labeled as AI-made (vs. human-made) because it is perceived as less creative and subsequently induces less awe, an emotional response typically associated with the aesthetic appreciation of art. These effects are more pronounced among people with stronger anthropocentric creativity beliefs (i.e., who believe that creativity is a uniquely human characteristic). Systematic depreciation of AI-made art (assignment of lower creative value, suppression of emotional reactions) appears to serve a shaken anthropocentric worldview whereby creativity is exclusively reserved for humans.}
}
@article{DOU2021103147,
title = {Enhancing higher-order eigenmodes of AFM using bridge/cantilever coupled system},
journal = {Micron},
volume = {150},
pages = {103147},
year = {2021},
issn = {0968-4328},
doi = {https://doi.org/10.1016/j.micron.2021.103147},
url = {https://www.sciencedirect.com/science/article/pii/S0968432821001384},
author = {Zhipeng Dou and Jianqiang Qian and Yingzi Li and Rui Lin and Tingwei Wang and Jianhai Wang and Peng Cheng and Zeyu Xu},
keywords = {Atomic force microscopy, Multi-frequency, Transfer function, Higher-order eigenmodes, Finite element simulation},
abstract = {The wide application of multi-frequency atomic force microscopy (AFM) places higher demands on the higher-order modes response of the cantilever. The response of the higher modes however is generally weaker than that of the fundamental mode in air. Researchers have proposed many methods, most of which involve cantilever modification, to enhance higher-order eigenmodes response. These previous results are proved to be effective, but the microfabrication is expensive. In this article, we propose a novel model based on bridge/cantilever coupled system to enhance the higher-order modes response of AFM cantilever. The segmented beam model provides a new thinking to explain the appearance of undesired peaks in mode analysis of cantilever. Through theoretical analysis and simulation, we find that higher resonance modes are enhanced by tuning the bridge to match the high resonances of the single clamped cantilever. The length, thickness of the coupled system and the location of excitation can affect the enhancement. In summary, this model provides a new way to improve higher mode response for multi-frequency and other high bandwidth applications of AFM.}
}
@article{KIRSCHNER2017135,
title = {The myths of the digital native and the multitasker},
journal = {Teaching and Teacher Education},
volume = {67},
pages = {135-142},
year = {2017},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2017.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X16306692},
author = {Paul A. Kirschner and Pedro {De Bruyckere}},
keywords = {Digital native, Multitasking, Homo zappiëns, Educational reform},
abstract = {Current discussions about educational policy and practice are often embedded in a mind-set that considers students who were born in an age of omnipresent digital media to be fundamentally different from previous generations of students. These students have been labelled digital natives and have been ascribed the ability to cognitively process multiple sources of information simultaneously (i.e., they can multitask). As a result of this thinking, they are seen by teachers, educational administrators, politicians/policy makers, and the media to require an educational approach radically different from that of previous generations. This article presents scientific evidence showing that there is no such thing as a digital native who is information-skilled simply because (s)he has never known a world that was not digital. It then proceeds to present evidence that one of the alleged abilities of students in this generation, the ability to multitask, does not exist and that designing education that assumes the presence of this ability hinders rather than helps learning. The article concludes by elaborating on possible implications of this for education/educational policy.}
}
@article{2016940,
title = {Anne Churchland},
journal = {Neuron},
volume = {92},
number = {5},
pages = {940-942},
year = {2016},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2016.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0896627316308662},
abstract = {Anne Churchland’s scientific experience has focused on understanding the neural circuits behind multisensory decision making. In an interview with Neuron, she discusses large-scale recordings in behaving animals, communication between experimental and theoretical labs, and the creation of her website anneslist.net to highlight women in systems and computational neuroscience in an effort to help close the gender gap in conference speakers.}
}
@article{PALANIYAPPAN2023994,
title = {Studying Psychosis Using Natural Language Generation: A Review of Emerging Opportunities},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {8},
number = {10},
pages = {994-1004},
year = {2023},
note = {Natural Language Processing in Psychiatry and Clinical Neuroscience Research},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2023.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S2451902223001040},
author = {Lena Palaniyappan and David Benrimoh and Alban Voppel and Roberta Rocca},
keywords = {Computational psychiatry, Deep learning, Explainable models, Large language models, Neural networks, Neuroimaging},
abstract = {Disrupted language in psychotic disorders, such as schizophrenia, can manifest as false contents and formal deviations, often described as thought disorder. These features play a critical role in the social dysfunction associated with psychosis, but we continue to lack insights regarding how and why these symptoms develop. Natural language generation (NLG) is a field of computer science that focuses on generating human-like language for various applications. The theory that psychosis is related to the evolution of language in humans suggests that NLG systems that are sufficiently evolved to generate human-like language may also exhibit psychosis-like features. In this conceptual review, we propose using NLG systems that are at various stages of development as in silico tools to study linguistic features of psychosis. We argue that a program of in silico experimental research on the network architecture, function, learning rules, and training of NLG systems can help us understand better why thought disorder occurs in patients. This will allow us to gain a better understanding of the relationship between language and psychosis and potentially pave the way for new therapeutic approaches to address this vexing challenge.}
}
@article{MELGAREJO2025121371,
title = {Optimization test function synthesis with generative adversarial networks and adaptive neuro-fuzzy systems},
journal = {Information Sciences},
volume = {686},
pages = {121371},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121371},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524012854},
author = {Miguel Melgarejo and Mariana Medina and Juan Lopez and Angie Rodriguez},
keywords = {Optimization test functions, Generative adversarial networks, Adaptive neuro-fuzzy systems, Fuzzy basis function expansion, Symbolic regression},
abstract = {This paper presents an approach to synthesizing optimization test functions that couples generative adversarial networks and adaptive neuro-fuzzy systems. A generative adversarial network produces optimization landscapes from a database of known optimization test functions, and an adaptive neuro-fuzzy system performs regression on the generated landscapes to provide closed-form expressions. These expressions can be implemented as fuzzy basis function expansions. Eight databases of two-dimensional optimization landscapes reported in the literature are used to train the generative network. Exploratory landscape analysis over the generated samples reveals that the network can lead to new optimization landscapes with features of interest. In addition, fuzzy basis function expansions provide the best approximation results when compared against two symbolic regression frameworks over several selected landscapes. Examples are used to illustrate the ability of these functions to model complex surface artifacts such as plateaus. The proposed approach can be used as a mathematical collaboration tool that couples generative artificial and computational intelligence techniques to formulate high-dimensional optimization test problems from two-dimensional synthesized functions.}
}
@incollection{HALLGRIMSSON20051,
title = {CHAPTER 1 - Variation and Variability: Central Concepts in Biology},
editor = {Benedikt Hallgrímsson and Brian K. Hall},
booktitle = {Variation},
publisher = {Academic Press},
address = {Burlington},
pages = {1-7},
year = {2005},
isbn = {978-0-12-088777-4},
doi = {https://doi.org/10.1016/B978-012088777-4/50003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012088777450003X},
author = {Benedikt Hallgrímsson and Brian K. Hall},
abstract = {Publisher Summary
Variation is a central topic, both conceptually and historically in evolutionary biology. Phenotypic variation was Darwin's fundamental observation. Indeed, the first two chapters of On the Origin of Species deal explicitly with variation. Variation within and among species has certainly been as central to the thinking of Ernst Mayr (1963) as it was to the thinking of Sewall Wright (1968), two of the fathers of the modern synthesis. However, the study of variability or the propensity to vary, with few exceptions, has remained peripheral to study of the mechanisms of evolutionary change at any level of the biological hierarchy. Although implicit in virtually all research in the biological sciences, whether one is seeking understanding at the genetic, developmental, organismal, species, population, or ecologic/community levels, variation is seldom treated as a subject in and of itself. Variation is an extremely broad topic, and a modern treatment of this subject is not possible without a thematic focus. This chapter introduces this theme through both a hierarchical treatment and integrative approaches that point toward new directions of research.}
}
@article{WINSTON201292,
title = {The next 50years: A personal view},
journal = {Biologically Inspired Cognitive Architectures},
volume = {1},
pages = {92-99},
year = {2012},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2012.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X12000035},
author = {Patrick Henry Winston},
keywords = {Biologically inspired cognitive models, Human intelligence, Evolution of intelligence, Inner language, Story understanding, Directed perception},
abstract = {I review history, starting with Turing’s seminal paper, reaching back ultimately to when our species started to outperform other primates, searching for the questions that will help us develop a computational account of human intelligence. I answer that the right questions are: What’s different between us and the other primates and what’s the same. I answer the what’s different question by saying that we became symbolic in a way that enabled story understanding, directed perception, and easy communication, and other species did not. I argue against Turing’s reasoning-centered suggestions, offering that reasoning is just a special case of story understanding. I answer the what’s the same question by noting that our brains are largely engineered in the same exotic way, with information flowing in all directions at once. By way of example, I illustrate how these answers can influence a research program, describing the Genesis system, a system that works with short summaries of stories, provided in English, together with low-level common-sense rules and higher-level concept patterns, likewise expressed in English. Genesis answers questions, notes abstract concepts such as revenge, tells stories in a listener-aware way, and fills in story gaps using precedents. I conclude by suggesting, optimistically, that a genuine computational theory of human intelligence will emerge in the next 50years if we stick to the right, biologically inspired questions, and work toward biologically informed models.}
}
@article{GAO2024104747,
title = {Representing and assessing distributed situation awareness in multi-agency disaster response: A hypergraph-based methodology},
journal = {International Journal of Disaster Risk Reduction},
volume = {111},
pages = {104747},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104747},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924005090},
author = {Chong Gao and Hui Jiang and Xiaoling Guo},
keywords = {Distributed situation awareness, Systems thinking, Higher-order interactions, Multi-agency response},
abstract = {This paper introduces a novel hypergraph-based methodology for representing and assessing distributed situation awareness (DSA) in multi-agency disaster response. The fundamental ideas and motivations of our methodology stem from the following widely acknowledged understandings and phenomenons: (a) DSA’s representation should be approached from social, information and task dimensions; (b) DSA is one of the collective behaviors that emerge from the interactions; (c) the interactions in the real world are not pairwise. Our methodology delineates the collaboration, co-activation, and co-existence interactions among social, information, and task elements as higher-order interactions. We then construct these interaction systems using hypergraph-structured data derived from disaster response scenarios. Subsequently, these systems are encoded into hypergraphs, which are validated against our dataset and proven to be practical tools for depicting higher-order interaction patterns. Analytical techniques tailored to hypergraphs are applied, yielding insights intrinsic to hypergraphs regarding DSA in emergency response. Moreover, we integrate these interaction systems into a comprehensive framework that allows for the visualization and quantitative analyses of DSA evolution dynamics. We propose several indicators of evolution, discussing their trends and implications throughout the development of the emergency response. We locate the system deficiencies by revealing a mismatch between the positions of specific elements in the network and their functions. We also identify the saturation phase in the DSA evolution process.}
}
@incollection{VODOVOTZ20153,
title = {Chapter 1.1 - Interesting Times: The Translational Dilemma and the Need for Translational Systems Biology of Inflammation},
editor = {Yoram Vodovotz and Gary An},
booktitle = {Translational Systems Biology},
publisher = {Academic Press},
address = {Boston},
pages = {3-8},
year = {2015},
isbn = {978-0-12-397884-4},
doi = {https://doi.org/10.1016/B978-0-12-397884-4.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012397884400001X},
author = {Yoram Vodovotz and Gary An},
keywords = {Inflammation, translational research, Translational Dilemma, Translational Systems Biology, computational modeling},
abstract = {Inflammation and critical illness are the final common pathway for many diseases, many of them terminal, and for which there are essentially no medicines. We suggest that this failing is symptomatic of a fragmented continuum of health care and biomedical research, with the primary issue being the inability to translate basic science research into treatments effectively and efficiently, termed the Translational Dilemma. We assert that this present, sad state is due to numerous deficiencies in the way biomedical research is carried out. Accentuating the problem is the fact that the Translational Dilemma is most pronounced with respect to diseases, such as critical illness, that manifest features of so-called complex systems. To address these problems and thereby help alleviate the Translational Dilemma, we have used computational modeling with an explicitly applied focus on generating clinically actionable knowledge. We call this approach Translational Systems Biology. This investigative strategy is predicated on the use of dynamic computational modeling and associated computational methods of data analysis and aggregation to accelerate the Scientific Cycle with an explicit target of generating clinically actionable knowledge.}
}
@article{CARAYON2010657,
title = {Human factors in patient safety as an innovation},
journal = {Applied Ergonomics},
volume = {41},
number = {5},
pages = {657-665},
year = {2010},
note = {Human Factors and Ergonomics in Patient Safety},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2009.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0003687009001719},
author = {Pascale Carayon},
keywords = {Human factors and ergonomics, Patient safety, Healthcare, Innovation, Adoption, Dissemination, Diffusion, Implementation},
abstract = {The use of Human Factors and Ergonomics (HFE) tools, methods, concepts and theories has been advocated by many experts and organizations to improve patient safety. To facilitate and support the spread of HFE knowledge and skills in healthcare and patient safety, we propose to conceptualize HFE as innovations whose diffusion, dissemination, implementation and sustainability need to be understood and specified. Using Greenhalgh et al. (2004) model of innovation, we identified various factors that can either hinder or facilitate the spread of HFE innovations in healthcare organizations. Barriers include lack of systems thinking, complexity of HFE innovations and lack of understanding about the benefits of HFE innovations. Positive impact of HFE interventions on task performance and the presence of local champions can facilitate the adoption, implementation and sustainability of HFE innovations. This analysis concludes with a series of recommendations for HFE professionals, researchers and educators.}
}
@article{KRAUZLIS2014457,
title = {Attention as an effect not a cause},
journal = {Trends in Cognitive Sciences},
volume = {18},
number = {9},
pages = {457-464},
year = {2014},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2014.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364661314001296},
author = {Richard J. Krauzlis and Anil Bollimunta and Fabrice Arcizet and Lupeng Wang},
keywords = {attention, basal ganglia, decision making, learning, perception, superior colliculus},
abstract = {Attention is commonly thought to be important for managing the limited resources available in sensory areas of the neocortex. Here we present an alternative view that attention arises as a byproduct of circuits centered on the basal ganglia involved in value-based decision making. The central idea is that decision making depends on properly estimating the current state of the animal and its environment and that the weighted inputs to the currently prevailing estimate give rise to the filter-like properties of attention. After outlining this new framework, we describe findings from physiological, anatomical, computational, and clinical work that support this point of view. We conclude that the brain mechanisms responsible for attention employ a conserved circuit motif that predates the emergence of the neocortex.}
}
@article{GOLCUK2022159,
title = {An interval type-2 fuzzy axiomatic design method: A case study for evaluating blockchain deployment projects in supply chain},
journal = {Information Sciences},
volume = {602},
pages = {159-183},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.04.034},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522003802},
author = {İlker Gölcük},
keywords = {Blockchain technology, Fuzzy subsethood, Axiomatic design, Best-worst method, Interval type-2 fuzzy sets},
abstract = {This study is concerned with the development of the axiomatic design (AD) method under an interval type-2 fuzzy (IT2F) environment and its application in evaluating blockchain deployment projects in supply chains. Blockchain is a transformative technology that has received significant attention recently. Blockchain technology can process various business transactions by offering a reliable and decentralized infrastructure. Supply chain management is an important application area of blockchains due to its desirable properties, including data security, extended visibility, product traceability, digitalization, and disintermediation. Since blockchain technologies are in their infancy, adopting them to supply chains requires proper design methodologies. Fuzzy AD offers valuable computational mechanisms to evaluate design options in the presence of functional requirements. However, extending AD to different fuzzy extensions is not an easy task, and area-based calculations hinder its widespread applicability. In this study, an IT2F-AD method is developed based on the concept of fuzzy subsethood. The potential of the fuzzy subsethood measure as the main computation engine within type-1 and IT2F-AD is demonstrated. Finally, an integrated multiple criteria decision-making (MCDM) model is proposed by using IT2F Best-Worst Method (IT2F-BWM) and IT2F-AD. The proposed model is used to prioritize blockchain deployment projects in a real-life case study.}
}
@article{KECECI2021100386,
title = {A mixed integer programming formulation for Smashed Sums puzzle: Generating and solving problem instances},
journal = {Entertainment Computing},
volume = {36},
pages = {100386},
year = {2021},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2020.100386},
url = {https://www.sciencedirect.com/science/article/pii/S187595212030094X},
author = {Barış Keçeci},
keywords = {Smashed Sums, Sudoku, Mathematical formulation},
abstract = {Playing mind games and puzzles has 2500 years of known history. Puzzles and games constitute a research domain that is attracting the interest of scientists from numerous disciplines such as artificial and computational intelligence, neural networks etc. All types of puzzles and games contain their own logic and mathematics. Able to know the science behind them and modelling the logic that a person uses to solve them would shed light to some decisional concepts. This is particularly true from the perspective of computational intelligence. In this paper a logic-based puzzle game called Smashed Sums is considered. The binary integer linear programming formulation is proposed to use in solving and generating the puzzles. Illustrative examples are given to show the validity of the formulation. Some experimental computations are conducted to analyze the puzzle and its complexity. And several open problems are concluded for the further researches.}
}
@article{LEVIAKANGAS2025102824,
title = {Towards smart, digitalised rural regions and communities – Policies, best practices and case studies},
journal = {Technology in Society},
volume = {81},
pages = {102824},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102824},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000144},
author = {Pekka Leviäkangas and Signe Sønvisen and Diego Casado-Mansilla and Marius Mikalsen and Andrea Cimmino and Anastassios Drosou and Shahid Hussain},
abstract = {Rural communities and regions face specific challenges in terms of thin markets, low population density, and long distances. Also, the demographics of these communities are often skewed towards the elderly, and the socioeconomics is characterized by higher share of low-income populations. While the concept of urban smart communities is quite well established, such as Smart Cities, the concept of smart rural region communities is only beginning to gain scholarly attention. Smart rural communities can be understood as rural areas and communities that build on their existing strengths and assets as well as on developing new opportunities based on the aforementioned. Traditional and new networks and services can be improved by utilizing digital telecommunication technologies, innovations, and better use of data and knowledge to benefit the communities. Investing in both physical and digital connectivity, and building digital environments for innovative services, economic sustainability, jobs, and social capital can be enhanced, thus contributing to active and live rural communities. Consequently, the development of smart rural communities and regions begins to emerge in research. What is becoming evident is that achieving the ambitions of smart rural communities requires not only digital technologies but also innovation of commercial and social services, as well as better digital capabilities and skills to bridge the existing – and in places the widening - divide between rural and urban communities.}
}
@article{NABORS2003133,
title = {From fractions to proportional reasoning: a cognitive schemes of operation approach},
journal = {The Journal of Mathematical Behavior},
volume = {22},
number = {2},
pages = {133-179},
year = {2003},
note = {Fractions, ratio and proportional reasoning, Part A},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(03)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S073231230300018X},
author = {Wanda K Nabors},
keywords = {Fractions, Proportional reasoning, Teaching experiment, Cognitive schemes},
abstract = {Four seventh grade students participated in a constructivist teaching experiment in which manipulatives within a computer microworld were used to solve fractional reasoning tasks followed by tasks that involve concepts of rate, ratio and proportion. Through a retrospective analysis of video tapes, their thinking processes were analyzed from the perspective of the types of cognitive schemes of operation used as they engaged in the given problem situations. One result of the study indicates that the modifications of the students’ available schemes of operation when solving the fractional reasoning tasks formed a basis for the cognitive schemes of operation used in their solutions of tasks involving proportionality.}
}
@article{JIAQI2024109752,
title = {Decomposed-coordinated framework with intelligent extremum network for operational reliability analysis of complex system},
journal = {Reliability Engineering & System Safety},
volume = {242},
pages = {109752},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109752},
url = {https://www.sciencedirect.com/science/article/pii/S095183202300666X},
author = {Liu Jia-Qi and Feng Yun-Wen and Lu Cheng and Pan Wei-Huang},
keywords = {Machine learning method, System operational reliability, Decomposed-coordinated surrogate model, Multi-failure mode, Approximate modeling},
abstract = {The analysis of operational reliability in complex systems, which involve numerous subsystems and multiple disciplines, presents significant computational challenges due to their highly nonlinear, transient nature and the presence of many hyperparameters. Although reliability analysis models have made progress, they are still inadequate for accurately modeling composite functions with multiple sublayers and sub-functions. To improve the performance of modeling composite functions, the decomposed-coordinated intelligent extremum network model (DC-IENM) is proposed in this paper. The present study employs the decomposed-coordinated (DC) strategy as a means to effectively address the coordination relationship among multiple analysis objectives. To assess the efficacy of the proposed approach, two illustrative examples are considered: (1) the approximate and probabilistic analysis of a nonlinear function with multiple responses, and (2) the reliability analysis of civil aircraft brake system temperature. These examples serve to demonstrate the effectiveness of the developed DC-IENM. Furthermore, the modeling and simulation properties are rigorously examined by means of a comparative analysis involving various methodologies. The obtained results unequivocally indicate that the proposed DC-IENM exhibits distinct advantages in terms of both computational efficiency and precision.}
}
@article{MAIR201646,
title = {Briefing: Advanced sensing technologies for structural health monitoring},
journal = {Proceedings of the Institution of Civil Engineers - Forensic Engineering},
volume = {169},
number = {2},
pages = {46-49},
year = {2016},
issn = {2043-9903},
doi = {https://doi.org/10.1680/jfoen.16.00013},
url = {https://www.sciencedirect.com/science/article/pii/S2043990316000119},
author = {Robert J. Mair},
keywords = {buildings, structures & design, diaphragm & in situ walls, field testing & monitoring},
abstract = {The engineering, management, maintenance and upgrading of infrastructure requires fresh thinking to minimise the use of materials, energy and labour while still ensuring resilience. This can only be achieved by a full understanding of the performance of the infrastructure, both during its construction and throughout its design life, through the application of innovative sensor technologies and other emerging technologies. This approach covers the design and commissioning, construction process, exploitation and use and eventual decommissioning. Crucial elements of these emerging technologies are the innovative application of the latest sensor technologies, data management tools, manufacturing processes and supply chain management processes to the construction industry, both during infrastructure construction and throughout its design life. In particular, advances in sensing technologies such as fibre-optic sensors and wireless sensor networks for structural health monitoring have a huge potential to transform the approaches to the design, the construction and the operation of an infrastructure. This briefing article gives some examples of the recent application of these advanced sensing technologies to structural health monitoring for a large number of construction sites and existing infrastructure.}
}
@article{GUO2023100142,
title = {Advances in biorenewables-resource-waste systems and modelling},
journal = {Carbon Capture Science & Technology},
volume = {9},
pages = {100142},
year = {2023},
issn = {2772-6568},
doi = {https://doi.org/10.1016/j.ccst.2023.100142},
url = {https://www.sciencedirect.com/science/article/pii/S2772656823000465},
author = {Miao Guo and Chunfei Wu and Stephen Chapman and Xi Yu and Tom Vinestock and Astley Hastings and Pete Smith and Nilay Shah},
keywords = {Biomass, Biorenewable, Mathematical optimisation, Process design, Modelling advances},
abstract = {The transformation to a resource-circular bio-economy offers a mechanism to mitigate climate change and environmental degradation. As advanced bioeconomy components, biorenewables derived from terrestrial, aquatic biomass and waste resources are expected to play significant roles over the next decades. This study provides an overview of potential biomass resources ranging from higher plant species to phototrophic microbial cluster, and their fundamental photosynthesis processes as well as biogeochemical carbon cycles involved in ecosystems. The review reflects empirical advances in conversion technologies and processes to manufacture value-added biorenewables from biomass and waste resources. The nexus perspective of resource-biorenewable-waste has been analysed to understand their interdependency and wider interaction with environmental resources and ecosystems. We further discussed the systems perspectives of biorenewables to develop fundamental understanding of resource flows and carbon cycles across biorenewable subsystems and highlight their spatial and temporal variability. Our in-depth review suggested the system challenges of biorenewable, which are subject to nonlinearity, variability and complexity. To unlock such system complexity and address the challenges, a whole systems approach is necessary to develop fundamental understanding, design novel biorenewable solutions. Our review reflects recent advances and prospects of computational methods for biorenewable systems modelling. This covers the development and applications of first principle models, process design, quantitative evaluation of sustainability and ecosystem services and mathematical optimisation to improve design, operation and planning of processes and develop emerging biorenewable systems. Coupling these advanced computational methods, a whole systems approach enables a multi-scale modelling framework to inherently link the processes and subsystems involved in biomass ecosystems and biorenewable manufacturing. Reviewing modelling advances, our study provides insights into the emerging opportunities in biorenewable research and highlights the frontier research directions, which have the potential to impact biorenewable sector sustainability.}
}
@article{SCHACTER2012677,
title = {The Future of Memory: Remembering, Imagining, and the Brain},
journal = {Neuron},
volume = {76},
number = {4},
pages = {677-694},
year = {2012},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2012.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0896627312009919},
author = {Daniel L. Schacter and Donna Rose Addis and Demis Hassabis and Victoria C. Martin and R. Nathan Spreng and Karl K. Szpunar},
abstract = {During the past few years, there has been a dramatic increase in research examining the role of memory in imagination and future thinking. This work has revealed striking similarities between remembering the past and imagining or simulating the future, including the finding that a common brain network underlies both memory and imagination. Here, we discuss a number of key points that have emerged during recent years, focusing in particular on the importance of distinguishing between temporal and nontemporal factors in analyses of memory and imagination, the nature of differences between remembering the past and imagining the future, the identification of component processes that comprise the default network supporting memory-based simulations, and the finding that this network can couple flexibly with other networks to support complex goal-directed simulations. This growing area of research has broadened our conception of memory by highlighting the many ways in which memory supports adaptive functioning.}
}
@article{LIU2023113460,
title = {What is the “DNA” of healthy buildings? A critical review and future directions},
journal = {Renewable and Sustainable Energy Reviews},
volume = {183},
pages = {113460},
year = {2023},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2023.113460},
url = {https://www.sciencedirect.com/science/article/pii/S1364032123003179},
author = {Hui Liu and Xiaoxiao Xu and Vivian W.Y. Tam and Peng Mao},
keywords = {Healthy building, Indoor environment, DNA framework, Sustainability, Life-cycle, Future directions},
abstract = {Since the outbreak of COVID-19, buildings that provide improved performance have aroused extensive discussion. Nowadays, the connotation of healthy building is becoming complex, performance metrics for healthy buildings vary significantly from different regions in the world and there may be information asymmetry among stakeholders. Consequently, building health performance cannot be effectively achieved. However, previous studies have launched extensive reviews on green building, and there remains a lack of comprehensive and systematic reviews on healthy buildings. To address the above issues, therefore, this research aims to (1) conduct a thorough review of healthy building research and reveal its nature; and (2) identify the current research gaps and propose possible future research directions. Content analysis using NVivo were applied to review 238 relevant publications. A DNA framework of healthy buildings, which clarifies the characteristics, triggers, guides and actions, was then constructed for better understanding of the nature of them. Subsequently, the application of DNA framework and the directions of future research were discussed. Six future research directions were finally recommended, including life-cycle thinking, standard systems improvement, policies & regulations, awareness increase, healthy building examination, and multidisciplinary integration. This research differs from previous ones because it painted a panorama of previous healthy building research. Findings of this research contribute to reveal knowledge map of healthy buildings, guide researchers to fill existing knowledge gaps, provide a standardized platform for healthy building stakeholders, and promote high-quality development of healthy buildings.}
}
@article{LI20151,
title = {The association between alexithymia as assessed by the 20-item Toronto Alexithymia Scale and depression: A meta-analysis},
journal = {Psychiatry Research},
volume = {227},
number = {1},
pages = {1-9},
year = {2015},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2015.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0165178115000761},
author = {Shuwen Li and Bin Zhang and Yufang Guo and Jingping Zhang},
keywords = {Alexithymia, Depression, Meta-analysis, Questionnaire},
abstract = {Patients with depression exhibit high rates of alexithymia, representing a major public health concern. We sought to examine relationships between depression severity and alexithymia as assessed by the Toronto Alexithymia Scale (TAS-20) and the TAS-20 subscales of difficulty identifying feelings (DIF), difficulty describing feelings (DDF), and externally oriented thinking (EOT). Potentially relevant studies were obtained independently by two reviewers. Chi-square statistics based on the Q-test and I2 index assessed statistical heterogeneity between studies. Subgroup analyses were mainly used to explore sources of heterogeneity. Begg׳s test and Duval and Tweedie’ trim and fill were used to assess potential publication bias. Altogether, 3572 subjects from 20 study groups across 19 studies were included. Medium relationships were observed between depression and TAS-total score (TAS-TS), DIF, and DDF. There was also a weak relationship between EOT and depression. Subgroup analyses showed a stronger correlation between TAS-TS and depression assessed by self-reported tools than that assessed by the Hamilton Rating Scale for Depression. The heterogeneity significantly decreased only in the subgroup analysis by depression tool. We conclude that alexithymia, as assessed by the TAS-20 and its subscales DIF and DDF, is closely related to depression. These relationships were affected by depression measurement tools.}
}
@article{BARAK20171,
title = {Recurrent neural networks as versatile tools of neuroscience research},
journal = {Current Opinion in Neurobiology},
volume = {46},
pages = {1-6},
year = {2017},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2017.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438817300429},
author = {Omri Barak},
abstract = {Recurrent neural networks (RNNs) are a class of computational models that are often used as a tool to explain neurobiological phenomena, considering anatomical, electrophysiological and computational constraints. RNNs can either be designed to implement a certain dynamical principle, or they can be trained by input–output examples. Recently, there has been large progress in utilizing trained RNNs both for computational tasks, and as explanations of neural phenomena. I will review how combining trained RNNs with reverse engineering can provide an alternative framework for modeling in neuroscience, potentially serving as a powerful hypothesis generation tool. Despite the recent progress and potential benefits, there are many fundamental gaps towards a theory of these networks. I will discuss these challenges and possible methods to attack them.}
}
@article{GARCIA2025e207,
title = {Future-proofing cities against negative city mobility and public health impacts of impending natural hazards: a system dynamics modelling study},
journal = {The Lancet Planetary Health},
volume = {9},
number = {3},
pages = {e207-e218},
year = {2025},
issn = {2542-5196},
doi = {https://doi.org/10.1016/S2542-5196(25)00026-9},
url = {https://www.sciencedirect.com/science/article/pii/S2542519625000269},
author = {Leandro Garcia and Mehdi Hafezi and Larissa Lima and Christopher Millett and Jason Thompson and Ruoyu Wang and Selin Akaraci and Rahul Goel and Rodrigo Reis and Kerry A Nice and Belen Zapata-Diomedi and Pedro C Hallal and Esteban Moro and Clifford Amoako and Ruth F Hunter},
abstract = {Summary
Background
The world faces increasing risk from more frequent and larger scale natural hazards, including infectious disease outbreaks (IDOs) and climate change-related extreme weather events (EWEs). These natural hazards are expected to have adverse mobility and public health impacts, with people living in cities especially vulnerable. Little is known about how transport systems can be optimally designed to make cities more resilient to these hazards. Our aim was to investigate how cities’ transport systems, and their resulting mobility patterns, affect their capabilities to mitigate mobility and health impacts of future large-scale IDOs and EWEs.
Methods
System dynamics modelling was used to investigate how different city mobility scenarios can affect the health and mobility impacts of four plausible future IDO and EWE (flooding) shocks in three cities: Belfast, UK; Belo Horizonte, Brazil; and Delhi, India. Three city mobility scenarios with incremental degrees of modal shift towards active travel (private motor vehicle volume reduced to 50% and 20% of total road trip volume in vision 1 and 2, and motor vehicle volume [including buses] reduced to 20% of total road trip volume in vision 3) were tested. For each city and each IDO and EWE shock, we estimated the percentage of deaths prevented in visions 1, 2, and 3, relative to the reference scenario, as well as changes in mode share over time.
Findings
In all scenarios, all cities showed reduced susceptibility to flooding, with 4–50% of deaths potentially prevented, depending on case city, city mobility, and EWE scenario. The more ambitious the transition towards healthier city mobility patterns, the greater the resilience against flooding. Only vision 3 (the most ambitious transition) showed reduced vulnerability to IDOs, with 6–19% of deaths potentially prevented. Evolution of mode shares varied greatly across cities and mobility scenarios under the IDO shocks.
Interpretation
Our results emphasise the importance of well designed, forward-thinking urban transport systems that make cities more resilient and reduce the impact of future public health-related and climate-related threats.
Funding
UK Prevention Research Partnership, UK Economic and Social Research Council, UK Medical Research Council, UK National Institute for Health and Care Research, Australian Research Council, Australian National Health and Medical Research Council, and Health and Social Care Research and Development Office Northern Ireland.}
}
@article{LI2022107258,
title = {Transformer helps identify kiwifruit diseases in complex natural environments},
journal = {Computers and Electronics in Agriculture},
volume = {200},
pages = {107258},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.107258},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922005713},
author = {Xiaopeng Li and Xiaoyu Chen and Jialin Yang and Shuqin Li},
keywords = {Identify kiwifruit diseases, Deep learning, Vision transformer, Complex environments, Convolutional neural network},
abstract = {The complex background of disease images and the small contrast between the disease area and the background easily confuse, seriously affecting the robustness and accuracy of kiwifruit disease identification models. To address the above problems, this paper proposes a disease identification model based on Vision Transformer and Convolutional Neural Network, ConvViT(Convolutional Neural Network and Vision Transformer), to identify diseases by extracting effective features of kiwifruit disease spots. The proposed ConvViT includes convolutional structure and Transformer structure: The convolutional structure is used to extract the global features of the image, and the Transformer structure is used to obtain the local features of the disease area to help the CNN see better. Meanwhile, the paper designs different models according to the number of parameters and FLOPs (floating-point operations) to improve the model's scalability. The model variants of different sizes are designed to be lightweight to run on devices with different resource constraints. We achieved 98.78% identification accuracy on the self-built kiwifruit disease dataset, with up to 4.53% improvement in identification accuracy compared to the same level of Resnet, ViT, and ResMLP, and more than 10% reduction in the number of parameters and FLOPs. Experimental results on the PlantVillage dataset and the AI Challenger 2018 also show that ConvViT has good generalizability, indicating that the proposed model can solve kiwifruit disease identification problems in complex environments and be valuable a backbone network for other identification tasks with practical applications.}
}
@article{TUYSUZ2024107221,
title = {A novel decomposed Z-fuzzy TOPSIS method with functional and dysfunctional judgments: An application to transfer center location selection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {127},
pages = {107221},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107221},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623014057},
author = {Nurdan Tüysüz and Cengiz Kahraman},
keywords = {Decomposed fuzzy sets, Fuzzy MCDM, Reliability, TOPSIS, Z-Fuzzy numbers},
abstract = {Decomposed fuzzy sets (DFSs) are one of the latest extensions of intuitionistic fuzzy sets which are introduced to express vague and imprecise information to be used in multi-criteria decision-making. DFSs represent the human thinking structure in a multidirectional way, and they enable it through functional and dysfunctional judgments. However, DFSs cannot completely represent the entire human mindset as they are incapable of capturing reliability information, as it is in the other extensions, and this inability may cause wrong decisions to be given. To handle this problem, decomposed Z-fuzzy numbers, which are the integrated DFSs with reliability information provided by Z-fuzzy numbers, are introduced to model functional and dysfunctional judgments for taking the consistency of decision makers into account. Collecting judgments with both their fuzzy restrictions and fuzzy reliabilities from decision makers based on functional and dysfunctional questions provide more consistent and reliable judgments in the practice. Subsequently, a new decomposed Z-fuzzy linguistic scale and defuzzification formula are introduced to reach a final solution. Then, decomposed Z-fuzzy TOPSIS method is developed. Finally, we analyze the effect of the reliability parameter on the given decisions and present a comparative analysis with crisp TOPSIS method by an application of transfer center location selection for a private cargo company in Marmara Region of Turkey.}
}
@article{ZHU20207240,
title = {A New Distribution-Free Concept for Representing, Comparing, and Propagating Uncertainty in Dynamical Systems with Kernel Probabilistic Programming⁎⁎This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 798321, the German Federal Ministry for Economic Affairs and Energy (BMWi) via eco4wind (0324125B) and DyConPV (0324166B), and by DFG via Research Unit FOR 2401.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {7240-7247},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.557},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320308569},
author = {Jia-Jie Zhu and Krikamol Muandet and Moritz Diehl and Bernhard Schölkopf},
keywords = {Uncertainty Quantification, Machine Learning, Kernel Methods, Nonparametric Methods, Stochastic System Identification, Robust Control, Randomized Algorithms},
abstract = {This work presents the concept of kernel mean embedding and kernel probabilistic programming in the context of stochastic systems. We propose formulations to represent, compare, and propagate uncertainties for fairly general stochastic dynamics in a distribution-free manner. The new tools enjoy sound theory rooted in functional analysis and wide applicability as demonstrated in distinct numerical examples. The implication of this new concept is a new mode of thinking about the statistical nature of uncertainty in dynamical systems.}
}
@article{PRIORELLI2024e39129,
title = {Slow but flexible or fast but rigid? Discrete and continuous processes compared},
journal = {Heliyon},
volume = {10},
number = {20},
pages = {e39129},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e39129},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024151602},
author = {Matteo Priorelli and Ivilin Peev Stoianov},
abstract = {A tradeoff exists when dealing with complex tasks composed of multiple steps. High-level cognitive processes can find the best sequence of actions to achieve a goal in uncertain environments, but they are slow and require significant computational demand. In contrast, lower-level processing allows reacting to environmental stimuli rapidly, but with limited capacity to determine optimal actions or to replan when expectations are not met. Through reiteration of the same task, biological organisms find the optimal tradeoff: from action primitives, composite trajectories gradually emerge by creating task-specific neural structures. The two frameworks of active inference – a recent brain paradigm that views action and perception as subject to the same free energy minimization imperative – well capture high-level and low-level processes of human behavior, but how task specialization occurs in these terms is still unclear. In this study, we compare two strategies on a dynamic pick-and-place task: a hybrid (discrete-continuous) model with planning capabilities and a continuous-only model with fixed transitions. Both models rely on a hierarchical (intrinsic and extrinsic) structure, well suited for defining reaching and grasping movements, respectively. Our results show that continuous-only models perform better and with minimal resource expenditure but at the cost of less flexibility. Finally, we propose how discrete actions might lead to continuous attractors and compare the two frameworks with different motor learning phases, laying the foundations for further studies on bio-inspired task adaptation.}
}
@article{TILSTRA201366,
title = {Cognitive processes of middle grade readers when reading expository text with an assigned goal},
journal = {Learning and Individual Differences},
volume = {28},
pages = {66-74},
year = {2013},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2013.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S1041608013001271},
author = {Janet Tilstra and Kristen L. McMaster},
keywords = {Reading, Comprehension-building, Struggling readers, Think alouds, Cognitive processes, Expository text},
abstract = {The purpose of this study was to examine 5th-grade readers' cognitive processes during reading when assigned to read for a specific goal as compared to reading for general comprehension. Equal groups of good and struggling readers (N=40) read expository texts and thought aloud while reading. In addition, the readers completed a text retell to examine the impact of an assigned goal on comprehension. During reading in the specific goal condition, both groups of readers used more study statements (monitoring, repetitions, and paraphrases) and fewer inferences (elaborative, predictive, and text-based) when thinking aloud compared with general comprehension. No reliable condition differences were noted in the amount or type of information included in retells. Implications for developing readers' comprehension-building processes when assigned a goal for reading are discussed.}
}
@article{WALL201161,
title = {Structure–function relations are subtle in genetic regulatory networks},
journal = {Mathematical Biosciences},
volume = {231},
number = {1},
pages = {61-68},
year = {2011},
note = {Special issue on biological design principles},
issn = {0025-5564},
doi = {https://doi.org/10.1016/j.mbs.2011.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0025556411000150},
author = {Michael E. Wall},
keywords = {Gene regulation, Function prediction, Network motifs, , Computational biology, Synthetic biology},
abstract = {Recent studies have yielded insights into structure–function relations in genetic regulatory networks. Models of feed-forward loops show that the input–output behavior depends critically on the input signal as well as transcription interactions. Models of induction of the lac operon in Escherichia coli reveal the importance of metabolism in determining genetic regulatory network behavior. Combined experimental and computational studies of activation by MarA in E. coli show how mechanisms of transcription regulation, hidden at the level of genetic regulatory networks, can influence behavior. Together these studies illustrate that gene regulation is critically influenced by factors beyond the topology of genetic regulatory interactions. Prediction of the specific information processing roles of gene circuits is more difficult than we would like, but it is still possible. Thinking about evolution of proteins and networks might make it easier.}
}
@article{2024100673,
title = {Erratum regarding missing Declaration of Competing Interest statements in previously published articles},
journal = {International Journal of Child-Computer Interaction},
volume = {41},
pages = {100673},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100673},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000412}
}
@article{GHIMIRE2025102913,
title = {Utilizing ChatGPT to integrate world English and diverse knowledge: A transnational perspective in critical artificial intelligence (AI) literacy},
journal = {Computers and Composition},
volume = {75},
pages = {102913},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000896},
author = {Asmita Ghimire},
abstract = {This article proposes the implementation of a transnational post-digital pedagogy and Critical AI literacy incorporating ChatGPT in the classroom. It draws upon Scott Graham's suggestion for a multidimensional recursive writing process, emphasizing fact-checking and revision while utilizing ChatGPT. Additionally, it incorporates Suresh Canagarajah's (2019) theorization of transnational habits of writing among most international, multilingual, and marginalized students, which, according to him, are characterized by rhetorical sensitivity, depth of awareness, and linguistic knowledge. Based on these empirical and theoretical perspectives, this article proposes pausing, pondering, posing, and prioritizing as critical praxis that can be built into metacognitive activities. To explain this praxis, it showcases two kinds of metacognitive activities for fostering transnational habits among students through fact-checking processes. Similarly, it suggests designing the revision phase of writing assignments to allow students to incorporate their English language skills into the classroom. This paper identifies engaging in critical dialogue with ChatGPT and encouraging self-reflection on fact-checking and revision as effective ways to cultivate a transnational habitus among students. It concludes that adopting a transnational post-digital critical pedagogy and critical AI literacy in the writing process benefits both national and international students by promoting diverse linguistic norms and perspectives.}
}
@article{MORAVEC2025100691,
title = {Environmental footprint of GenAI – Changing technological future or planet climate?},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {3},
pages = {100691},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100691},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000411},
author = {Vaclav Moravec and Beata Gavurova and Viliam Kovac},
keywords = {Generative artificial intelligence, ChatGPT, DeepSeek, Artificial intelligence literacy, Climate change, Data centre, Czechia},
abstract = {The beginnings of generative artificial intelligence (GenAI), led by Chat Generative Pre-Trained Transformer (ChatGPT), not only change the behaviour of digital media ecosystem users but also increase the energy consumption of enterprises working with GenAI, which presents them with a fundamental challenge in the era of climate change. This study aims to examine the relationships between the selected aspects of the use of GenAI tools and the environmental perception and behaviour of their users to understand the population's current environmental attitudes towards environmental risks and environmental sustainability. The survey was conducted in October 2024 on a sample of 1,268 respondents of the Czech Republic population. To process the data set, a logistic regression analysis, chi-squared test, Akaike information criterion, and Bayesian information criterion are employed. The results show that the more often people use GenAI tools, the more distant they consider the effects of climate change in time. The low frequency of use of ChatGPT may influence a higher willingness to change popular GenAI tools that are not maintained by environmentally friendly data centres. The frequency of ChatGPT use influences individuals’ perception of the importance of climate-change solving. The more frequently the respondents use artificial intelligence (AI) systems, they less perceive climate change as important. The low frequency of ChatGPT usage is associated with lower willingness to change email provider, transfer own data, leave social networks, stop using a favourite streaming platform and stop using a favourite GenAI platform. The respondents’ attitudes show a visible behavioural change. Internal personal motivation and self-confidence in learning, interest in career and self-confidence when using AI, the behavioural aspects, and the cognitive aspects are altered considerably. Based on the outcomes of the population survey, the study concludes that the issue of environmental friendliness of AI tools should become part of AI literacy that could strengthen population's willingness to use more energy-efficient GenAI platforms. The listed challenges are important in the perspective of the latest technological development, as shown by the discussion on the energy and computational demands of the GenAI platform DeepSeek, which is also discussed in the study.}
}
@article{BROER2022115131,
title = {The Googlization of Health: Invasiveness and corporate responsibility in media discourses on Facebook's algorithmic programme for suicide prevention},
journal = {Social Science & Medicine},
volume = {306},
pages = {115131},
year = {2022},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2022.115131},
url = {https://www.sciencedirect.com/science/article/pii/S0277953622004373},
author = {Tineke Broer},
keywords = {Suicide prevention, Facebook, Content moderation, Privacy, Googlization of health},
abstract = {Big tech companies increasingly play a role in the domain of health. Also called the “Googlization of Health”, this phenomenon is often studied by drawing on the notion of ‘hostile worlds’, where market values and common goods are incommensurable. Yet, the ‘hostile worlds’ theory is not uncontested; scholars for instance argue that the justifications of big tech companies are important analytical considerations as well. Building on this literature, in this paper I report on a case study of Facebook employing AI for suicide prevention, moving beyond Facebook's justifications only to study the ways in which media commentators and their audiences discussed Facebook's programme and the values they saw as being at stake. In the results, I show how invasiveness was, in different ways and forms, a main theme in thinking about Facebook using AI to do suicide prevention. Commentators and readers alike discussed how: 1) Facebook takes corporate responsibility with this initiative, or alternatively Facebook only has commercial interests and uses the notion of ‘public good’ to transgress spheres and sectors even further, thus being invasive; 2) Facebook's AI suicide prevention programme is invasive in relation to privacy and privacy laws, or, instead, people give up their privacy willingly in exchange for entertainment; 3) The programme undermines, rather than enhances, safety; 4) Suicide prevention in itself is already invasive. These different forms of invasiveness, I argue in the conclusion, also imply responsibility for different actors, from AI itself to Facebook through to medical professionals. Moreover, they show what values are at stake in, and transformed through, Facebook's AI suicide prevention programme, going beyond the frames of privacy and surveillance capitalism.}
}
@article{BASHIRPOURBONAB2023104459,
title = {Urban quantum leap: A comprehensive review and analysis of quantum technologies for smart cities},
journal = {Cities},
volume = {140},
pages = {104459},
year = {2023},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2023.104459},
url = {https://www.sciencedirect.com/science/article/pii/S0264275123002718},
author = {Aysan {Bashirpour Bonab} and Maria Fedele and Vincenzo Formisano and Ihor Rudko},
keywords = {Smart city, Quantum city, Smart city technologies, Urban quantum technologies, Semi-systematic literature review, Thematic analysis},
abstract = {Contemporary smart city solutions rely on standardized von Neumann architecture, in which single data units are coded as “0” or “1.” Conversely, urban quantum technologies rely on the fundamental principles of quantum physics, transcending the conventions of the current computational paradigm. On the one hand, urban quantum technologies hold managerial relevance for future smart cities. On the other hand, they are often overlooked by smart city researchers. Accordingly, their value as a breakthrough technological paradigm is still largely unexplored. In this article, we look at how quantum technologies may contribute to existing smart city solutions, including the Internet of Things, cloud computing, big data, ICT, smart transportation, artificial intelligence, and blockchain. First, through a semi-systematic review of eighty articles on quantum computing within the social science domain, we identify two relevant classes of urban quantum technologies: quantum communication and quantum computing. Second, we establish a comprehensive taxonomy of conventional smart city solutions based on the automated content analysis of 567 abstracts of articles on the technological aspects of smart cities. Third, we investigate potential associations between two classes of technologies (conventional smart city solutions and urban quantum technologies) by analyzing the semantic relationships between eighty articles on quantum technologies according to the frequency of keywords denoting different types of conventional smart city solutions. Finally, we triangulate our findings through a thematic analysis of potential uses of quantum technologies within identified categories of smart city solutions.}
}
@incollection{ADAMS2024593,
title = {Nature's novel materials: A review of quantum biology},
editor = {Tapash Chakraborty},
booktitle = {Encyclopedia of Condensed Matter Physics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {593-604},
year = {2024},
isbn = {978-0-323-91408-6},
doi = {https://doi.org/10.1016/B978-0-323-90800-9.00268-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323908009002687},
author = {Betony Adams and Francesco Petruccione},
keywords = {Avian migration, Chirality, Coherent energy and charge transfer, Consciousness, DNA, Entanglement, Enzymes, Microtubules, Mitochondria, Nontrivial quantum effects, Photosynthesis, Posner molecules, Quantum biology, Quantum tunnelling, Reactive oxygen species, Receptors, Spin chemistry},
abstract = {Quantum biology is, most simply, the investigation of quantum effects in biological systems. While all matter is fundamentally quantum, quantum biology focuses on those quantum effects that result in properties of biological scale and relevance. It has long been argued that quantum effects are incompatible with biological systems, due to the likelihood of decoherence. But nature is a surprising and enterprising engineer. In this sense, quantum biology is the study of nature's materials and how they might sustain and enhance quantum effects, even in hot and wet environments. Quantum mechanics was developed in response to seemingly anomalous interactions between light and matter. It seems fitting that a great deal of the progress made in quantum biology in the last few decades has been on the topic of photosynthesis: the interaction of light with living matter. The interaction of electromagnetic radiation with matter is also at the heart of many other topics of quantum biology. This review is a broad overview of the current state of this research. While the underlying quantum effects are often similar—energy and charge transfer, tunnelling, spin dynamics—the biological contexts are varied and continue to grow. These contexts include enzyme catalysis, DNA mutation, receptor binding, photosynthesis, microtubule and mitochondrial function, magnetoreception, regulation of the production of reactive oxygen species, calcium ion storage and release and, potentially, consciousness. While there remain a number of reservations regarding quantum biology, progress made in this regard might further our understanding of both quantum and biological systems. With respect to the latter, advances in understanding biology might also contribute to a better understanding of physiology and the development of new therapeutics. But quantum biology might equally advance our understanding of quantum mechanics, by illustrating what quantum effects could look like in the novel materials out of which living systems are built.}
}
@article{TARI2023119635,
title = {Expansion-based Hill-climbing},
journal = {Information Sciences},
volume = {649},
pages = {119635},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119635},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523012203},
author = {Sara Tari and Matthieu Basseur and Adrien Goëffon},
keywords = {Maximum expansion, Hill-climbing algorithm, Local search, Fitness landscapes, Landscape-aware heuristics, Combinatorial optimization},
abstract = {This paper investigates the influence of adaptive walks heuristics within local searches, by studying to what extent a wiser choice among improving neighbors influences the expected quality of the attained local optima. To this aim, we specifically focus on hill-climbers and introduce the maximum expansion pivoting rule, which selects the improving neighbor having the highest number of improving neighbors. Experiments show that having one step ahead of information allows for wiser neighbor choices, leading to better local optima. As the best improvement climber, a maximum expansion climber selects a particular search trajectory among all possible first improvement trajectories, however, it significantly increases the expected quality of the trajectory. On the other hand, the computational overhead makes this heuristic less valuable when included in an iterated search process, where repeating fast random hill-climbings from random starting points still allows a better exploration of the search space. This paper, therefore, extends previous studies on the relative efficiency of hill-climbing pivoting rules, by focusing on the original maximum expansion selection criterion. Results suggest that the achievement of good local optima combined with the use of approximation techniques and problem specificities could lead to the design of effective advanced metaheuristics that exploit the maximum expansion principle.}
}
@article{ZHAO2021270,
title = {Learnable Heterogeneous Convolution: Learning both topology and strength},
journal = {Neural Networks},
volume = {141},
pages = {270-280},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100126X},
author = {Rongzhen Zhao and Zhenzhi Wu and Qikun Zhang},
keywords = {Convolution neural network, Efficiency & performance, Learning topology & strength, Fine-grained but structural, Hardware acceleration},
abstract = {Existing convolution techniques in artificial neural networks suffer from huge computation complexity, while the biological neural network works in a much more powerful yet efficient way. Inspired by the biological plasticity of dendritic topology and synaptic strength, our method, Learnable Heterogeneous Convolution, realizes joint learning of kernel shape and weights, which unifies existing handcrafted convolution techniques in a data-driven way. A model based on our method can converge with structural sparse weights and then be accelerated by devices of high parallelism. In the experiments, our method either reduces VGG16/19 and ResNet34/50 computation by nearly 5× on CIFAR10 and 2× on ImageNet without harming the performance, where the weights are compressed by 10× and 4× respectively; or improves the accuracy by up to 1.0% on CIFAR10 and 0.5% on ImageNet with slightly higher efficiency. The code will be available on www.github.com/Genera1Z/LearnableHeterogeneousConvolution.}
}
@article{WYLIE2025107472,
title = {15+ years of joint parallel application performance analysis/tools training with Scalasca/Score-P and Paraver/Extrae toolsets},
journal = {Future Generation Computer Systems},
volume = {162},
pages = {107472},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.07.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24004187},
author = {Brian J.N. Wylie and Judit Giménez and Christian Feld and Markus Geimer and Germán Llort and Sandra Mendez and Estanislao Mercadal and Anke Visser and Marta García-Gasulla},
keywords = {Hybrid parallel programming, MPI message-passing, OpenMP multithreading, OpenACC device offload acceleration, HPC application execution performance measurement & analysis, Performance assessment & optimisation methodology & tools, Hands-on training & coaching},
abstract = {The diverse landscape of distributed heterogeneous computer systems currently available and being created to address computational challenges with the highest performance requirements presents daunting complexity for application developers. They must effectively decompose and distribute their application functionality and data, efficiently orchestrating the associated communication and synchronisation, on multi/manycore CPU processors with multiple attached acceleration devices structured within compute nodes with interconnection networks of various topologies. Sophisticated compilers, runtime systems and libraries are (loosely) matched with debugging, performance measurement and analysis tools, with proprietary versions by integrators/vendors provided exclusively for their systems complemented by portable (primarily) open-source equivalents developed and supported by the international research community over many years. The Scalasca and Paraver toolsets are two widely employed examples of the latter, installed on personal notebook computers through to the largest leadership HPC systems. Over more than fifteen years their developers have worked closely together in numerous collaborative projects culminating in the creation of a universal parallel performance assessment and optimisation methodology focused on application execution efficiency and scalability, and the associated training and coaching of application developers (often in teams) in its productive use, reviewed in this article with lessons learnt therefrom.}
}
@article{NOUIOUA2023104,
title = {The quantum computer for accelerating image processing and strengthening the security of information systems},
journal = {Chinese Journal of Physics},
volume = {81},
pages = {104-124},
year = {2023},
issn = {0577-9073},
doi = {https://doi.org/10.1016/j.cjph.2022.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0577907322002763},
author = {Tarek Nouioua and Ahmed Hafid Belbachir},
keywords = {Quantum computer, Quantum physics, Quantum image processing, Quantum edge detection, RSA algorithm, Information security, Post-quantum-cryptography},
abstract = {Many researchers and laboratories have been involved for many years in the development of the quantum computer. In 2019, Google has announced that they have reached quantum supremacy with their quantum computer Sycamore using a 53 qubits processor. On November 2021, IBM also announced that they have built a quantum computer with the highest number of 127 qubits and revealed their ambitious goal of building a 1000 qubits processor by 2023. According to these two giants of the quantum computing field, such a machine can perform an astronomical quantity of calculations significantly faster than any other conventional computer. This technology could be a real revolution in many fields such as computing, artificial intelligence, medicine, chemistry, banking, and experimental techniques, …etc. Since this technology is still in its infancy in hardware and software, its progress may be slow. However, many working in the field predict that 2,000 to 5,000 quantum computers of a first generation will be operational by 2030, but quantum computers needed to deal with more complex problems may not exist until 2035 or beyond. In this paper, we will go over some of the basic aspects of a quantum computer, in particular the concept of the qubit or the quantum bit and the quantum computer itself. Then we will see how a quantum computer can effectively speed up the processing of large images, reduce the amount of memory needed for computation and storage and even, strengthen the security of information systems. Lastly, we will present and discuss a real hardware implementation of the well-known quantum edge detection, as well as a spy hunter simulation.}
}
@article{HEISS2023107908,
title = {Social media information literacy: Conceptualization and associations with information overload, news avoidance and conspiracy mentality},
journal = {Computers in Human Behavior},
volume = {148},
pages = {107908},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107908},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223002595},
author = {Raffael Heiss and Andreas Nanz and Jörg Matthes},
keywords = {Social media, Media literacy, Information literacy, Information overload, News avoidance, Conspiracy mentality},
abstract = {In this study, we present a novel scale for measuring social media information literacy (SMIL) that encompasses six sub-dimensions: navigation, curation, appraisal, comprehension, creation, and interaction. We also examine antecedents of SMIL, its association with information overload, and possible indirect consequences such as news avoidance and conspiracy thinking. Relying on a two-wave panel dataset (n = 901), we first used factor analysis to test the proposed measurement. The results showed that the six dimensions were empirically distinct and loaded on a higher order SMIL factor. In a second step, we explored antecedents and outcomes of SMIL and its sub-dimensions. We found that not age, but education and frequency of social media use were positively associated with gains in SMIL. Furthermore, SMIL was associated with a decrease in information overload. Information overload, in turn, was associated with a decrease in news avoidance and an increase in conspiracy mentality. Taken together, our results lend support that SMIL may support positive civic outcomes by its potential role in lowering information overload. Helping citizens to acquire SMIL may be one valuable measure to foster democratic resilience.}
}
@incollection{HORVATH1995315,
title = { - Feature-based support of conceptual design of mechanical products},
editor = {Mohamed E. Elarabi and Abdalla S. Wifi and A.S. Wifi},
booktitle = {Current Advances in Mechanical Design and Production VI},
publisher = {Pergamon},
address = {Oxford},
pages = {315-322},
year = {1995},
isbn = {978-0-08-042140-7},
doi = {https://doi.org/10.1016/B978-008042140-7/50029-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080421407500299},
author = {I. Horváth and Z. Bagoly and P. Kulcsár},
abstract = {Publisher Summary
The chapter presents a novel interpretation of conceptual design process that implies thinking in concepts rather than in functions. This chapter implements an interactive platform for early stage representation of designs. A framework, associative concept network (ACN), is elaborated to promote the development of a new computational model for concept spaces. It is also expected that higher level automation of conceptual design can be achieved based on ACNs. The reported research concentrates on the development and application of concept feature-objects (CFO). CFOs are functionally and morphologically parameterized three-dimensional skeletons that are arranged into an organ structure. Components of CFO descriptions are the physical ports, contact surfaces related to ports, bones between ports, DOF of ports, relevant physical parameters characterizing the energy transformation processes, and scientific and empirical descriptions of intentional transformations and environmental effects. Modeling entities for a given application are constructed by genetic modeling. The set of the new modeling entities can be used both for static analysis and dynamic simulation of mechanical products.}
}
@article{CHOI2023100069,
title = {Art and the artificial},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100069},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000286},
author = {Suk Kyoung Choi and Steve DiPaola and Liane Gabora},
keywords = {Creativity systems, Anticipatory esthetics, AI art, Creative process, Arts-based research, Affective computing},
abstract = {This paper explores the philosophical implications of machine learning text-to-image synthesis in a practice-based phenomenology of the computational poetics of a visual art process. It is hypothesized that artificial intelligence (AI) facilitated reflective image development fosters an anticipatory esthetics in creative interactivity. The concept of AI-mediated “perspectival affordance” is introduced and its application to affective computing design emphasized. It is proposed that positioning intelligent systems as collaborative creativity tools promotes a dynamic interplay that envisions creativity as an anticipatory system, conceived of as those systems where exchange between artist and tool is mediated by future-oriented affective projection upon the system. The paper aims to establish a cognitive framework for AI-mediated creativity grounded in anticipatory interactivity, enhancing understanding of embodied cognition as mediated by AI in human-centered creativity support systems.}
}
@article{SUN2020104036,
title = {R4 Det: Refined single-stage detector with feature recursion and refinement for rotating object detection in aerial images},
journal = {Image and Vision Computing},
volume = {103},
pages = {104036},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.104036},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620301682},
author = {Peng Sun and Yongbin Zheng and Zongtan Zhou and Wanying Xu and Qiang Ren},
keywords = {Rotating object detection in aerial images and videos, Single-stage detector, A novel encoder-decoder architecture, Recursive feature pyramid, Recursive feature contact, RetinaNet-based rotation detection, Feature refinement},
abstract = {The detection of objects with multi-orientations and multi-scales in aerial images is receiving increasing attention because of numerous useful applications in computer vision, image understanding, satellite remote sensing and surveillance. However, such detection can be exceedingly challenging because of a birds eye view, multi-scale rotating objects with large aspect ratios, dense distributions and extremely imbalanced categories. Despite the considerable progress that has been made, detection performance falls considerably below that required for real-world applications. In this paper, we propose an accurate and fast end-to-end detector to address the aforementioned challenges. Our contributions are threefold. First, inspired by the looking and thinking twice mechanism, recursive neural networks and the DetectoRS detector, we propose a novel encoder-decoder based architecture by introducing the recursive feature pyramid into a single-stage object detection framework. The improved backbone network can generate increasingly powerful multi-scale representations for classification and regression. Second, we propose a refined single-stage detector with feature recursion and refinement for rotating objects. Third, we use instance balance to improve focal loss, thereby optimizing the loss in the correct direction. Extensive experiments on two challenging aerial image object detection public datasets, DOTA and HRSC2016, show that the proposed R4Det detector achieves the state-of-the-art accuracy while running very fast. Moreover, further experiments show that our detector is more robust to adversarial image patch attacks than the previous state-of-art detector.}
}
@article{REGIER201440,
title = {Task complexity and response certainty in discrete choice experiments: An application to drug treatments for juvenile idiopathic arthritis},
journal = {Journal of Behavioral and Experimental Economics},
volume = {50},
pages = {40-49},
year = {2014},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2014.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S221480431400038X},
author = {Dean A. Regier and Verity Watson and Heather Burnett and Wendy J. Ungar},
keywords = {Discrete choice experiment, Stated response certainty, Random heterogeneity, Sampling uncertainty, Dual-process thinking},
abstract = {Responding to a stated preference discrete choice experiment (DCE) is a complex task for respondents to undertake. Task complexity can induce response error, thereby decreasing the statistical precision of the econometric model. This study explores the link between task complexity and statistical precision as moderated by the level of thoughtful deliberation respondents exert when completing choice tasks. To do this, we make novel use of subjects’ certainty of response to DCE tasks as a measure of their deliberation. The distinction between intuitive and deliberate thought (System 1 and System 2, respectively) motivates how task complexity will differentially affect System 1 and System 2 respondents. The principle of utility balance in experimental design theory is used to understand how greater deliberation will increase task complexity, but will also improve statistical precision if respondents are engaging in System 2 processing. Our analyses find that increases in choice task utility balance decreases response certainty, and re-weighting the regression to favor respondents who are more uncertain of their choices increases the statistical precision of the econometric model.}
}
@article{MCNAUGHTON2024102653,
title = {The homogenous hippocampus: How hippocampal cells process available and potential goals},
journal = {Progress in Neurobiology},
volume = {240},
pages = {102653},
year = {2024},
issn = {0301-0082},
doi = {https://doi.org/10.1016/j.pneurobio.2024.102653},
url = {https://www.sciencedirect.com/science/article/pii/S0301008224000893},
author = {Neil McNaughton and David Bannerman},
keywords = {Hippocampus, Cell fields, Iteration, Goals, Space, Anxiety, Memory, Eye blink conditioning, Vinogradova},
abstract = {We present here a view of the firing patterns of hippocampal cells that is contrary, both functionally and anatomically, to conventional wisdom. We argue that the hippocampus responds to efference copies of goals encoded elsewhere; and that it uses these to detect and resolve conflict or interference between goals in general. While goals can involve space, hippocampal cells do not encode spatial (or other special types of) memory, as such. We also argue that the transverse circuits of the hippocampus operate in an essentially homogeneous way along its length. The apparently different functions of different parts (e.g. memory retrieval versus anxiety) result from the different (situational/motivational) inputs on which those parts perform the same fundamental computational operations. On this view, the key role of the hippocampus is the iterative adjustment, via Papez-like circuits, of synaptic weights in cell assemblies elsewhere.}
}
@article{SCHIFFERKANE2024104659,
title = {Converting OMOP CDM to phenopackets: A model alignment and patient data representation evaluation},
journal = {Journal of Biomedical Informatics},
volume = {155},
pages = {104659},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104659},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000777},
author = {Kayla Schiffer-Kane and Cong Liu and Tiffany J. Callahan and Casey Ta and Jordan G. Nestor and Chunhua Weng},
keywords = {Phenopackets schema, OMOP-CDM, Health data standards, Interoperability, Phenotyping, Data model},
abstract = {Objective
This study aims to promote interoperability in precision medicine and translational research by aligning the Observational Medical Outcomes Partnership (OMOP) and Phenopackets data models. Phenopackets is an expert knowledge-driven schema designed to facilitate the storage and exchange of multimodal patient data, and support downstream analysis. The first goal of this paper is to explore model alignment by characterizing the common data models using a newly developed data transformation process and evaluation method. Second, using OMOP normalized clinical data, we evaluate the mapping of real-world patient data to Phenopackets. We evaluate the suitability of Phenopackets as a patient data representation for real-world clinical cases.
Methods
We identified mappings between OMOP and Phenopackets and applied them to a real patient dataset to assess the transformation’s success. We analyzed gaps between the models and identified key considerations for transforming data between them. Further, to improve ambiguous alignment, we incorporated Unified Medical Language System (UMLS) semantic type-based filtering to direct individual concepts to their most appropriate domain and conducted a domain-expert evaluation of the mapping’s clinical utility.
Results
The OMOP to Phenopacket transformation pipeline was executed for 1,000 Alzheimer’s disease patients and successfully mapped all required entities. However, due to missing values in OMOP for required Phenopacket attributes, 10.2 % of records were lost. The use of UMLS-semantic type filtering for ambiguous alignment of individual concepts resulted in 96 % agreement with clinical thinking, increased from 68 % when mapping exclusively by domain correspondence.
Conclusion
This study presents a pipeline to transform data from OMOP to Phenopackets. We identified considerations for the transformation to ensure data quality, handling restrictions for successful Phenopacket validation and discrepant data formats. We identified unmappable Phenopacket attributes that focus on specialty use cases, such as genomics or oncology, which OMOP does not currently support. We introduce UMLS semantic type filtering to resolve ambiguous alignment to Phenopacket entities to be most appropriate for real-world interpretation. We provide a systematic approach to align OMOP and Phenopackets schemas. Our work facilitates future use of Phenopackets in clinical applications by addressing key barriers to interoperability when deriving a Phenopacket from real-world patient data.}
}
@article{VALENAS2017102,
title = {Prediction of pre-exam state anxiety from ruminative disposition: The mediating role of impaired attentional disengagement from negative information},
journal = {Behaviour Research and Therapy},
volume = {91},
pages = {102-110},
year = {2017},
issn = {0005-7967},
doi = {https://doi.org/10.1016/j.brat.2017.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S0005796717300232},
author = {Sergiu P. Vălenaş and Aurora Szentágotai-Tătar and Ben Grafton and Lies Notebaert and Andrei C. Miu and Colin MacLeod},
keywords = {Anxiety, Rumination, Attentional biases},
abstract = {Rumination is a maladaptive form of repetitive thinking that enhances stress responses, and heightened disposition to engage in rumination may contribute to the onset and persistence of stress-related symptoms. However, the cognitive mechanisms through which ruminative disposition influences stress reactivity are not yet fully understood. This study investigated the hypothesis that the impact of ruminative disposition on stress reactivity is carried by an attentional bias reflecting impaired attentional disengagement from negative information. We examined the capacity of a measure of ruminative disposition to predict both attentional biases to negative exam-related information, and state anxiety, in students approaching a mid-term exam. As expected, ruminative disposition predicted state anxiety, over and above the level predicted by trait anxiety. Ruminative disposition also predicted biased attentional disengagement from, but not biased attentional engagement with, negative information. Importantly, biased attentional disengagement from negative information mediated the relation between ruminative disposition and state anxiety. These findings confirm that dispositional rumination is associated with difficulty disengaging attention from negative information, and suggest that this attentional bias may be one of the mechanisms through which ruminative disposition influences stress reactivity.}
}
@incollection{GULATI1991173,
title = {Neurocomputing Formalisms for Computational Learning and Machine Intelligence},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {33},
pages = {173-245},
year = {1991},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60167-9},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808601679},
author = {S. Gulati and J. Barhen and S.S. Iyengar},
abstract = {Publisher Summary
The chapter discusses the capabilities of neural-network learning that is central to the deeper question of its feasibility to artificial intelligence. It focuses on machine learning in the context of neural networks from the standpoints of computational complexity and algorithms information theory, and on the emerging area of learning theory in the context of dynamic systems. Engineered intelligent systems behave with remarkable rigidity when compared with, their biological counterparts, especially in their ability to recognize objects or speech, to manipulate and adapt in an unstructured environment, and to learn from past experience. A major reason for this limited technical success in emulating some of the more fundamental aspects of human intelligence lies in the differences between the organization and structuring of knowledge, and the dynamics of biological neuronal circuitry and its emulation using the symbolic-processing paradigm. The chapter rederives a theoretical framework for neural learning of nonlinear mappings, wherein both the topology of the network and synaptic interconnection strengths are evolved adaptively. The proposed methodology exploits a new class of mathematical constructs, terminal attractors, which provide unique information-processing capabilities to artificial neural systems. Terminal attractor representations are used not only to ensure infinite local stability of the encoded information, but also to provide a qualitative as well as quantitative change in the nature of the learning process. The chapter also draws from mathematical constructs in sensitivity theory for nonlinear systems to illustrate the notion of forward and adjoint-operators. The formalism exploits the concept of adjoint-operators to enable a fast global computation of the network's response to perturbations in all system parameters. This formalism eliminates the heuristic overtones of the proposed framework.}
}
@article{SHAIKHOUNI2012392,
title = {Computers and Neurosurgery},
journal = {World Neurosurgery},
volume = {78},
number = {5},
pages = {392-398},
year = {2012},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2012.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S1878875012010169},
author = {Ammar Shaikhouni and J. Bradley Elder},
keywords = {Computers, Neuroimaging, Neurosurgery, Technology},
abstract = {At the turn of the twentieth century, the only computational device used in neurosurgical procedures was the brain of the surgeon. Today, most neurosurgical procedures rely at least in part on the use of a computer to help perform surgeries accurately and safely. The techniques that revolutionized neurosurgery were mostly developed after the 1950s. Just before that era, the transistor was invented in the late 1940s, and the integrated circuit was invented in the late 1950s. During this time, the first automated, programmable computational machines were introduced. The rapid progress in the field of neurosurgery not only occurred hand in hand with the development of modern computers, but one also can state that modern neurosurgery would not exist without computers. The focus of this article is the impact modern computers have had on the practice of neurosurgery. Neuroimaging, neuronavigation, and neuromodulation are examples of tools in the armamentarium of the modern neurosurgeon that owe each step in their evolution to progress made in computer technology. Advances in computer technology central to innovations in these fields are highlighted, with particular attention to neuroimaging. Developments over the last 10 years in areas of sensors and robotics that promise to transform the practice of neurosurgery further are discussed. Potential impacts of advances in computers related to neurosurgery in developing countries and underserved regions are also discussed. As this article illustrates, the computer, with its underlying and related technologies, is central to advances in neurosurgery over the last half century.}
}
@article{BENITEZANDRADES2022,
title = {Traditional Machine Learning Models and Bidirectional Encoder Representations From Transformer (BERT)–Based Automatic Classification of Tweets About Eating Disorders: Algorithm Development and Validation Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {2},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/34492},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001004},
author = {José Alberto Benítez-Andrades and José-Manuel Alija-Pérez and Maria-Esther Vidal and Rafael Pastor-Vargas and María Teresa García-Ordás},
keywords = {natural language processing, NLP, social media, data, bidirectional encoder representations from transformer, BERT, deep learning, machine learning, eating disorder, mental health, model, classification, Twitter, nutrition, diet, weight, disorder, performance},
abstract = {Background
Eating disorders affect an increasing number of people. Social networks provide information that can help.
Objective
We aimed to find machine learning models capable of efficiently categorizing tweets about eating disorders domain.
Methods
We collected tweets related to eating disorders, for 3 consecutive months. After preprocessing, a subset of 2000 tweets was labeled: (1) messages written by people suffering from eating disorders or not, (2) messages promoting suffering from eating disorders or not, (3) informative messages or not, and (4) scientific or nonscientific messages. Traditional machine learning and deep learning models were used to classify tweets. We evaluated accuracy, F1 score, and computational time for each model.
Results
A total of 1,058,957 tweets related to eating disorders were collected. were obtained in the 4 categorizations, with The bidirectional encoder representations from transformer–based models had the best score among the machine learning and deep learning techniques applied to the 4 categorization tasks (F1 scores 71.1%-86.4%).
Conclusions
Bidirectional encoder representations from transformer–based models have better performance, although their computational cost is significantly higher than those of traditional techniques, in classifying eating disorder–related tweets.}
}
@article{ARIYA2025101387,
title = {Digital literacy through gaming: A comparative study of knowledge acquisition, social presence, and emotional reactions in digital and non-digital board games},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101387},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101387},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125001147},
author = {Pakinee Ariya and Natchaya Wongwan and Kannikar Intawong and Kitti Puritat},
keywords = {Educational board games, Digital literacy, Digital board game, Emotional reactions, Social presence},
abstract = {The trend of educational board games is experiencing significant growth, with notable integration of technology; however, many educators continue to use both digital and physical board games. Digital board games offer convenience, accessibility, and enhanced interactivity through features like animations, sound effects, and automated rule enforcement. In contrast, physical board games emphasize tactile engagement and face-to-face social presence, fostering a stronger sense of connection among players. This study investigates the comparative impacts of digital and non-digital board games on knowledge acquisition, social presence, and emotional reactions among higher education students. Employing a quasi-experimental design, 82 students enrolled in an Information Literacy course were divided into two groups: one using digital board games and the other using non-digital board games. Pre- and post-tests measured knowledge acquisition, while the Social Presence in Gaming Questionnaire (SPGQ) and the Positive and Negative Affect Schedule (PANAS) assessed social and emotional impacts. Results indicate that both digital and non-digital games significantly enhance knowledge acquisition, with no substantial differences between the two formats. However, digital board games showed higher engagement levels, suggesting a greater potential for promoting active participation. Emotional responses were similar across both groups, with no significant differences in positive or negative affect. These findings underscore the educational value of both game formats and highlight the importance of selecting the appropriate type based on specific educational objectives.}
}
@incollection{KERN20241,
title = {Chapter 1 - Introduction and overview},
editor = {Eugene Barton Kern and Oren Friedman},
booktitle = {Empty Nose Syndrome},
publisher = {Elsevier},
pages = {1-31},
year = {2024},
isbn = {978-0-443-10715-3},
doi = {https://doi.org/10.1016/B978-0-443-10715-3.00001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443107153000019},
author = {Eugene Barton Kern and Oren Friedman},
keywords = {Empty nose syndrome (ENS), American Rhinologic Society (ARS), secondary atrophic rhinitis, “approximate temporary truth,” on-urgical urbinate eductive djunctive rocedure (n-sTRAP), evidence-based medicine (EBM), randomized controlled trials (RCTs), total inferior turbinectomy, nasal crime, conservative submucosal inferior turbinoplasty, authorized research, clustered regularly interspaced short palindromic repeats (CRISPER), “genetic engineering,” solidated tandards f eporting rials (CONSORT statement), propensity score matching (PSM), clinical practice guidelines (CPGs), conflicts of interest (COI), computational fluid dynamics (CFD), medical journals, peer reviewers, nasal cripple, nasal physiology, “organ of the nose,” primary functions of the nose, nasal cycle, and the autonomic nervous system},
abstract = {This chapter presents the introduction and overview of the empty nose syndrome (ENS), highlighting subjects we will consider in detail with corresponding citations from the literature (included in the broad bibliography of 376 references), besides providing complete commentary regarding the fundamental features of ENS along with a review of pertinent nasal physiology, a comprehensive differential diagnosis and an analysis of the various medical, surgical, and psychological treatment options for these desperately distraught patients, some of whom have committed suicide because of their horrific torment. ENS was initially recognized and formally presented to the profession by the Mayo Clinic team in 1994. With over a quarter of a century experience treating hundreds of patients devastated by ENS, we reexamined the existing thinking concerning the etiology, differential diagnosis, diagnosis, treatment, and ultimately preventing this crippling disorder.}
}
@article{TSAI2025105305,
title = {Effects of integrating self-regulation scaffolding supported by chatbot and online collaborative reflection on students’ learning in an artificial intelligence course},
journal = {Computers & Education},
volume = {232},
pages = {105305},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105305},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000739},
author = {Chia-Wen Tsai and Lynne Lee and Michael {Yu-Ching Lin} and Yih-Ping Cheng and Chih-Hsien Lin and Meng-Chuan Tsai},
keywords = {Cooperative/collaborative learning, Distance education and online learning, Pedagogical issues, Teaching/learning strategies, 21st century abilities},
abstract = {Artificial intelligence (AI) includes complex concepts and could be difficult for non-computer or information students, and they may experience difficulties in an AI course. In order to develop students' AI skills, regulate their academic stress, and reduce student loneliness, the researchers in this study integrated self-regulation scaffolding (supported by a chatbot designed in this study) with online collaborative reflection, and investigated their effects on students' learning. The researchers conducted a quasi-experiment to explore the effects of self-regulation scaffolding and online collaborative reflection. The participants in this experiment were 116 undergraduates from three classes (groups) of a non-computer department taking a compulsory course titled ‘Introduction to Artificial Intelligence’. The experimental groups in this study included the first class (G1) simultaneously receiving the interventions of self-regulation scaffolding and online collaborative reflection, as well as the second class (G2) only receiving the intervention of self-regulation scaffolding. The last class (G3), that received a traditional teaching method (non-self-regulation scaffolding and non-online collaborative reflection) in an online AI course, served as the control group. According to the statistical analysis in this study, the self-regulation scaffolding approach in G2 significantly promoted participants' AI skills and fostered their ability to regulate academic stress compared to the control group. However, G1 students who received concurrent online collaborative reflection did not demonstrate the expected effects of enhancing their learning compared with those (G2) who did not receive it. This study represents an early attempt to implement self-regulation scaffolding and online collaborative reflection integrated with chatbot in an online AI course. The results of this study could serve as a reference for online course designers, educators, and scholars planning to adopt these teaching methods, especially for those focusing on implementing online AI education and educational technologies (such as chatBot).}
}
@article{ALBERT2013353,
title = {Extending SysML for Engineering Designers by Integration of the Contact & Channel – Approach (C&C2-A) for Function-Based Modeling of Technical Systems},
journal = {Procedia Computer Science},
volume = {16},
pages = {353-362},
year = {2013},
note = {2013 Conference on Systems Engineering Research},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.01.037},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913000380},
author = {Albers Albert and Zingel Christian},
keywords = {Function-based modeling, state-based structure modeling, SysML, Contact & Channel - Approach, C&C-A, Engineering design},
abstract = {Model-Based Systems Engineering (MBSE) is advancing rapidly in the domains of software and embedded systems. In contrast, mechanical engineers still have trouble in application of MBSE. SysML has established as the leading modeling language for multidisciplinary systems, but some limitations still hinder mechanical engineers from its application. The provided behavioral and structural diagrams seem to not being sufficiently capable to represent all relevant information regarding mechanical systems. This paper presents an extending profile which aims to overcome some of those limitations. The profile is based on the Contact & Channel – Approach (C&C2-A), which is well-proven in function-based modeling of technical systems comprising function-relevant structural properties. The goals of the C&C2-A are to retain a maximal solution space, to overcome component- afflicted thinking and to provide an adequate modeling approach for mechanical relevant information. A prototypic tool implementation of the extending SysML-profile, complemented by some automatisms in form of a plugin, is evaluated at the example of a small gearbox.}
}
@article{CARVALHAES2021102165,
title = {An overview & synthesis of disaster resilience indices from a complexity perspective},
journal = {International Journal of Disaster Risk Reduction},
volume = {57},
pages = {102165},
year = {2021},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2021.102165},
url = {https://www.sciencedirect.com/science/article/pii/S221242092100131X},
author = {Thomaz M. Carvalhaes and Mikhail V. Chester and Agami T. Reddy and Braden R. Allenby},
keywords = {Complex adaptive systems, Resilience, Indicators, Disaster index, Urban systems, Socio-ecological systems},
abstract = {Identifying Disaster resilience indices (DRI) for cities and communities remains a common approach for assessing their structural ability and inherent capacity to cope with, recover from, and adapt to disasters. Particularly popular are composite DRI methodologies that are quantitative, top-down, and geographically mappable. DRI have become more comprehensive as the complexity of urban systems is increasingly acknowledged. However, DRI remain criticized as static, reductive, and inadequate when viewed under a complexity paradigm, which views urban systems as Complex Adaptive Systems (CAS), where observed properties (like resilience) emerge from many interactions among heterogenous agents in a network. Literature reviews have covered the state and trends for DRI development. Our objective is to synthesize literature at the nexus of these reviews, CAS, and Socio-ecological Systems (SES) to determine the extent to which commonly adopted indicators relate to widely accepted tenets of CAS. Findings show that DRI indicators usually relate more closely to temporal snapshots of vulnerability, and alternative framings of current indicators along with interdisciplinary approaches could better capture CAS aspects of urban resilience. Research and development should strive to develop DRI based on underlying principles of CAS and SES, and consider adapting top-down quantitative approaches with thick data, network models, and mixed-method triangulations. Explicitly associating complexity theory with DRI can (i) help researchers in socio-technical and socio-ecological domains develop improved resilience indicators and assessment methods that are clearly differentiated from vulnerability metrics, and (ii) guide policy and decision-makers, amid future uncertainty, to better identify, implement and track capacity-enhancing measures.}
}
@article{SCHORR2003465,
title = {Motion, speed, and other ideas that “should be put in books”},
journal = {The Journal of Mathematical Behavior},
volume = {22},
number = {4},
pages = {465-477},
year = {2003},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2003.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0732312303000531},
author = {Roberta Y. Schorr},
keywords = {Motion, Speed, Velocity, Graphs, Graphical representations},
abstract = {This paper focuses on a portion of a research project involving a group of inner-city middle school students who used SimCalc simulation software over the course of an entire school year to investigate ideas relating to graphical representations of motion and speed. The classroom environment was one in which students openly defended and justified their thinking as they actively explored and solved rich mathematical problems. The activities, generally speaking, involved functions that were intended to tap students’ real world intuitions as well as prior mathematical skills and understandings about speed, motion, and other graphical representations that underlie the mathematics of motion. Results indicate that these students did build ideas related to those concepts. This paper will provide documentation of the ways in which these students interpreted graphical representations involving linear and quadratic functions that are associated with constant and linearly changing velocities, respectively.}
}
@article{SALIS202320,
title = {An Edge-Cloud based Reference Architecture to support cognitive solutions in Process Industry},
journal = {Procedia Computer Science},
volume = {217},
pages = {20-30},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.198},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922022761},
author = {Antonio Salis and Angelo Marguglio and Gabriele {De Luca} and Silvia Razzetti and Walter Quadrini and Sergio Gusmeroli},
keywords = {Industry 4.0, process industry, smart manufacturing, reference architecture, cloud, edge computing, cognitive computing, artificial intelligence, big data analytics},
abstract = {Process Industry is one of the leading sectors of the world economy, characterized however by intense environmental impact, and very high-energy consumption. Despite a traditional low innovation pace in PI, in the recent years a strong push at worldwide level towards the dual objective of improving the efficiency of plants and the quality of products, significantly reducing the consumption of electricity and CO2 emissions has taken momentum. Digital Technologies (namely Smart Embedded Systems, IoT, Data, AI and Edge-to-Cloud Technologies) are enabling drivers for a Twin Digital-Green Transition, as well as foundations for human centric, safe, comfortable and inclusive workplaces. Currently, digital sensors in plants produce a large amount of data, which in most cases constitutes just a potential and not a real value for Process Industry, often locked-in in close proprietary systems and seldomly exploited. Digital technologies, with process modelling-simulation via digital twins, can build a bridge between the physical and the virtual worlds, bringing innovation with great efficiency and drastic reduction of waste. In accordance with the guidelines of Industrie 4.0 this work proposes a modular and scalable Reference Architecture, based on open source software, which can be implemented both in brownfield and greenfield scenarios. The ability to distribute processing between the edge, where the data have been created, and the cloud, where the greatest computational resources are available, facilitates the development of integrated digital solutions with cognitive capabilities. The reference architecture is being validated in the three pilot plants, paving the way to the development of integrated planning solutions, with scheduling and control of the plants, optimizing the efficiency and reliability of the supply chain, and balancing energy efficiency.}
}
@article{GUERRERO2023107817,
title = {Forming We-intentions under breakdown situations in human-robot interactions},
journal = {Computer Methods and Programs in Biomedicine},
volume = {242},
pages = {107817},
year = {2023},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2023.107817},
url = {https://www.sciencedirect.com/science/article/pii/S0169260723004832},
author = {Esteban Guerrero and Maitreyee Tewari and Panu Kalmi and Helena Lindgren},
keywords = {We-intentions, Breakdown situations, Conflict of intentions, Repairing conflicts, Human-robot interaction, Answer set programming, Logic programming, Shared intentions, Social robots, Healthcare scenarios},
abstract = {Background and Objective: When agents (e.g. a person and a social robot) perform a joint activity to achieve a joint goal, they require sharing a relevant group intention, which has been defined as a We-intention. In forming We-intentions, breakdown situations due to conflicts between internal and “external” intentions are unavoidable, particularly in healthcare scenarios. To study such We-intention formation and “reparation” of conflicts, this paper has a two-fold objective: introduce a general computational mechanism allowing We-intention formation and reparation in interactions between a social robot and a person; and exemplify how the formal framework can be applied to facilitate interaction between a person and a social robot for healthcare scenarios. Method: The formal computational framework for managing We-intentions was defined in terms of Answer set programming and a Belief-Desire-Intention control loop. We exemplify the formal framework based on earlier theory-based user studies consisting of human-robot dialogue scenarios conducted in a Wizard of Oz setup, video-recorded and evaluated with 20 participants. Data was collected through semi-structured interviews, which were analyzed qualitatively using thematic analysis. N=20 participants (women n=12, men=8, age range 23-72) were part of the study. Two age groups were established for the analysis: younger participants (ages 23-40) and older participants (ages 41-72). Results: We proved four theoretical propositions, which are well-desired characteristics of any rational social robot. In our study, most participants suggested that people were the cause of breakdown situations. Over half of the young participants perceived the social robot's avoidant behavior in the scenarios. Conclusions: This work covered in depth the challenge of aligning the intentions of two agents (for example, in a person-robot interaction) when they try to achieve a joint goal. Our framework provides a novel formalization of the We-intentions theory from social science. The framework is supported by formal properties proving that our computational mechanism generates consistent potential plans. At the same time, the agent can handle incomplete and inconsistent intentions shared by another agent (for example, a person). Finally, our qualitative results suggested that this approach could provide an acceptable level of action/intention agreement generation and reparation from a person-centric perspective.}
}
@article{HOZ2024e40032,
title = {Educational robotics for science and mathematics teaching: Analysis of pre-service teachers' perceptions and self-confidence},
journal = {Heliyon},
volume = {10},
number = {21},
pages = {e40032},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e40032},
url = {https://www.sciencedirect.com/science/article/pii/S240584402416063X},
author = {Alejandro De la Hoz and Lina Melo and Florentina Cañada and Javier Cubero},
keywords = {Educational robotics, Pre-service teachers, Self-confidence, Perception, Mathematics education, Science education},
abstract = {Educational Robotics has had an important impact in recent years as it offers a number of advantages for students. The inclusion of robotics in any educational stage requires teachers with adequate predisposition and training, making it necessary to know the opinions of pre-service teachers. The aim of our study is to analyze the perceptions and self-confidence of 109 pre-service primary education teachers before and after an intervention based on educational robotics and challenge-based learning to teach scientific and mathematical content, in their third academic year. A quasi-experimental design was used involving pretest and posttest, using the nonparametric Mann-Whitney and Wilcoxon U tests. The results showed a significant improvement in the overall mean self-confidence. In addition, the intervention led to a more positive perception of the benefits and possibilities of robotics for teaching of scientific and mathematical content, although it also increased the difficulties of implementation due to the lack of training in this digital resource. It is concluded that interventions are required based on educational robotics that allow pre-service teachers to gain the necessary self-confidence and perception to facilitate its introduction for the teaching of scientific and mathematical content.}
}
@article{ESSAKALI2024123910,
title = {Advanced predictive maintenance and fault diagnosis strategy for enhanced HVAC efficiency in buildings},
journal = {Applied Thermal Engineering},
volume = {254},
pages = {123910},
year = {2024},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2024.123910},
url = {https://www.sciencedirect.com/science/article/pii/S1359431124015783},
author = {Niima Es-sakali and Zineb Zoubir and Samir {Idrissi Kaitouni} and Mohamed Oualid Mghazli and Moha Cherkaoui and Jens Pfafferott},
keywords = {Variable refrigerant flow, Predictive maintenance, Fault detection and diagnosis, Refrigerant leakage, Noise reduction models, Building Environment},
abstract = {Variable refrigerant flow (VRF) systems are constantly prone to failures during their lifespan, causing breakdowns, high energy bills, and indoor discomfort. In addition to correctly identifying these defects, fault detection, and diagnostic studies should be able to anticipate and predict the anomalies before they occur for efficient maintenance. Therefore, this study introduces an efficient self-learning predictive maintenance system, CACMMS (Cloud Air Conditioning Monitoring & Management System), designed to anticipate refrigerant leaks in VRF systems. Unlike previous efforts, this system leverages advanced fault detection and diagnosis strategies in a real existing building to enhance prediction accuracy. The study employed three noise filtering models (Kalman filter, moving average, S-G smoothing) in the preprocessing phase. Ten features were selected for assessment, and four machine learning models (decision tree, random forest, K-nearest neighbor, support vector machine) were compared. The accuracy, precision, sensitivity, computation time as well and confusion matrix were used as performance indicators and metrics to evaluate and choose the best performant model. Results indicated that decision tree and random forest models achieved over 95 % accuracy with execution times between 0.70 s and 3.32 s, outperforming K-nearest neighbor and support vector machine models. These findings highlight the system’s potential to reduce downtime and energy costs through effective predictive maintenance.}
}
@article{CALDERON201860,
title = {Sunrise Hotels: An integrated managerial accounting teaching case},
journal = {Journal of Accounting Education},
volume = {44},
pages = {60-72},
year = {2018},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2018.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575117302439},
author = {Thomas Calderon and James W. Hesford and Nicolas Mangin and Mina Pizzini},
keywords = {Managerial accounting, Integrated learning, Case study, Teaching case},
abstract = {“Sunrise Hotels” consists of six, linked cases developed from a field study of a large hotel chain in North America. The cases are short, so they can be distributed and solved in less than a full class period, after a short lecture by the instructor. Students often see managerial topics as an unrelated collection of tools rather than as a coherent, integrated framework for decision-making and management control. Questions included with each short case guide students, and the integration developed across six cases in a single setting should help students view managerial accounting topics as inter-related tools for decision making and control.}
}
@article{NABONI2017110,
title = {Thermal Comfort-CFD maps for Architectural Interior Design},
journal = {Procedia Engineering},
volume = {180},
pages = {110-117},
year = {2017},
note = {International High-Performance Built Environment Conference – A Sustainable Built Environment Conference 2016 Series (SBE16), iHBE 2016},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.04.170},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817316776},
author = {Emanuele Naboni and Daniel Sang-Hoon Lee and Kristian Fabbri},
keywords = {Building Retrofit, Thermal Comfort Map, Computational Fluid Dynamic, Mean Radiant Temperature, Architectural Design Process},
abstract = {Within the context of nearly Zero-Energy Buildings, it is debated that the energy-centred notion of design, proposed by regulatory frames, needs to be combined with a further focus toward users’ comfort and delight. Accordingly, the underlying theory of the research is that designers should take responsibility for understanding the heat flows through the building parts and its spaces. A design, which is sensible to the micro-thermal conditions coexisting in space, allows the inhabitants to control the building to their needs and desires: for instance, maximising the benefits of heat gain from the sun moving a series of internal partitions so as to avoid the danger of over-heating. It is thus necessary that existing simulation software tools are tested to the purpose of modelling and visualising the indoor thermal environment complexity. The research discusses how thermal comfort maps, which are prepared with the use of Computational Fluid Dynamic simulation method, could integrate energy simulation outputs to uphold qualitative architectural design decisions. Mean radiant temperature maps were thus used to design the retrofit of a small educational building in Copenhagen. The thermal opportunities of movable interior partitions (operated by the users) could be estimated, providing a new layer of information to the designer. The applicability of the thermal maps within an architectural design process is discussed adopting standard energy simulation comfort outputs as a reference. The capabilities and the limitations of the method are appraised.}
}
@article{TAGHIKHANI2024114574,
title = {A hybrid modified PSO algorithm for the inverse p-median location problem in fuzzy random environment},
journal = {Theoretical Computer Science},
volume = {1000},
pages = {114574},
year = {2024},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2024.114574},
url = {https://www.sciencedirect.com/science/article/pii/S0304397524001890},
author = {Sepideh Taghikhani and Fahimeh Baroughi and Behrooz Alizadeh},
keywords = {Inverse p-median location problem, Fuzzy random variable, Conditional value at risk, Particle swarm optimization},
abstract = {This paper considers the inverse p-median location problem with variable edge lengths and variable vertex weights on general graphs in which the modification costs are the fuzzy random variables. We present a model for the problem in fuzzy random environment in which the objective value is computed by conditional value at risk criterion. Then, we show that the problem is NP-hard under this criterion. Therefore, a new hybrid modified particle swarm optimization algorithm is proposed to obtain the approximate optimal solution of the proposed model. Finally, computational experiments are given to illustrate high efficiency of the proposed algorithm.}
}
@incollection{KAMEDA2015441,
title = {Evolutionary Group Dynamics},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {441-447},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.81040-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868810405},
author = {Tatsuya Kameda and Mark {Van Vugt} and Robert Scott Tindale},
keywords = {Adaptation, Coordination, Evolution, Evolutionary psychology, Group cohesion, Group decision making, Group living, Human sociality, Intergroup relations, Psychological processes, Social brain, Social exchange, Social psychology, Status},
abstract = {Evolutionary psychology adds many insights to the literature on group dynamics and small-group processes. First, groups are a fundamental aspect of human evolution, suggesting that humans have evolved a range of adaptations to deal with specific threats and opportunities afforded by living in groups. Second, an evolutionary perspective integrates knowledge from numerous behavioral science disciplines such as psychology, evolutionary biology, primatology, biological anthropology, social neuroscience, and behavioral economics that are all concerned with group dynamics. Third, an evolutionary analysis produces many novel hypotheses about different aspects of our group psychology. We show the generativity of an evolutionary psychological approach through discussing examples of research applying evolutionary thinking to understanding key adaptive group tasks such as coordination, social exchange, status, group cohesion, collective decision making, and intergroup relations.}
}
@incollection{MARINESCU2017113,
title = {Chapter 4 - Computer Clouds},
editor = {Dan C. Marinescu},
booktitle = {Complex Systems and Clouds},
publisher = {Elsevier},
address = {Boston},
pages = {113-145},
year = {2017},
series = {Computer Science Reviews and Trends},
isbn = {978-0-12-804041-6},
doi = {https://doi.org/10.1016/B978-0-12-804041-6.00004-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128040416000049},
author = {Dan C. Marinescu},
keywords = {Cloud delivery models, Hierarchical organization, Warehouse-scale computers, Over-provisioning, Cloud energy consumption, Cloud resource management, Cloud federations, Combinatorial auctions},
abstract = {Computer clouds have altered our thinking about computing and in this chapter, we first provide a down-to-earth view of the new paradigm and present the cloud delivery models. Next we discuss the hierarchical organization of the cloud infrastructure, consisting of multiple warehouse-scale computers. Cloud elasticity, the effects of over-provisioning on costs and energy consumption, and existing cloud resource management (CRM) policies and mechanisms for implementing these policies are analyzed. Alternative CRMs based on market mechanisms, such as auctions and server coalitions are then introduced. Combinatorial auctions allow access to packages of resources for applications with a complex workflow.}
}
@article{CHU2023106290,
title = {A data-driven meta-learning recommendation model for multi-mode resource constrained project scheduling problem},
journal = {Computers & Operations Research},
volume = {157},
pages = {106290},
year = {2023},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2023.106290},
url = {https://www.sciencedirect.com/science/article/pii/S0305054823001545},
author = {Xianghua Chu and Shuxiang Li and Fei Gao and Can Cui and Forest Pfeiffer and Jianshuang Cui},
keywords = {Data-driven decision making, Meta-learning, Feature extraction, Meta-heuristics},
abstract = {Meta-heuristics widely proposed in addressing multi-mode resource constrained project scheduling problem (MRCPSP) are problem-dependent. This paper first proposes an adaptive data-driven meta-learning Meta-heuristic Recommendation Model (MRM) to solve MRCPSP intelligently and efficiently. By learning the association between problem meta-features and algorithm performance, MRM can identify the most appropriate algorithm for different MRCPSPs. Multiclass Support Vector Machine (MCSVM) are integrated to train the classifiers for predicting the performance of the candidate meta-heuristics. To validate the proposed MRM, the performance is evaluated and compared in terms of accuracy, precision, sensitivity, and comprehensive evaluation index. In the experiments of 4 scenarios with 2 strategies, the average optimization and prediction accuracies are higher than 90% without increase in computational complexity. Comprehensive experiments and numerical results demonstrate the outperforming performance of the proposed MRM across various MRCPSP.}
}
@article{HORVATH2024593,
title = {AI for conceptual architecture: Reflections on designing with text-to-text, text-to-image, and image-to-image generators},
journal = {Frontiers of Architectural Research},
volume = {13},
number = {3},
pages = {593-612},
year = {2024},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2024.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S2095263524000256},
author = {Anca-Simona Horvath and Panagiota Pouliou},
keywords = {Machine learning, StyleGAN2-ADA, RNN TensorFlow, VQGAN + clip, AD journal, eVolo, Conceptual design, Architectural design},
abstract = {In this paper we present a research-through-design study where we employed text-to-text, text-to-image, and image-to-image generative tools for a conceptual architecture project for the eVolo skyscraper competition. We trained these algorithms on a dataset that we collected and curated, consisting of texts about and images of architecture. We describe our design process, present the final proposal, reflect on the usefulness of such tools for early-stage design, and discuss implications for future research and practice. By analysing the results from training the text-to-text generators we could establish a specific design brief that informed the final concept. The results from the image-to-image generator gave an overview of the shape grammars of previous submissions. All results were intriguing and can assist creativity and in this way, the tools were useful for gaining insight into historical architectural data, helped shape a specific design brief, and provoked new ideas. By reflecting on our design process, we argue that the use of language when employing such tools takes a new role and that three layers of language intertwined in our work: architectural discourse, programming languages, and annotations. We present a map that unfolds how these layers came together as a contribution to making machine learning more explainable for creatives.}
}
@incollection{LINSTER2020650,
title = {3.33 - Modeling of Olfactory Processing☆},
editor = {Bernd Fritzsch},
booktitle = {The Senses: A Comprehensive Reference (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {650-660},
year = {2020},
isbn = {978-0-12-805409-3},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.24153-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245241539},
author = {Christiane Linster and Thomas A. Cleland},
keywords = {Bulbar neurons, Filtering and contrast enhancement, Odorant molecules, Odorant receptors, Olfactory bulb, Pattern of activation},
abstract = {Synopsis
We here review how computational models of olfactory system have guided our understanding of olfactory processing. We discuss how the neural mechanisms underlying functionalities such as contrast enhancement, filtering and associative memory processes have been elucidated by computational models at different levels of detail. We provide an overall view of current theories of olfactory processing.}
}
@article{RANJBARI2023124,
title = {Waste management beyond the COVID-19 pandemic: Bibliometric and text mining analyses},
journal = {Gondwana Research},
volume = {114},
pages = {124-137},
year = {2023},
note = {Special Issue on Environmental impacts of COVID-19 pandemic},
issn = {1342-937X},
doi = {https://doi.org/10.1016/j.gr.2021.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1342937X22000272},
author = {Meisam Ranjbari and Zahra {Shams Esfandabadi} and Sneha Gautam and Alberto Ferraris and Simone Domenico Scagnelli},
keywords = {COVID-19, Plastic waste, Healthcare waste, Municipal solid waste, Wastewater, Personal protective equipment},
abstract = {The outbreak of the COVID-19 pandemic has significantly increased the demand for personal protective equipment, in particular face masks, thus leading to a huge amount of healthcare waste generated worldwide. Consequently, such an unprecedented amount of newly emerged waste has posed significant challenges to practitioners, policy-makers, and municipal authorities involved in waste management (WM) systems. This research aims at mapping the COVID-19-related scientific production to date in the field of WM. In this vein, the performance indicators of the target literature were analyzed and discussed through conducting a bibliometric analysis. The conceptual structure of COVID-19-related WM research, including seven main research themes, were uncovered and visualized through a text mining analysis as follows: (1) household and food waste, (2) personnel safety and training for waste handling, (3) sustainability and circular economy, (4) personal protective equipment and plastic waste, (5) healthcare waste management practices, (6) wastewater management, and (7) COVID-19 transmission through infectious waste. Finally, a research agenda for WM practices and activities in the post-COVID-19 era was proposed, focusing on the following three identified research gaps: (i) developing a systemic framework to properly manage the pandemic crisis implications for WM practices as a whole, following a systems thinking approach, (ii) building a circular economy model encompassing all activities from the design stage to the implementation stage, and (iii) proposing incentives to effectively involve informal sectors and local capacity in decentralizing municipal waste management, with a specific focus on developing and less-developed countries.}
}
@article{SHAPIRO2007807,
title = {Bacteria are small but not stupid: cognition, natural genetic engineering and socio-bacteriology},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {38},
number = {4},
pages = {807-819},
year = {2007},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2007.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S1369848607000544},
author = {J.A. Shapiro},
keywords = {Computation, Sensing, Regulation, Cybernetic, Evolution},
abstract = {Forty years’ experience as a bacterial geneticist has taught me that bacteria possess many cognitive, computational and evolutionary capabilities unimaginable in the first six decades of the twentieth century. Analysis of cellular processes such as metabolism, regulation of protein synthesis, and DNA repair established that bacteria continually monitor their external and internal environments and compute functional outputs based on information provided by their sensory apparatus. Studies of genetic recombination, lysogeny, antibiotic resistance and my own work on transposable elements revealed multiple widespread bacterial systems for mobilizing and engineering DNA molecules. Examination of colony development and organization led me to appreciate how extensive multicellular collaboration is among the majority of bacterial species. Contemporary research in many laboratories on cell–cell signaling, symbiosis and pathogenesis show that bacteria utilise sophisticated mechanisms for intercellular communication and even have the ability to commandeer the basic cell biology of ‘higher’ plants and animals to meet their own needs. This remarkable series of observations requires us to revise basic ideas about biological information processing and recognise that even the smallest cells are sentient beings.}
}
@article{CLAPIN2002231,
title = {Content and cognitive science},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {231-242},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00004-6},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000046},
author = {Hugh Clapin},
keywords = {Symbols, Classical, Cognitive science, Tacit representation, Architectural content, Computation},
abstract = {The computer model of the mind has informed and guided debate in the cognitive sciences for over 40 years, and gives pride of place to symbols. In this paper I investigate the nature of computational symbols and show that even in the parade cases of symbolic computation, symbols are not doing all the semantic and computational work. This analysis has important consequences for the scope of cognitive science, particularly with regard to what constitutes its domain: cognition.}
}
@article{DIPAOLA2014212,
title = {Using a Contextual Focus Model for an Automatic Creativity Algorithm to Generate Art Work},
journal = {Procedia Computer Science},
volume = {41},
pages = {212-219},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.105},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015506},
author = {Steve DiPaola},
keywords = {Evolutionary Systems, Genetic Programming, Contextual Focus, Creativity, Computational Modelling},
abstract = {We sought to implement and determine whether incorporating cognitive based contextual focus into a genetic programming fitness function would play a crucial role in enabling the computer system to generate art that humans find “creative” (i.e. possessing qualities of novelty and aesthetic value typically ascribed to the output of a creative artistic process). We implemented contextual focus in the evolutionary art algorithm by giving the program the capacity to vary its level of fluidity and functional triggered dynamic control over different phases of the creative process. The domain of portrait painting was chosen because it requires both focused attention (analytical thought) to accomplish the primary goal of creating portrait sitter resemblance as well as defocused attention (associative thought) to creativity deviate from resemblance i.e., to meet the broad and often conflicting criteria of aesthetic art. Since judging creative art is subjective, rather than use quantitative analysis, a representative subset of the automatically produced art-work from this system was selected and submitted to many peer reviewed and commissioned art shows, thereby allowing it to be judged positively or negatively as creative by human art curators, reviewers and the art gallery going public.}
}